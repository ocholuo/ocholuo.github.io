<!DOCTYPE html><html lang="en" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://myochosite-291718.appspot.com/query?id=ahNwfm15b2Nob3NpdGUtMjkxNzE4chULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="AWS - ELK Setup" /><meta property="og:locale" content="en" /><meta name="description" content="ELK Setup basic Install ELK Environment specifications Configuration Filebeat Logstash collect data setup 相关配置 Elasticsearch kibana installation Install ELK on Mac OS X Installation ship the data install ELK on Ubuntu in Docker Install Docker Install Elasticsearch :9200 Installing Logstash Installing Kibana :5601 Installing Metricbeat Ship the data, set up data pipeline by Logstash. Installing ELK on Docker install ship data Metricbeat Fillbeat Palo Alto Network Syslog CortexXDR Cortex Data Lake" /><meta property="og:description" content="ELK Setup basic Install ELK Environment specifications Configuration Filebeat Logstash collect data setup 相关配置 Elasticsearch kibana installation Install ELK on Mac OS X Installation ship the data install ELK on Ubuntu in Docker Install Docker Install Elasticsearch :9200 Installing Logstash Installing Kibana :5601 Installing Metricbeat Ship the data, set up data pipeline by Logstash. Installing ELK on Docker install ship data Metricbeat Fillbeat Palo Alto Network Syslog CortexXDR Cortex Data Lake" /><link rel="canonical" href="https://ocholuo.github.io//posts/ELK-Setup/" /><meta property="og:url" content="https://ocholuo.github.io//posts/ELK-Setup/" /><meta property="og:site_name" content="Grace" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-02-11T10:11:11-05:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="AWS - ELK Setup" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-10-30T21:02:21-04:00","datePublished":"2020-02-11T10:11:11-05:00","description":"ELK Setup basic Install ELK Environment specifications Configuration Filebeat Logstash collect data setup 相关配置 Elasticsearch kibana installation Install ELK on Mac OS X Installation ship the data install ELK on Ubuntu in Docker Install Docker Install Elasticsearch :9200 Installing Logstash Installing Kibana :5601 Installing Metricbeat Ship the data, set up data pipeline by Logstash. Installing ELK on Docker install ship data Metricbeat Fillbeat Palo Alto Network Syslog CortexXDR Cortex Data Lake","headline":"AWS - ELK Setup","mainEntityOfPage":{"@type":"WebPage","@id":"https://ocholuo.github.io//posts/ELK-Setup/"},"url":"https://ocholuo.github.io//posts/ELK-Setup/"}</script><title>AWS - ELK Setup | Grace</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Grace"><meta name="application-name" content="Grace"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://myochosite-291718.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://myochosite-291718.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/huoye.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Grace</a></div><div class="site-subtitle font-italic">2023 Mar 14 updated</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/ocholuo" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['',''].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>AWS - ELK Setup</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>AWS - ELK Setup</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Grace JyL </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Tue, Feb 11, 2020, 10:11 AM -0500" >Feb 11, 2020<i class="unloaded">2020-02-11T10:11:11-05:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sun, Oct 30, 2022, 6:02 PM -0700" >Oct 30, 2022<i class="unloaded">2022-10-30T21:02:21-04:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4395 words">24 min read</span> <span id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </span> views</div></div><div class="post-content"><ul><li><a href="#elk-setup">ELK Setup</a><ul><li><a href="#basic">basic</a><li><a href="#install-elk">Install ELK</a><ul><li><a href="#environment-specifications">Environment specifications</a></ul></ul><li><a href="#configuration">Configuration</a><ul><li><a href="#filebeat">Filebeat</a><li><a href="#logstash-collect-data">Logstash <code class="language-plaintext highlighter-rouge">collect data</code></a><ul><li><a href="#setup">setup</a><li><a href="#相关配置">相关配置</a></ul><li><a href="#elasticsearch">Elasticsearch</a><li><a href="#kibana">kibana</a></ul><li><a href="#installation">installation</a><ul><li><a href="#install-elk-on-mac-os-x">Install ELK on Mac OS X</a><ul><li><a href="#installation-1">Installation</a><li><a href="#ship-the-data">ship the data</a></ul><li><a href="#install-elk-on-ubuntu-in-docker">install ELK on Ubuntu in Docker</a><ul><li><a href="#install-docker">Install Docker</a><li><a href="#install-elasticsearch-9200">Install Elasticsearch <code class="language-plaintext highlighter-rouge">:9200</code></a><li><a href="#installing-logstash">Installing Logstash</a><li><a href="#installing-kibana-5601">Installing Kibana <code class="language-plaintext highlighter-rouge">:5601</code></a><li><a href="#installing-metricbeat">Installing Metricbeat</a><li><a href="#ship-the-data-set-up-data-pipeline-by-logstash">Ship the data, set up data pipeline by Logstash.</a></ul><li><a href="#installing-elk-on-docker">Installing ELK on Docker</a><ul><li><a href="#install">install</a><li><a href="#ship-data">ship data</a><ul><li><a href="#metricbeat">Metricbeat</a><li><a href="#fillbeat">Fillbeat</a></ul></ul></ul><li><a href="#palo-alto-network-syslog">Palo Alto Network Syslog</a><ul><li><a href="#cortexxdr">CortexXDR</a><li><a href="#cortex-data-lake">Cortex Data Lake</a></ul><li>ref:<ul><li><a href="https://logz.io/learn/complete-guide-elk-stack/#installing-elk">The Complete Guide to the ELK Stack</a></ul></ul><hr /><h1 id="elk-setup">ELK Setup</h1><hr /><h2 id="basic">basic</h2><p>The data lifecycle for ELK goes a little something like this:</p><ol><li><code class="language-plaintext highlighter-rouge">Syslog Server</code> feeds <code class="language-plaintext highlighter-rouge">Logstash</code><li><code class="language-plaintext highlighter-rouge">Logstash</code> filters and parses logs and stores them within <code class="language-plaintext highlighter-rouge">Elasticsearch</code><li><code class="language-plaintext highlighter-rouge">Elasticsearch</code> indexes and makes sense out of all the data<li><code class="language-plaintext highlighter-rouge">Kibana</code> makes millions of data points consumable by us mere mortals</ol><p>For this project you will need…</p><ol><li>A Linux Ubuntu Server 14.04 LTS: 1 core, 4Gb Memory, 100Gb storage<li>A Palo Alto Networks firewall with a Threat Prevention Subscription<li>Something on the firewall to generate traffic</ol><p><img data-proofer-ignore data-src="https://i.imgur.com/LAJg7EA.png" alt="image6-1024x422" /></p><hr /><h2 id="install-elk">Install ELK</h2><p>The ELK Stack can be installed using a variety of methods and on a wide array of different operating systems and environments.</p><ul><li>ELK can be installed locally, on the cloud, using Docker and configuration management systems like Ansible, Puppet, and Chef.<li>The stack can be installed using a tarball or .zip packages or from repositories.</ul><hr /><h3 id="environment-specifications">Environment specifications</h3><ul><li>single AWS Ubuntu 18.04 machine on an m4.large instance using its local storage.<li>started an EC2 instance in the public subnet of a VPC<li>set up the security group (firewall) to enable access from anywhere using SSH and TCP 5601 (Kibana).<li>added a new elastic IP address to the instance for internet connection.</ul><hr /><h1 id="configuration">Configuration</h1><hr /><h2 id="filebeat">Filebeat</h2><p><a href="https://www.jianshu.com/p/4abb141da37b">link</a></p><hr /><h2 id="logstash-collect-data">Logstash <code class="language-plaintext highlighter-rouge">collect data</code></h2><p><img data-proofer-ignore data-src="https://i.imgur.com/jztRxZK.png" width="600" /></p><p>Logstash架构：</p><p><img data-proofer-ignore data-src="https://i.imgur.com/HDzvFSW.png" alt="Screen Shot 2020-11-16 at 19.53.57" /></p><h3 id="setup">setup</h3><ol><li>下载安装</ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="c"># 下载</span>
wget https://artifacts.elastic.co/downloads/logstash/logstash-6.4.3.tar.gz
<span class="nb">tar</span> <span class="nt">-zxvf</span> logstash-6.4.3.tar.gz <span class="nt">-C</span> /usr/local
<span class="nb">ls</span> /usr/local/logstash-6.4.3/

<span class="c"># 测试logstash-6.4.3</span>
logstash <span class="nt">-e</span> <span class="s1">'input{stdin{}}output{stdout{codec=&gt;rubydebug}}'</span>
<span class="c"># [2019-09-25T15:12:47,020][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=&gt;9600}</span>
<span class="c"># 如果启动成功会出现提示语句</span>


<span class="c"># 接着屏幕就等着你输入了，比如输入一个Hello World，会出现以下的提示语句。</span>
    HelloWorld
    <span class="o">{</span>
        <span class="s2">"@timestamp"</span> <span class="o">=&gt;</span> 2019-09-25T07:14:40.491Z,
              <span class="s2">"host"</span> <span class="o">=&gt;</span> <span class="s2">"localhost"</span>,
          <span class="s2">"@version"</span> <span class="o">=&gt;</span> <span class="s2">"1"</span>,
           <span class="s2">"message"</span> <span class="o">=&gt;</span> <span class="s2">"HelloWorld"</span>
    <span class="o">}</span>
</pre></table></code></div></div><ol><li>配置文件简单测试</ol><p>pipeline配置简介：</p><div class="language-yml highlighter-rouge"><div class="code-header" text-data="yml"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
</pre><td class="rouge-code"><pre>
<span class="c1"># Pipeline用于配置input、filter和output插件</span>
<span class="s">input {}</span>
<span class="s">filter {}</span>
<span class="s">output {}</span>


<span class="c1"># 创建配置文件logstash.conf：</span>
<span class="s">vim config/logstash.conf</span>

<span class="s">input {</span>
    <span class="s">stdin { }</span>
<span class="err">}</span>
<span class="s">output {</span>
    <span class="s">stdout {</span>
        <span class="s">codec =&gt; rubydebug { }</span>
    <span class="s">}</span>
    <span class="s">elasticsearch {</span>
        <span class="s">hosts =&gt; ["0.0.0.0:9200"]</span>
        <span class="s"># user =&gt; elastic</span>
        <span class="s"># password =&gt; xW9dqAxThD5U4ShQV1JT</span>
    <span class="s">}</span>
<span class="err">}</span>


<span class="c1"># 启动elasticsearch</span>
<span class="c1"># 指定配置文件启动</span>
<span class="s">./bin/logstash -f config/logstash.conf</span>

<span class="c1"># 同样命令行等着你输入指令</span>
<span class="s">Hello World</span>
<span class="pi">{</span>
      <span class="s2">"</span><span class="s">@version"</span> <span class="nv">=&gt; "1"</span><span class="pi">,</span>
          <span class="s2">"</span><span class="s">host"</span> <span class="nv">=&gt; "localhost"</span><span class="pi">,</span>
    <span class="s2">"</span><span class="s">@timestamp"</span> <span class="nv">=&gt; 2019-09-25T07</span><span class="pi">:</span><span class="nv">25</span><span class="pi">:</span><span class="nv">03.292Z</span><span class="pi">,</span>
       <span class="s2">"</span><span class="s">message"</span> <span class="nv">=&gt; "Hello World"</span>
<span class="pi">}</span>

<span class="c1"># 访问：</span>
<span class="c1"># http://192.168.77.132:9200/_search?q=Hello</span>
<span class="pi">{</span>
    <span class="s2">"</span><span class="s">took"</span><span class="pi">:</span><span class="nv">59</span><span class="pi">,</span>
    <span class="s2">"</span><span class="s">timed_out"</span><span class="pi">:</span><span class="nv">false</span><span class="pi">,</span>
    <span class="s2">"</span><span class="s">_shards"</span><span class="pi">:{</span><span class="s2">"</span><span class="s">total"</span><span class="pi">:</span><span class="nv">1</span><span class="pi">,</span><span class="s2">"</span><span class="s">successful"</span><span class="pi">:</span><span class="nv">1</span><span class="pi">,</span><span class="s2">"</span><span class="s">skipped"</span><span class="pi">:</span><span class="nv">0</span><span class="pi">,</span><span class="s2">"</span><span class="s">failed"</span><span class="pi">:</span><span class="nv">0</span><span class="pi">},</span>
    <span class="s2">"</span><span class="s">hits"</span><span class="pi">:{</span>
        <span class="s2">"</span><span class="s">total"</span><span class="pi">:{</span><span class="s2">"</span><span class="s">value"</span><span class="pi">:</span><span class="nv">0</span><span class="pi">,</span><span class="s2">"</span><span class="s">relation"</span><span class="pi">:</span><span class="s2">"</span><span class="s">eq"</span><span class="pi">},</span>
        <span class="s2">"</span><span class="s">max_score"</span><span class="pi">:</span><span class="nv">null</span><span class="pi">,</span>
        <span class="s2">"</span><span class="s">hits"</span><span class="pi">:[]</span>
    <span class="pi">}</span>
<span class="pi">}</span>
</pre></table></code></div></div><h3 id="相关配置">相关配置</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre><td class="rouge-code"><pre>1.  持久队列基本配置<span class="o">(</span>pipelines.yml<span class="o">)</span>

    queue.type:persisted    <span class="c"># 默认是memory</span>
    queue.max_bytes:4gb     <span class="c"># 队列存储最大数据量</span>


2.  线程相关配置<span class="o">(</span>logstash.yml<span class="o">)</span>

    pipeline.worksers | <span class="nt">-w</span>
    <span class="c"># pipeline线程数，即filter_output的处理线程数，默认是cpu核数</span>
    pipeline.batch.size | <span class="nt">-b</span>
    <span class="c"># Batcher一次批量获取的待处理文档数，默认是125，可以根据输出进行调整，越大会占用越多的heap空间，可以通过jvm.options调整</span>
    pipeline.batch.delay | <span class="nt">-u</span>
    <span class="c"># Batcher等待的时长，单位为ms</span>



3.  Logstash配置文件:
<span class="c"># logstash.yml：logstash相关配置，比如node.name、path.data、pipeline.workers、queue.type等，这其中的配置可以被命令行参数中的相关参数覆盖</span>
<span class="c"># jvm.options：修改jvm的相关参数，比如修改heap size等</span>
<span class="c"># pipeline配置文件：定义数据处理流程的文件，以.conf结尾</span>

logstash.yml配置项：

    node.name:   <span class="c"># 节点名称，便于识别</span>
    path.data:   <span class="c"># 持久化存储数据的文件夹，默认是logstash home目录下的data</span>
    path.config: <span class="c"># 设定pipeline配置文件的目录（如果指定文件夹，会默认把文件夹下的所有.conf文件按照字母顺序拼接为一个文件）</span>
    path.log:    <span class="c"># 设定pipeline日志文件的目录</span>
    pipeline.workers:          <span class="c"># 设定pipeline的线程数（filter+output），优化的常用项</span>
    pipeline.batch.size/delay: <span class="c"># 设定批量处理数据的数据和延迟</span>
    queue.type:                <span class="c"># 设定队列类型，默认是memory</span>
    queue.max_bytes:           <span class="c"># 队列总容量，默认是1g</span>
</pre></table></code></div></div><hr /><h2 id="elasticsearch">Elasticsearch</h2><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="c"># since we are installing Elasticsearch on AWS, it is a good best practice to bind Elasticsearch to either a private IP or localhost:</span>
<span class="nb">sudo </span>vim /etc/elasticsearch/elasticsearch.yml

network.host: <span class="s2">"localhost"</span>
http.port:9200
cluster.initial_master_nodes: <span class="o">[</span><span class="s2">"&lt;PrivateIP"</span><span class="o">]</span>
</pre></table></code></div></div><div class="language-yml highlighter-rouge"><div class="code-header" text-data="yml"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre><span class="c1"># ======================== Elasticsearch Configuration =========================</span>
<span class="c1"># ---------------------------------- Cluster -----------------------------------</span>
<span class="c1">#cluster.name: my-application</span>
<span class="c1"># ------------------------------------ Node ------------------------------------</span>
<span class="c1">#node.name: node-1</span>
<span class="c1">#node.attr.rack: r1</span>
<span class="c1"># ----------------------------------- Paths ------------------------------------</span>
<span class="na">path.data</span><span class="pi">:</span> <span class="s">/var/lib/elasticsearch</span>
<span class="na">path.logs</span><span class="pi">:</span> <span class="s">/var/log/elasticsearch</span>
<span class="c1"># ----------------------------------- Memory -----------------------------------</span>
<span class="c1">#bootstrap.memory_lock: true</span>
<span class="c1"># ---------------------------------- Network -----------------------------------</span>
<span class="na">network.host</span><span class="pi">:</span> <span class="s2">"</span><span class="s">localhost"</span>
<span class="na">http.port</span><span class="pi">:</span> <span class="m">9200</span>
<span class="c1"># --------------------------------- Discovery ----------------------------------</span>
<span class="c1">#discovery.seed_hosts: ["host1", "host2"]</span>
<span class="na">cluster.initial_master_nodes</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">node-1"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">node-2"</span><span class="pi">]</span>
<span class="c1"># ---------------------------------- Gateway -----------------------------------</span>
<span class="c1">#gateway.recover_after_nodes: 3</span>
<span class="c1"># ---------------------------------- Various -----------------------------------</span>
<span class="c1">#action.destructive_requires_name: true</span>
</pre></table></code></div></div><hr /><h2 id="kibana">kibana</h2><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre><td class="rouge-code"><pre><span class="nb">sudo </span>vim /etc/kibana/kibana.yml

server.port: 5601
server.host: 10.0.1.168
<span class="c"># server.host: 127.0.0.1</span>
<span class="c"># server.host: "localhost"</span>
elasticsearch.url: <span class="s2">"http://localhost:9200"</span>
elasticsearch.hosts: <span class="o">[</span><span class="s2">"http://localhost:9200"</span><span class="o">]</span>
<span class="c"># tell Kibana which Elasticsearch to connect to and which port to use.</span>



<span class="nb">cd</span> /var/log/kibana/
root@319291962e3b:/var/log/kibana# <span class="nb">ls</span> <span class="nt">-la</span>
total 48
drwxr-s--- 2 kibana kibana  4096 Jan 12 15:04 <span class="nb">.</span>
drwxr-xr-x 1 root   root    4096 Jan 12 15:04 ..
<span class="nt">-rw-r--r--</span> 1 root   kibana   576 Jan 12 15:10 kibana.stderr
<span class="nt">-rw-r--r--</span> 1 root   kibana 24858 Jan 12 15:10 kibana.stdout

<span class="nb">chmod </span>777 kibana.stderr
<span class="nb">chmod </span>777 kibana.stdout
</pre></table></code></div></div><div class="language-yml highlighter-rouge"><div class="code-header" text-data="yml"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
</pre><td class="rouge-code"><pre><span class="c1"># Kibana:</span>
<span class="c1"># /etc/kibana/kibana.yml</span>
<span class="na">server.port</span><span class="pi">:</span> <span class="m">5601</span>
<span class="na">server.host</span><span class="pi">:</span> <span class="s2">"</span><span class="s">localhost"</span>
<span class="na">server.basePath</span><span class="pi">:</span> <span class="s2">"</span><span class="s">"</span>
<span class="na">server.rewriteBasePath</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">server.maxPayloadBytes</span><span class="pi">:</span> <span class="m">1048576</span>
<span class="na">server.name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">your-hostname"</span>
<span class="na">elasticsearch.hosts</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">http://localhost:9200"</span><span class="pi">]</span>
<span class="na">kibana.index</span><span class="pi">:</span> <span class="s2">"</span><span class="s">.kibana"</span>
<span class="na">kibana.defaultAppId</span><span class="pi">:</span> <span class="s2">"</span><span class="s">home"</span>
<span class="na">elasticsearch.username</span><span class="pi">:</span> <span class="s2">"</span><span class="s">kibana_system"</span>
<span class="na">elasticsearch.password</span><span class="pi">:</span> <span class="s2">"</span><span class="s">pass"</span>
<span class="na">server.ssl.enabled</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">server.ssl.certificate</span><span class="pi">:</span> <span class="s">/path/to/your/server.crt</span>
<span class="na">server.ssl.key</span><span class="pi">:</span> <span class="s">/path/to/your/server.key</span>
<span class="na">elasticsearch.ssl.certificate</span><span class="pi">:</span> <span class="s">/path/to/your/client.crt</span>
<span class="na">elasticsearch.ssl.key</span><span class="pi">:</span> <span class="s">/path/to/your/client.key</span>
<span class="na">elasticsearch.ssl.certificateAuthorities</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">/path/to/your/CA.pem"</span> <span class="pi">]</span>
<span class="na">elasticsearch.ssl.verificationMode</span><span class="pi">:</span> <span class="s">full</span>
<span class="na">elasticsearch.pingTimeout</span><span class="pi">:</span> <span class="m">1500</span>
<span class="na">elasticsearch.requestTimeout</span><span class="pi">:</span> <span class="m">30000</span>
<span class="na">elasticsearch.requestHeadersWhitelist</span><span class="pi">:</span> <span class="pi">[</span> <span class="nv">authorization</span> <span class="pi">]</span>
<span class="na">elasticsearch.customHeaders</span><span class="pi">:</span> <span class="pi">{}</span>
<span class="na">elasticsearch.shardTimeout</span><span class="pi">:</span> <span class="m">30000</span>
<span class="na">elasticsearch.logQueries</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">pid.file</span><span class="pi">:</span> <span class="s">/var/run/kibana.pid</span>
<span class="na">logging.dest</span><span class="pi">:</span> <span class="s">stdout</span>
<span class="na">logging.silent</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">logging.quiet</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">logging.verbose</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">ops.interval</span><span class="pi">:</span> <span class="m">5000</span>
<span class="na">i18n.locale</span><span class="pi">:</span> <span class="s2">"</span><span class="s">en"</span>
</pre></table></code></div></div><hr /><h1 id="installation">installation</h1><hr /><h2 id="install-elk-on-mac-os-x">Install ELK on Mac OS X</h2><h3 id="installation-1">Installation</h3><ol><li><p>Install Homebrew</p><li><p>Install Java</p><li><p>Install Elasticsearch logstash kibana</p></ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre>brew <span class="nb">install </span>elasticsearch <span class="o">&amp;&amp;</span> brew info elasticsearch
brew services start elasticsearch

brew <span class="nb">install </span>logstash
brew services start logstash



brew <span class="nb">install </span>kibana
brew services start kibana

brew services list
<span class="c"># Name          Status  User Plist</span>
<span class="c"># elasticsearch started luo  /Users/luo/Library/LaunchAgents/homebrew.mxcl.elasticsearch.plist</span>
<span class="c"># kibana        started luo  /Users/luo/Library/LaunchAgents/homebrew.mxcl.kibana.plist</span>
<span class="c"># logstash      started luo  /Users/luo/Library/LaunchAgents/homebrew.mxcl.logstash.plist</span>
<span class="c"># openvpn       started root /Library/LaunchDaemons/homebrew.mxcl.openvpn.plist</span>
</pre></table></code></div></div><h3 id="ship-the-data">ship the data</h3><ol><li>configuration</ol><div class="language-yml highlighter-rouge"><div class="code-header" text-data="yml"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
</pre><td class="rouge-code"><pre><span class="c1"># --------------------- Kibana configure:</span>
<span class="c1"># /usr/local/etc/kibana/kibana.yml</span>
<span class="na">server.port</span><span class="pi">:</span> <span class="m">5601</span>                               <span class="c1"># defining the Kibana port</span>
<span class="c1"># elasticsearch.url: "http://localhost:9200”    # defining the Elasticsearch instance</span>
<span class="na">elasticsearch.hosts</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">http://localhost:9200"</span><span class="pi">]</span>



<span class="c1"># --------------------- Logstash configure:</span>
<span class="c1"># /etc/logstash/conf.d/syslog.conf</span>
<span class="c1"># Logstash pipeline sending syslog logs into the stack.</span>

<span class="c1"># Brew installs logstash in /usr/local/Cellar/logstash/7.9.0,</span>
<span class="c1"># and creates a symlink of the config folder</span>
<span class="c1"># in /usr/local/Cellar/logstash/7.9.0/libexec/config to /usr/local/etc/logstash.</span>

<span class="c1"># when your run sudo vim /etc/logstash/conf.d/syslog.conf,, it will not find the dir and will throw an error.</span>
<span class="c1"># even if you create the folder with the conf file, you will see no "syslog-demo" index in Kibana.</span>

<span class="c1"># Solution!</span>
<span class="c1"># Create a new conf.d folder inside /usr/local/etc/logstash, and then create a syslog config file.</span>
<span class="c1"># mkdir /usr/local/etc/logstash/conf.d</span>
<span class="c1"># sudo vim /etc/logstash/conf.d/syslog.conf</span>
<span class="c1"># Copy the configuration, paste it, save and quit vim.</span>

<span class="c1"># After that, set Logstash config path:</span>
<span class="c1"># logstash -f /usr/local/etc/logstash/conf.d/*.conf</span>

<span class="s">input {</span>
    <span class="s">file {</span>
        <span class="s">path =&gt; [ "/var/log/*.log", "/var/log/messages", "/var/log/syslog" ]</span>
        <span class="s">type =&gt; "syslog"</span>
    <span class="s">}</span>
<span class="err">}</span>

<span class="s">filter {</span>
    <span class="s">if [type] == "syslog" {</span>
        <span class="s">grok {</span>
            <span class="s">match =&gt; { "message" =&gt; "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }</span>
            <span class="s">add_field =&gt; [ "received_at", "%{@timestamp}" ]</span>
            <span class="s">add_field =&gt; [ "received_from", "%{host}" ]</span>
        <span class="s">}</span>
        <span class="s">syslog_pri { }</span>
        <span class="s">date {</span>
            <span class="s">match =&gt; [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]</span>
        <span class="s">}</span>
    <span class="s">}</span>
<span class="err">}</span>

<span class="s">output {</span>
    <span class="s">elasticsearch {</span>
        <span class="s">hosts =&gt; ["127.0.0.1:9200"]</span>
        <span class="s">index =&gt; "syslog-demo"</span>
    <span class="s">}</span>
    <span class="s">stdout { codec =&gt; rubydebug }</span>
<span class="err">}</span>
</pre></table></code></div></div><p><img data-proofer-ignore data-src="https://i.imgur.com/gpVIydn.png" alt="Screen Shot 2021-01-12 at 23.25.21" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/g1FGNyh.png" alt="Screen Shot 2021-01-12 at 23.30.17" /></p><hr /><h2 id="install-elk-on-ubuntu-in-docker">install ELK on Ubuntu in Docker</h2><h3 id="install-docker">Install Docker</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>apt-get <span class="nt">-y</span> <span class="nb">install sudo </span>gnupg2 gnupg vim curl apache2 ufw
apt-get update
apt-get <span class="nb">install </span>wget

docker run ubuntu:18.04
docker run <span class="nt">-it</span> ubuntu:18.04 /bin/bash
</pre></table></code></div></div><hr /><h3 id="install-elasticsearch-9200">Install Elasticsearch <code class="language-plaintext highlighter-rouge">:9200</code></h3><ol><li>add Elastic’s signing key<ul><li>so that the downloaded package can be verified<li>(skip this step if you’ve already installed packages from Elastic):</ul></ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="c"># Ubuntu:</span>
wget <span class="nt">-qO</span> - https://artifacts.elastic.co/GPG-KEY-elasticsearch | <span class="nb">sudo </span>apt-key add -

<span class="c"># Debian:</span>
<span class="c"># need to then install the apt-transport-https package</span>
<span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nb">install </span>apt-transport-https
</pre></table></code></div></div><ol><li>add the repository definition to the system:</ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="nb">echo</span> <span class="s2">"deb https://artifacts.elastic.co/packages/7.x/apt stable main"</span> | <span class="nb">sudo tee</span> <span class="nt">-a</span> /etc/apt/sources.list.d/elastic-7.x.list

<span class="c"># To install a version of Elasticsearch that contains only features licensed under Apache 2.0 (aka OSS Elasticsearch):</span>
<span class="nb">echo</span> <span class="s2">"deb https://artifacts.elastic.co/packages/oss-7.x/apt stable main"</span> | <span class="nb">sudo tee</span> <span class="nt">-a</span> /etc/apt/sources.list.d/elastic-7.x.list
</pre></table></code></div></div><ol><li>update repositories and install Elasticsearch:</ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get <span class="nb">install </span>elasticsearch
</pre></table></code></div></div><ol><li>Elasticsearch configurations<ul><li>using a configuration file to configure<li>general settings (e.g. node name),<li>network settings (e.g. host and port),<li>where data is stored, memory, log files, and more.</ul></ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="c"># since we are installing Elasticsearch on AWS, it is a good best practice to bind Elasticsearch to either a private IP or localhost:</span>
<span class="nb">sudo </span>vim /etc/elasticsearch/elasticsearch.yml

network.host: <span class="s2">"localhost"</span>
http.port:9200
cluster.initial_master_nodes: <span class="o">[</span><span class="s2">"&lt;PrivateIP"</span><span class="o">]</span>
</pre></table></code></div></div><ol><li>To run Elasticsearch</ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nb">sudo </span>service elasticsearch start
</pre></table></code></div></div><ol><li>To confirm that everything is working as expected<ul><li>point curl or your browser to http://localhost:9200,<li>and you should see something like the following output:</ul></ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre>
curl http://localhost:9200
<span class="o">{</span>
  <span class="s2">"name"</span> : <span class="s2">"319291962e3b"</span>,
  <span class="s2">"cluster_name"</span> : <span class="s2">"elasticsearch"</span>,
  <span class="s2">"cluster_uuid"</span> : <span class="s2">"_na_"</span>,
  <span class="s2">"version"</span> : <span class="o">{</span>
    <span class="s2">"number"</span> : <span class="s2">"7.10.1"</span>,
    <span class="s2">"build_flavor"</span> : <span class="s2">"default"</span>,
    <span class="s2">"build_type"</span> : <span class="s2">"deb"</span>,
    <span class="s2">"build_hash"</span> : <span class="s2">"1c34507e66d7db1211f66f3513706fdf548736aa"</span>,
    <span class="s2">"build_date"</span> : <span class="s2">"2020-12-05T01:00:33.671820Z"</span>,
    <span class="s2">"build_snapshot"</span> : <span class="nb">false</span>,
    <span class="s2">"lucene_version"</span> : <span class="s2">"8.7.0"</span>,
    <span class="s2">"minimum_wire_compatibility_version"</span> : <span class="s2">"6.8.0"</span>,
    <span class="s2">"minimum_index_compatibility_version"</span> : <span class="s2">"6.0.0-beta1"</span>
  <span class="o">}</span>,
  <span class="s2">"tagline"</span> : <span class="s2">"You Know, for Search"</span>
<span class="o">}</span>
</pre></table></code></div></div><blockquote><p>Installing an Elasticsearch cluster requires a different type of setup.</p></blockquote><hr /><h3 id="installing-logstash">Installing Logstash</h3><ol><li>Logstash requires Java 8 or Java 11 to run<ul><li>start the process of setting up Logstash with:</ul></ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> default-jre

<span class="c"># Verify java is installed:</span>
java <span class="nt">-version</span>
<span class="c"># openjdk version "1.8.0_191"</span>
<span class="c"># OpenJDK Runtime Environment (build 1.8.0_191-8u191-b12-2ubuntu0.16.04.1-b12)</span>
<span class="c"># OpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode)</span>
<span class="c"># # mine:</span>
<span class="c"># openjdk version "11.0.9.1" 2020-11-04</span>
<span class="c"># OpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04)</span>
<span class="c"># OpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)</span>
</pre></table></code></div></div><ol><li>Since already defined the repository in the system, install Logstash is run:</ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nb">sudo </span>apt-get <span class="nb">install </span>logstash
</pre></table></code></div></div><p>Before you run Logstash, you will need to configure a data pipeline. We will get back to that once we’ve installed and started Kibana.</p><hr /><h3 id="installing-kibana-5601">Installing Kibana <code class="language-plaintext highlighter-rouge">:5601</code></h3><ol><li>install Kibana:</ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> kibana
</pre></table></code></div></div><ol><li>Kibana configuration file <code class="language-plaintext highlighter-rouge">/etc/kibana/kibana.yml</code></ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="nb">sudo </span>vim /etc/kibana/kibana.yml

server.port: 5601
server.host: 10.0.1.168
<span class="c"># server.host: 127.0.0.1</span>
<span class="c"># server.host: "localhost"</span>
elasticsearch.url: <span class="s2">"http://localhost:9200"</span>
elasticsearch.hosts: <span class="o">[</span><span class="s2">"http://localhost:9200"</span><span class="o">]</span>
<span class="c"># tell Kibana which Elasticsearch to connect to and which port to use.</span>
</pre></table></code></div></div><ol><li>start Kibana with:</ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nb">sudo </span>service kibana start
</pre></table></code></div></div><ol><li>Open up Kibana in browser with: http://localhost:5601 &gt; Kibana home page.</ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>curl http://localhost:5601
</pre></table></code></div></div><p><img data-proofer-ignore data-src="https://dytvr9ot2sszz.cloudfront.net/wp-content/uploads/2019/08/kibana_7_homepage.png" alt="pic" /></p><hr /><h3 id="installing-metricbeat">Installing Metricbeat</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="c"># install Metricbeat:</span>
<span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> metricbeat
<span class="nb">sudo </span>service metricbeat start
</pre></table></code></div></div><p>Metricbeat</p><ul><li>begin monitoring your server and create an Elasticsearch index which you can define in Kibana.</ul><hr /><h3 id="ship-the-data-set-up-data-pipeline-by-logstash">Ship the data, set up data pipeline by Logstash.</h3><ol><li>prepared some sample data containing Apache access logs that is refreshed daily.<ul><li>You can download the data here: <a href="https://s3.amazonaws.com/logzio-elk/apache-daily-access.log">sample-data</a></ul><li>create a new Logstash configuration file<ul><li><code class="language-plaintext highlighter-rouge">/etc/logstash/conf.d/apache-01.conf</code></ul></ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nb">sudo </span>vim /etc/logstash/apache-01.conf
</pre></table></code></div></div><ol><li>Enter the following Logstash configuration<ul><li>(change the path to the file you downloaded accordingly):</ul></ol><div class="language-js highlighter-rouge"><div class="code-header" text-data="js"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="nx">input</span> <span class="p">{</span>
    <span class="nx">file</span> <span class="p">{</span>
        <span class="nx">path</span> <span class="o">=&gt;</span> <span class="dl">"</span><span class="s2">/root/test/apache-daily-access.log</span><span class="dl">"</span>
        <span class="nx">start_position</span> <span class="o">=&gt;</span> <span class="dl">"</span><span class="s2">beginning</span><span class="dl">"</span>
        <span class="nx">sincedb_path</span> <span class="o">=&gt;</span> <span class="dl">"</span><span class="s2">/dev/null</span><span class="dl">"</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="nx">filter</span> <span class="p">{</span>
    <span class="nx">grok</span> <span class="p">{</span><span class="nx">match</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="dl">"</span><span class="s2">message</span><span class="dl">"</span> <span class="o">=&gt;</span> <span class="dl">"</span><span class="s2">%{COMBINEDAPACHELOG}</span><span class="dl">"</span> <span class="p">}}</span>
    <span class="nx">date</span> <span class="p">{</span><span class="nx">match</span> <span class="o">=&gt;</span> <span class="p">[</span> <span class="dl">"</span><span class="s2">timestamp</span><span class="dl">"</span> <span class="p">,</span> <span class="dl">"</span><span class="s2">dd/MMM/yyyy:HH:mm:ss Z</span><span class="dl">"</span> <span class="p">]}</span>
    <span class="nx">geoip</span> <span class="p">{</span><span class="nx">source</span> <span class="o">=&gt;</span> <span class="dl">"</span><span class="s2">clientip</span><span class="dl">"</span><span class="p">}</span>
<span class="p">}</span>

<span class="nx">output</span> <span class="p">{</span>
    <span class="nx">elasticsearch</span> <span class="p">{</span>
        <span class="nx">hosts</span> <span class="o">=&gt;</span> <span class="p">[</span><span class="dl">"</span><span class="s2">localhost:9200</span><span class="dl">"</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><ol><li>Start Logstash with:</ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nb">sudo </span>service logstash start
</pre></table></code></div></div><ol><li>a new Logstash index will be created in Elasticsearch<ul><li>the pattern of which can now be defined in Kibana.<li>In Kibana, go to <strong>Management → Kibana Index Patterns</strong>.<li>Kibana should display the Logstash index and along with the Metricbeat index if you followed the steps for installing and running Metricbeat).</ul></ol><p><img data-proofer-ignore data-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="pic" /></p><p><img data-proofer-ignore data-src="https://dytvr9ot2sszz.cloudfront.net/wp-content/uploads/2019/08/kibana_7_define_index.png" alt="pic" /></p><p>Enter “<code class="language-plaintext highlighter-rouge">logstash-*</code>” as the index pattern, and in the next step select @timestamp as your Time Filter field.</p><p><img data-proofer-ignore data-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="pic" /></p><p><img data-proofer-ignore data-src="https://dytvr9ot2sszz.cloudfront.net/wp-content/uploads/2019/08/kibana_7_define_index_timestamp.png" alt="pic" /></p><p>Hit <strong>Create index pattern</strong>, and you are ready to analyze the data. Go to the Discover tab in Kibana to take a look at the data (look at today’s data instead of the default last 15 mins).</p><p><img data-proofer-ignore data-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="pic" /></p><p><img data-proofer-ignore data-src="https://dytvr9ot2sszz.cloudfront.net/wp-content/uploads/2019/08/kibana_7_discoverpage.png" alt="pic" /></p><p>Congratulations! You have set up your first ELK data pipeline using Elasticsearch, Logstash, and Kibana.</p><hr /><h2 id="installing-elk-on-docker">Installing ELK on Docker</h2><h3 id="install">install</h3><ol><li>Install</ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c"># Install</span>
git clone https://github.com/deviantony/docker-elk.git
<span class="nb">cd</span> /docker-elk
docker-compose up <span class="nt">-d</span>

<span class="c"># Verifying the installation</span>
docker ps
<span class="c"># CONTAINER ID        IMAGE                             COMMAND                  CREATED             STATUS              PORTS                                            NAMES</span>
<span class="c"># a1a00714081a        dockerelk_kibana                  "/bin/bash /usr/loca…"   54 seconds ago      Up 53 seconds       0.0.0.0:5601-&gt;5601/tcp                           dockerelk_kibana_1</span>
<span class="c"># 91ca160f606f        dockerelk_logstash                "/usr/local/bin/dock…"   54 seconds ago      Up 53 seconds       5044/tcp, 0.0.0.0:5000-&gt;5000/tcp, 9600/tcp       dockerelk_logstash_1</span>
<span class="c"># de7e3368aa0c        dockerelk_elasticsearch           "/usr/local/bin/dock…"   55 seconds ago      Up 54 seconds       0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp   dockerelk_elasticsearch_1</span>
</pre></table></code></div></div><ol><li>ports on localhost have been mapped to the default ports<ul><li>Elasticsearch (9200/9300), Kibana (5601) and Logstash (5000/5044).</ul><li>Everything is already pre-configured with a privileged username and password:<ul><li>user: elastic<li>password: changeme</ul><li>query Elasticsearch using:<ul><li><code class="language-plaintext highlighter-rouge">http://localhost:5601</code><li><code class="language-plaintext highlighter-rouge">curl http://localhost:9200/_security/_authenticate</code></ul></ol><h3 id="ship-data">ship data</h3><blockquote><p>Our next step is to forward some data into the stack.</p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header" text-data="plaintext"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>Other Beats currently available from Elastic are:

Filebeat: collects and ships log files.
Packetbeat: collects and analyzes network data.
Winlogbeat: collects Windows event logs.
Auditbeat: collects Linux audit framework data and monitors file integrity.
Heartbeat: monitors services for their availability with active probing.
</pre></table></code></div></div><ol><li>By default, the stack will be running Logstash with the default Logstash configuration file.<ul><li>configure that file to suit purposes<li>and ship any type of data into your Dockerized ELK<li>and then restart the container.</ul></ol><hr /><h4 id="metricbeat">Metricbeat</h4><ol><li>Alternatively, install Filebeat<ul><li>either on your host machine or as a container<li>and have Filebeat forward logs into the stack.</ul></ol><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
</pre><td class="rouge-code"><pre><span class="c"># 1. download and install Metricbeat:</span>
curl <span class="nt">-L</span> <span class="nt">-O</span> https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-6.1.2-darwin-x86_64.tar.gz
<span class="nb">tar </span>xzvf metricbeat-6.1.2-darwin-x86_64.tar.gz


<span class="c"># 2. configure the metricbeat.yml</span>
<span class="c">#    - collect metrics on operating system and ship them to the Elasticsearch container:</span>
<span class="nb">cd </span>metricbeat-6.1.2-darwin-x86_64
<span class="nb">sudo </span>vim metricbeat.yml

metricbeat.modules:
- module: system
  metricsets:
    - cpu
    - filesystem
    - memory
    - network
    - process
  enabled: <span class="nb">true
  </span>period: 10s
  processes: <span class="o">[</span><span class="s1">'.*'</span><span class="o">]</span>
  cpu_ticks: <span class="nb">false

</span>fields:
  <span class="nb">env</span>: dev

output.elasticsearch:
  <span class="c"># Array of hosts to connect to.</span>
  hosts: <span class="o">[</span><span class="s2">"localhost:9200"</span><span class="o">]</span>


metricbeat.modules:
- module: system
  metricsets: <span class="o">[</span><span class="s2">"cpu"</span>,<span class="s2">"memory"</span>,<span class="s2">"network"</span>, <span class="s2">"filesystem"</span>, <span class="s2">"process"</span><span class="o">]</span>
  enabled: <span class="nb">true
  </span>period: 10s
  processes: <span class="o">[</span><span class="s1">'.*'</span><span class="o">]</span>

fields:
  <span class="nb">env</span>: dev

output.elasticsearch:
  <span class="c"># Array of hosts to connect to.</span>
  hosts: <span class="o">[</span><span class="s2">"localhost:9200"</span><span class="o">]</span>
output.logstash:
  hosts: <span class="o">[</span><span class="s2">"localhost:5044"</span><span class="o">]</span>



<span class="c"># 3. start Metricbeat</span>
<span class="nb">sudo chown </span>root metricbeat.yml
<span class="nb">sudo chown </span>root modules.d/system.yml
<span class="nb">sudo</span> ./metricbeat <span class="nt">-e</span> <span class="nt">-c</span> metricbeat.yml <span class="nt">-d</span> <span class="s2">"publish"</span>


<span class="c"># 4. will see a Metricbeat index created in Elasticsearch, and it’s pattern identified in Kibana.</span>
curl <span class="nt">-XGET</span> <span class="s1">'localhost:9200/_cat/indices?v&amp;pretty'</span>
health status index                       uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   .kibana                     XPHh2YDCSKKyz7PtmHyrMw   1   1          2            1       67kb           67kb
yellow open   metricbeat-6.1.2-2018.01.25 T_8jrMFoRYqL3IpZk1zU4Q   1   1      15865            0      3.4mb          3.4mb

<span class="c"># mine</span>
curl <span class="nt">-XGET</span> <span class="s1">'localhost:9200/_cat/indices?v&amp;pretty'</span> <span class="nt">-u</span> elastic:changeme
health status index                             uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   .monitoring-kibana-7-2021.01.12   tgGfn-eLSme2BEAwLWVpCw   1   0        694            0    421.4kb        421.4kb
green  open   .triggered_watches                bfOzsoyKRUONi2rVEaAtsg   1   0          0            0     45.7kb         45.7kb
green  open   .apm-agent-configuration          wVWyj03nRGGNKTd9C1IypA   1   0          0            0       208b           208b
yellow open   logstash-2021.01.12-000001        VnUG-uKsTlew9hnrhP0c0A   1   1          0            0       208b           208b
green  open   .kibana_1                         RfvZCRBuSqCTu8kdwT4vRw   1   0       1548           46      5.3mb          5.3mb
green  open   .monitoring-logstash-7-2021.01.12 alkl8u8cRqy4_rf0SFmijQ   1   0       1946            0    477.5kb        477.5kb
green  open   .ml-config                        KD5Y-O6lT6uvA3IpPeqXtw   1   0         20            0     51.2kb         51.2kb
green  open   .security-7                       omtVvA4-QmmtGo550YJBrA   1   0         55            0    178.3kb        178.3kb
green  open   .apm-custom-link                  pcellkZLTiultUWQaq6vEA   1   0          0            0       208b           208b
green  open   .kibana_task_manager_1            BaTGM6N-QemCI05zSH_BxA   1   0          6           23    196.1kb        196.1kb
green  open   .monitoring-es-7-2021.01.12       yO-smpAuQXCelOxYk5x9BA   1   0       8083         1150      9.4mb          9.4mb
green  open   .monitoring-alerts-7              BX68CsmmQSKpEu_R_9rNWA   1   0          2            7    111.9kb        111.9kb
green  open   .kibana-event-log-7.10.1-000001   M36agcORQY-QeoKohg0Mog   1   0          2            0       11kb           11kb
yellow open   filebeat-7.10.1-2021.01.12-000001 eM3rpds0TwCrp9LjJEonFw   1   1          0            0       208b           208b
green  open   .watches                          bfRDY58eRRyBefLRdPd0Wg   1   0          6           48    375.5kb        375.5kb
</pre></table></code></div></div><hr /><h4 id="fillbeat">Fillbeat</h4><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre>curl <span class="nt">-L</span> <span class="nt">-O</span> https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.10.1-darwin-x86_64.tar.gz
<span class="nb">tar </span>xzvf filebeat-7.10.1-darwin-x86_64.tar.gz
<span class="nb">cd </span>filebeat-7.10.1-darwin-x86_64/

vim filebeat.yml

output.elasticsearch:
  hosts: <span class="o">[</span><span class="s2">"localhost:9200"</span><span class="o">]</span>
  username: <span class="s2">"elastic"</span>
  password: <span class="s2">"changeme"</span>
setup.kibana:
  host: <span class="s2">"localhost:5601"</span>
</pre></table></code></div></div><p><img data-proofer-ignore data-src="https://i.imgur.com/nOBMVjq.png" alt="Create-Index-Pattern" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/LztZPkX.png" alt="timestamp" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/RGq05Hz.png" alt="bar-graph" /></p><hr /><hr /><h1 id="palo-alto-network-syslog">Palo Alto Network Syslog</h1><h2 id="cortexxdr">CortexXDR</h2><p>To send XDR notifications to Syslog server. define the settings for the Syslog receiver from which you want to send notifications.</p><ol><li>Before define the Syslog settings, enable access to the following <code class="language-plaintext highlighter-rouge">XDR IP addresses</code> for your deployment region in your firewall configurations:</ol><p><img data-proofer-ignore data-src="https://i.imgur.com/ItiRV7H.png" alt="Screen Shot 2020-11-17 at 16.53.37" /></p><ol><li>Navigate to Settings &gt; Integrations &gt; External Applications.<li>In Syslog Servers, add a <kbd>+ New Server</kbd>.<li>Define the Syslog server parameters:<ul><li><strong>Name</strong> — Unique name for the server profile.<li><strong>Destination</strong> — IP address or fully qualified domain name (FQDN) of the Syslog server.<li><strong>Port</strong> — The port number on which to send Syslog messages.<li><strong>Facility</strong> — Choose one of the Syslog standard values.<ul><li>The value maps to how your Syslog server uses the facility field to manage messages.<li>For details on the facility field, see RFC 5424.</ul><li><strong>Protocol</strong> — Select a method of communication with the Syslog server:<ul><li><code class="language-plaintext highlighter-rouge">TCP</code> — No validation is made on the connection with the Syslog server. However, if an error occurred with the domain used to make the connection, the Test connection will fail.<li><code class="language-plaintext highlighter-rouge">UDP</code> — XDR runs a validation to ensure connection was made with the syslog server.<li><code class="language-plaintext highlighter-rouge">TCP + SSL</code> — XDR validates the syslog server certificate and uses the certificate signature and public key to encrypt the data sent over the connection.</ul><li><strong>Certificate</strong> — The communication between XDR and the Syslog destination can use TLS. In this case, upon connection, XDR validates that the Syslog receiver has a certificate signed by either a trusted root CA or a self signed certificate.<ul><li>If your syslog receiver uses a <code class="language-plaintext highlighter-rouge">self signed CA</code>:<ul><li>Browse and upload the Self Signed Syslog Receiver CA.<li>Make sure the self signed CA includes the public key.</ul><li>If you only use a <code class="language-plaintext highlighter-rouge">trusted root CA</code>:<ul><li>leave the Certificate field empty.</ul></ul><li><strong>Ignore Certificate Error</strong> — XDR does not recommend, but you can choose to select this option to ignore certificate errors if they occur. This will forward alerts and logs even if the certificate contains errors.</ul><li><strong>Test</strong> the parameters to ensure a valid connection and <strong>Create</strong> when ready.<ol><li>You can define up to five Syslog servers.<li>Upon success, the table displays the Syslog servers and their status.</ol><li>(Optional) Manage your Syslog server connection.<ul><li>In the Syslog Servers table<ul><li>Locate your Syslog server and right-click to <kbd>Send text message</kbd> to test the connection.<li>XDR sends a message to the defined Syslog server, check to see if the test message indeed arrived.</ul><li>Locate the <kbd>Status field</kbd>.<ul><li>The Status field displays a Valid or Invalid TCP connection.<li>XDR tests connection with the Syslog server every 10min.<li>If no connection is found after 1 hour, XDR send a notice to the Notification Center.</ul></ul><li>Configure Notification Forwarding.<ul><li>After you integrate with your Syslog receiver, you can configure your forwarding settings.</ul></ol><hr /><h2 id="cortex-data-lake">Cortex Data Lake</h2><p>By default, Cortex Data Lake forwards logs in CSV format and follows IETF Syslog message format defined in RFC 5425. but can select other log record formats, such as LEEF, that may adhere to different standards.</p><ul><li>For each instance of Cortex Data Lake, you can forward logs to ten Syslog destinations.<li>The communication between Cortex Data Lake and the Syslog destination uses <code class="language-plaintext highlighter-rouge">Syslog over TLS</code><li>and upon connection Cortex Data Lake validates that the Syslog receiver has a certificate signed by a trusted root CA.<li>To complete the SSL handshake and establish the connection, the Syslog receiver must present all the certificates from the chain of trust.<li>Cortex Data Lake does not support self-signed certificates.</ul><ol><li>Enable communication between Cortex Data Lake and your Syslog receiver.<ol><li>Ensure the Syslog receiver can connect to Cortex Data Lake<li>and can present a valid CA certificate to complete the connection request.<li>Allow an inbound TLS feed to the Syslog receiver from the following IP address ranges:<li><img data-proofer-ignore data-src="https://i.imgur.com/2lG48CX.png" alt="Screen Shot 2020-11-17 at 17.04.55" /><li>If you have allowed specific IP addresses for inbound traffic, you must also allow the above IP address ranges to forward logs to your Syslog receiver.<li>Obtain a certificate from a well-known, public CA, and install it on your Syslog receiver.<ol><li>Because Cortex Data Lake validates the server certificate to establish a connection, must verify that the Syslog receiver is configured to properly send the SSL certificate chain to Cortex Data Lake.<li>If the app cannot verify that the certificate of the receiver and all CA’s in the chain are trustworthy, the connection cannot be established.<li>See the list of trusted certificates.</ol></ol><li>Sign In to the hub<li>Select the Cortex Data Lake instance to configure for Syslog forwarding.<ol><li>If you have multiple Cortex Data Lake instances, click the Cortex Data Lake tile and select an instance from the list of those available.</ol><li>Select Log Forwarding &gt; Add to add a new Syslog forwarding profile.<li>Enter a descriptive Name for the profile.<li>Enter the Syslog Server IPv4 address or FQDN.<li>Enter the Port on which the Syslog server is listening.<ul><li>The default port for <code class="language-plaintext highlighter-rouge">Syslog messages over TLS</code> is <code class="language-plaintext highlighter-rouge">6514</code>.</ul><li>Select the Facility.<ul><li>Choose one of the Syslog standard values.<li>The value maps to how the Syslog server uses the facility field to manage messages.<li>For details on the facility field, see the IETF standard for the log format that you will choose in the next step.</ul><li>Specify the Format in which to forward the logs.<ul><li>The log format select depends on the destination of the log data.<li>For example, select LEEF if you are forwarding logs to IBM QRadar SIEM.</ul><li>Specify the Delimiter to separate the fields in your log messages.<li>(Optional) To receive a <strong>Status Notification</strong> when Cortex Data Lake is unable to connect to the Syslog server, enter the email address at which you’d like to receive the notification.<ul><li>These notifications describe the error impacting communication between Cortex Data Lake and the Syslog server, so that you can take the appropriate steps to restore Syslog connectivity.</ul><li>(Optional) Enter a <strong>Profile Token</strong> to send logs to a cloud Syslog receiver.<ul><li>If you use a third-party cloud-based Syslog service, you can enter a token that Cortex Data Lake inserts into the Syslog message so that the cloud Syslog provider can identify the source of the logs.<li>Follow your cloud Syslog provider’s instructions for generating an identifying token.<li>Enter the Profile Token.<li>Tokens have a maximum length of 128 characters.</ul><li>Select the logs you want to forward.<ol><li>Add a new log filter.<li>Select the log type.<ol><li>The Threat log type does not include URL logs or Data logs.<li>If you wish to forward these log types, you must add them individually.</ol><li>(Optional)Create a log filter to forward only the logs that are most critical to you.<ol><li>Log filters function like queries in Explore.<li>As such, you can either write your own queries from scratch or use the query builder. Also, selecting the query field presents some common predefined queries that you can use.<li>If you want to forward all logs of the type you selected, do not enter a query. Instead, proceed to the next step.</ol></ol><li><strong>Save</strong> your changes.<li>Verify the <strong>Status</strong> of the Syslog forwarding profile is <code class="language-plaintext highlighter-rouge">Running</code>.<li>Verify that you can view logs on the Syslog receiver.<ol><li>For details about the log format, refer to the Syslog field descriptions (Select the PAN-OS Administrator’s Guide for your firewall version).</ol></ol><hr /><p>ref:</p><ul><li><a href="https://www.jianshu.com/p/140ce103b03d">blog</a></ul><p>.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/00basic/'>00Basic</a>, <a href='/categories/elk/'>ELK</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/basic/" class="post-tag no-text-decoration" >Basic</a> <a href="/tags/aws/" class="post-tag no-text-decoration" >AWS</a> <a href="/tags/elk/" class="post-tag no-text-decoration" >ELK</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=AWS - ELK Setup - Grace&url=https://ocholuo.github.io//posts/ELK-Setup/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=AWS - ELK Setup - Grace&u=https://ocholuo.github.io//posts/ELK-Setup/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=AWS - ELK Setup - Grace&url=https://ocholuo.github.io//posts/ELK-Setup/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Amazon-CloudFront/">AWS Lab - AWS CloudFront</a><li><a href="/posts/Alexa-1stSkill/">AWS Alex First Skill - RedVelvet Time</a><li><a href="/posts/NetworkProtocol-SSL-TLS-Handshake/">NetworkProtocol SSL/TLS Handshake</a><li><a href="/posts/pythonCrash/">Python Crash</a><li><a href="/posts/%E4%B8%80%E5%8F%A5%E8%AF%9D%E8%A7%A3%E9%87%8AAWS/">AWS - 一句话解释AWS</a><li><a href="/posts/GKE/">GCP - Google Cloud Computing - Kubernetes and Kubernetes Engine</a><li><a href="/posts/Go-Note/">Go Note</a><li><a href="/posts/SCPs/">AWS - IdenAccessManage - SCPs (Service Control Policies)</a><li><a href="/posts/CompanyBenefit/">Company Benefit</a><li><a href="/posts/Encryption-SSL&TLS/">Cryptography - SSL/TLS Encryption</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/aws/">AWS</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/cyberattack/">CyberAttack</a> <a class="post-tag" href="/tags/lab/">Lab</a> <a class="post-tag" href="/tags/cyberattacktools/">CyberAttackTools</a> <a class="post-tag" href="/tags/gcp/">GCP</a> <a class="post-tag" href="/tags/sysadmin/">Sysadmin</a> <a class="post-tag" href="/tags/java/">Java</a> <a class="post-tag" href="/tags/network/">Network</a> <a class="post-tag" href="/tags/soc/">SOC</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Kafka/"><div class="card-body"> <span class="timeago small" >Feb 11, 2020<i class="unloaded">2020-02-11T10:11:11-05:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ELK - Kafka</h3><div class="text-muted small"><p> Kafka Kafka Monitoring Kafka Kafka Monitoring Prometheus: A Time Series database Custom JMX exporters Grafana: A Data Visualization application Built in domain...</p></div></div></a></div><div class="card"> <a href="/posts/Prometheus/"><div class="card-body"> <span class="timeago small" >Feb 11, 2020<i class="unloaded">2020-02-11T10:11:11-05:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ELK - Prometheus</h3><div class="text-muted small"><p> Prometheus 主要的特色 kafka with Prometheus Prometheus架构剖析 pull vs push Job/Exporter Telegraf ...</p></div></div></a></div><div class="card"> <a href="/posts/API-Gateway/"><div class="card-body"> <span class="timeago small" >Feb 11, 2020<i class="unloaded">2020-02-11T10:11:11-05:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>AWS - VPC Gateway - API Gateway</h3><div class="text-muted small"><p> API Gateway background basic 安全性（身份验证和潜在的授权） 开源 APIGateway 单节点 API 网关 Backends for frontends 网关 AWS API Gateway Ali API Gateway ba...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/OWASP10andCWE25/" class="btn btn-outline-primary" prompt="Older"><p>OWASP top 10, CWE top 25 and SANS 25</p></a> <a href="/posts/Kafka/" class="btn btn-outline-primary" prompt="Newer"><p>ELK - Kafka</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/ocholuo">Grace JyL</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/aws/">AWS</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/cyberattack/">CyberAttack</a> <a class="post-tag" href="/tags/lab/">Lab</a> <a class="post-tag" href="/tags/cyberattacktools/">CyberAttackTools</a> <a class="post-tag" href="/tags/gcp/">GCP</a> <a class="post-tag" href="/tags/sysadmin/">Sysadmin</a> <a class="post-tag" href="/tags/java/">Java</a> <a class="post-tag" href="/tags/network/">Network</a> <a class="post-tag" href="/tags/soc/">SOC</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://ocholuo.github.io/{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-179830187-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-179830187-1'); }); </script>
