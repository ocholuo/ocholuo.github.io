<!DOCTYPE html><html lang="en" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://myochosite-291718.appspot.com/query?id=ahNwfm15b2Nob3NpdGUtMjkxNzE4chULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="FB Trino" /><meta property="og:locale" content="en" /><meta name="description" content="FB - Trino (Presto) basic 背景及发展 特点 架构 Presto 服务进程 Presto 模型 Presto 查询执行模型 Presto/trino数据可视化查询 应用场景 安装和配置 Presto 编译 服务端部署 Presto CLI 简单 SQL 语法 安装trino 下载trino Java运行时要求 Python版本要求 开始安装 创建trino用户 配置trino用户打开的文件 上传并解压Zulu JDK 上传并解压trino安装包 配置trino 创建配置目录 配置节点属性 配置JVM 配置trino服务器 配置日志级别 配置trino catalog 分发配置 修改node2、node3配置 启动、关闭trino 安装trino cli客户端 下载trino cli 设置执行权限 启动客户端 webui 使用Trino 连接MySQL 创建MySQL对应的catalog 重启trino 启动客户端 执行查询 配置Hive connector 启动 测试 将MySQL数据导入到Hive 执行导入 执行关联查询 连接Kafka 启动Kafka Kafka Connector 测试" /><meta property="og:description" content="FB - Trino (Presto) basic 背景及发展 特点 架构 Presto 服务进程 Presto 模型 Presto 查询执行模型 Presto/trino数据可视化查询 应用场景 安装和配置 Presto 编译 服务端部署 Presto CLI 简单 SQL 语法 安装trino 下载trino Java运行时要求 Python版本要求 开始安装 创建trino用户 配置trino用户打开的文件 上传并解压Zulu JDK 上传并解压trino安装包 配置trino 创建配置目录 配置节点属性 配置JVM 配置trino服务器 配置日志级别 配置trino catalog 分发配置 修改node2、node3配置 启动、关闭trino 安装trino cli客户端 下载trino cli 设置执行权限 启动客户端 webui 使用Trino 连接MySQL 创建MySQL对应的catalog 重启trino 启动客户端 执行查询 配置Hive connector 启动 测试 将MySQL数据导入到Hive 执行导入 执行关联查询 连接Kafka 启动Kafka Kafka Connector 测试" /><link rel="canonical" href="https://ocholuo.github.io//posts/Trino/" /><meta property="og:url" content="https://ocholuo.github.io//posts/Trino/" /><meta property="og:site_name" content="Grace" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-11-11T10:11:11-05:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="FB Trino" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-10-30T21:02:21-04:00","datePublished":"2020-11-11T10:11:11-05:00","description":"FB - Trino (Presto) basic 背景及发展 特点 架构 Presto 服务进程 Presto 模型 Presto 查询执行模型 Presto/trino数据可视化查询 应用场景 安装和配置 Presto 编译 服务端部署 Presto CLI 简单 SQL 语法 安装trino 下载trino Java运行时要求 Python版本要求 开始安装 创建trino用户 配置trino用户打开的文件 上传并解压Zulu JDK 上传并解压trino安装包 配置trino 创建配置目录 配置节点属性 配置JVM 配置trino服务器 配置日志级别 配置trino catalog 分发配置 修改node2、node3配置 启动、关闭trino 安装trino cli客户端 下载trino cli 设置执行权限 启动客户端 webui 使用Trino 连接MySQL 创建MySQL对应的catalog 重启trino 启动客户端 执行查询 配置Hive connector 启动 测试 将MySQL数据导入到Hive 执行导入 执行关联查询 连接Kafka 启动Kafka Kafka Connector 测试","headline":"FB Trino","mainEntityOfPage":{"@type":"WebPage","@id":"https://ocholuo.github.io//posts/Trino/"},"url":"https://ocholuo.github.io//posts/Trino/"}</script><title>FB Trino | Grace</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Grace"><meta name="application-name" content="Grace"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://myochosite-291718.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://myochosite-291718.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/huoye.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Grace</a></div><div class="site-subtitle font-italic">2023 Mar 14 updated</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/ocholuo" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['',''].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>FB Trino</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>FB Trino</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Grace JyL </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Nov 11, 2020, 10:11 AM -0500" >Nov 11, 2020<i class="unloaded">2020-11-11T10:11:11-05:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sun, Oct 30, 2022, 6:02 PM -0700" >Oct 30, 2022<i class="unloaded">2022-10-30T21:02:21-04:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="10739 words">59 min read</span> <span id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </span> views</div></div><div class="post-content"><ul><li><a href="#fb---trino-presto">FB - Trino (Presto)</a><ul><li><a href="#basic">basic</a><li><a href="#背景及发展">背景及发展</a><li><a href="#特点">特点</a><li><a href="#架构">架构</a><ul><li><a href="#presto-服务进程">Presto 服务进程</a><li><a href="#presto-模型">Presto 模型</a><li><a href="#presto-查询执行模型">Presto 查询执行模型</a><li><a href="#prestotrino数据可视化查询">Presto/trino数据可视化查询</a></ul><li><a href="#应用场景">应用场景</a><li><a href="#安装和配置-presto">安装和配置 Presto</a><ul><li><a href="#编译">编译</a><li><a href="#服务端部署">服务端部署</a><li><a href="#presto-cli">Presto CLI</a><li><a href="#简单-sql-语法">简单 SQL 语法</a></ul></ul><li><a href="#安装trino">安装trino</a><ul><li><a href="#下载trino">下载trino</a><ul><li><a href="#java运行时要求">Java运行时要求</a><li><a href="#python版本要求">Python版本要求</a></ul><li><a href="#开始安装">开始安装</a><ul><li><a href="#创建trino用户">创建trino用户</a><li><a href="#配置trino用户打开的文件">配置trino用户打开的文件</a><li><a href="#上传并解压zulu-jdk">上传并解压Zulu JDK</a><li><a href="#上传并解压trino安装包">上传并解压trino安装包</a><li><a href="#配置trino">配置trino</a><ul><li><a href="#创建配置目录">创建配置目录</a><li><a href="#配置节点属性">配置节点属性</a><li><a href="#配置jvm">配置JVM</a><li><a href="#配置trino服务器">配置trino服务器</a></ul><li><a href="#配置日志级别">配置日志级别</a><ul><li><a href="#配置trino-catalog">配置trino catalog</a></ul><li><a href="#分发配置">分发配置</a><li><a href="#修改node2node3配置">修改node2、node3配置</a><li><a href="#启动关闭trino">启动、关闭trino</a></ul><li><a href="#安装trino-cli客户端">安装trino cli客户端</a><ul><li><a href="#下载trino-cli">下载trino cli</a><li><a href="#设置执行权限">设置执行权限</a><li><a href="#启动客户端">启动客户端</a><li><a href="#webui">webui</a></ul><li><a href="#使用trino">使用Trino</a><ul><li><a href="#连接mysql">连接MySQL</a><ul><li><a href="#创建mysql对应的catalog">创建MySQL对应的catalog</a><li><a href="#重启trino">重启trino</a><li><a href="#启动客户端-1">启动客户端</a><li><a href="#执行查询">执行查询</a><li><a href="#配置hive-connector">配置Hive connector</a><li><a href="#启动">启动</a><li><a href="#测试">测试</a></ul><li><a href="#将mysql数据导入到hive">将MySQL数据导入到Hive</a><ul><li><a href="#执行导入">执行导入</a><li><a href="#执行关联查询">执行关联查询</a></ul><li><a href="#连接kafka">连接Kafka</a><ul><li><a href="#启动kafka">启动Kafka</a><li><a href="#kafka-connector">Kafka Connector</a><li><a href="#测试-1">测试</a></ul></ul></ul><li>ref<ul><li>https://www.gairuo.com/p/trino-presto<li>https://miaowenting.site/2021/03/04/初识Presto(Trino)/</ul></ul><hr /><h1 id="fb---trino-presto">FB - Trino (Presto)</h1><hr /><h2 id="basic">basic</h2><p>Presto</p><ul><li>一个 facebook 开源的分布式 SQL 查询引擎<ul><li>基于 SQL 进行大数据分析的高性能分布式计算引擎<li>主要用来以解决 Facebook 海量 Hadoop 数据仓库的低延迟交互分析问题</ul><li>为了 <strong>高效查询</strong> <code class="language-plaintext highlighter-rouge">不同系统和各种规模的数据源</code> 而从头开始设计和编写的一套系统。<ul><li>尽管数据库的操作都大同小异，但每个数据库的操作都各不相同。<ul><li>这就导致开发者不得不学习无数种操作数据库的方式，很多时间被浪费在学习不同数据库的操作。<li>这往往导致开发者疲于拼命，没有足够的时间来提升自己的开发效率。<li>于是一个可以统一操作不同数据库的软件就是大势所趋了。</ul><li><p>最开始是用来解决Hive速度慢以及异构数据源互通的问题。</p><li><p>它在大数据家族中属于MPP（massive parallel processing）计算引擎范畴</p><li>其原理是火山（volcano）模型：<ul><li>将SQL抽象成一个个算子（operator），形成管线（pipeline）。<li>目前能够支持 Hive、HBase、ES、Kudu、Kafka、MySQL、Redis、ElasticSearch等 等几十种数据源的读取。</ul></ul><li>适用于交互式分析查询，数据量支持 GB 到 PB 字节。<li>Presto 的架构由关系型数据库的架构演化而来。<li><p>它是 hadoop 生态中著名的分布式 SQL 引擎。</p><li>2019年原作者从 Facebook 分道扬镳更名 Trino。<ul><li>由于开源纷争，Presto 现已更名为 Trino。</ul></ul><p>SQL 查询引擎？而不是数据库？</p><ul><li>和Oracle、MySQL、Hive等数据库相比，他们都具有存储数据和计算分析的能力。<li>如MySQL具有InnoDB存储引擎和有SQL的执行能力；<li>如Hive有多种数据类型、内外表（且这么叫）的管理能力，且能利用MR、TEZ执行HQL。<li>而Presto并不直接管理数据，它只有计算的能力。</ul><p>Presto</p><ul><li>支持从多种数据源获取数据来进行运算分析<li>一条SQL查询可以将多个数据源的数据进行合并分析。</ul><p>比如下面的SQL：a可以来源于MySQL，b可以来源于Hive。</p><div class="language-sql highlighter-rouge"><div class="code-header" text-data="sql"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">select</span> <span class="n">a</span><span class="p">.</span><span class="o">*</span><span class="p">,</span><span class="n">b</span><span class="p">.</span><span class="o">*</span>
<span class="k">from</span> <span class="n">a</span> <span class="k">join</span> <span class="n">b</span> <span class="k">on</span> <span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">b</span><span class="p">.</span><span class="n">id</span><span class="p">);</span>
</pre></table></code></div></div><hr /><h2 id="背景及发展">背景及发展</h2><p>MapReduce</p><ul><li>不能满足大数据快速实时 adhoc（即席查询）查询计算的性能要求。<ul><li>Hadoop 提供的大数据解决方案使用的是 MR 计算框架<li>这种计算框架适用于<code class="language-plaintext highlighter-rouge">大数据的离线和批量计算</code><li>因为该计算框架强调的是<code class="language-plaintext highlighter-rouge">吞吐率</code>而不是<code class="language-plaintext highlighter-rouge">计算效率</code>，所以其不能满足大数据快速实时 Ad-Hoc 查询计算的性能要求。</ul></ul><p>因此，开源社区和各大互联网公司纷纷进行大数据实时 Ad-Hoc 查询计算产品的研发</p><p>Presto 最初是由 Facebook 开发的一个分布式 SQL 执行引擎，</p><ul><li>它被设计为用来专门进行高速、实时的数据分析，以弥补 Hive 在<code class="language-plaintext highlighter-rouge">速度</code>和<code class="language-plaintext highlighter-rouge">对接多种数据源</code>上的短板。<li>Facebook 于2012年秋季开始开发 Presto，目前该产品已经在超过 1000 名 Facebook 雇员中使用，每天运行超过 30000 个查询，每日查询数据量在 1PB 级别。<li>Facebook 称 Presto 的性能比 Hive 要好上 10 倍还多，2013年 Facebook 正式宣布开源 Presto。</ul><p>Facebook 2012年开发，2013 年开源。发展历史如下：</p><ul><li>2012年秋季，Facebook启动Presto项目；<li>2013年冬季，Presto 开源；<li>2017年11月，11888 commits，203 releases，198 contributors；<li>2019年1月，Presto 分家，目前有 <code class="language-plaintext highlighter-rouge">PrestoDB</code> 和 <code class="language-plaintext highlighter-rouge">PrestoSQL（更名为 trino）</code> 两个社区。<ul><li>Presto 团队的三位创始人离开了 Facebook。<li>从此，Presto 项目被一分为二，<li>由 Facebook 维护 PrestoDB，<li>Martin、Dain、David 三位 Presto 项目最早的发起人维护 PrestoSQL。</ul></ul><p>两个社区：</p><ul><li>PrestoDB：https://prestodb.io，面向大数据的分布式 SQL 查询引擎<li>trino：<a href="https://trino.io">trino</a>，PrestoSQL，一个速度不可置信的查询引擎</ul><hr /><h2 id="特点">特点</h2><p>Presto有如下特点：</p><ul><li>基于SQL语言，上手成本低，而且功能强大，支持reduce和lambda函数；<li>纯计算引擎，解耦底层存储，可快速缩扩容；<li>纯内存计算，速度快，提供交互式的查询体验；<li>通过插件的方式实现拓展功能，二次开发友好；<li>通过不同的连接器（connector）插件读取异构数据源，进行联邦查询。</ul><p>另外还有以下特点：</p><ul><li><strong>快速查询</strong><ul><li>Trino是一个并行执行、分布式的查询引擎，通过Trino可以构建高效、低延迟的分析系统。</ul><li><strong>大规模部署</strong><ul><li>基于Trino可以查询EB级的数据湖、以及海量数据仓库。</ul><li><strong>就地分析</strong><ul><li>不需要复制数据，直接在hadoop、s3、cassandra、mysql等本地直接分析。</ul><li><strong>Runs anywhere</strong><ul><li>可以将Trino部署在本地集群、或者是云环境。</ul><li><strong>多数据源</strong>：<ul><li>支持众多常见的数据源，<li>目前 Presto 可以支持 Mysql、PostgreSql、Cassandra、Hive、Kafka、JMX、Iceberg 等多种 Connector，并且可以支持分库分表以及快速读取的功能。</ul><li><strong>混合计算</strong><ul><li>并且可以进行混合计算分析；<li>每种类型的数据源都对应于一种特定类型的 Connector，<li>用户可以根据业务需要在 Presto 中针对于一种类型的 Connector 配置一个或多个 Catalog 并查询其中的数据，<li>用户可以混合多个 Catalog 进行 join 查询和计算。</ul><li><strong>支持 SQL</strong><ul><li>Presto 已经可以完全支持 ANSI SQL<li>并提供了一个 SQL Shell 给用户，用户可以直接使用 ANSI SQL 进行数据查询和计算。</ul><li><strong>大数据</strong>：<ul><li>完全的内存计算<li>支持的数据量完全取决于集群内存大小。<li>不像SparkSQL可以配置把溢出的数据持久化到磁盘，Presto是完完全全的内存计算；</ul><li><strong>高性能</strong>：<ul><li>低延迟高并发的内存计算引擎，<li>相比Hive（无论MR、Tez、Spark执行引擎）、Impala 执行效率要高很多。<li>根据Facebook的测试报告，至少提升10倍以上；<li>经过 Facebook 和 京东商城的测试，Presto 的查询平均性能是 Hive 的10倍以上。</ul><li><strong>支持ANSI SQL</strong>：<ul><li>这点不像Hive、SparkSQL都是以HQL为基础，<li>Presto是标准的SQL。<li>用户可以使用标准SQL进行数据查询和分析计算；</ul><li><strong>扩展性</strong>：<ul><li>有众多SPI扩展点支持，开发人员可编写UDF、UDTF。<li>甚至可以实现自定义的Connector，实现索引下推，借助外置的索引能力，实现特殊场景下的MPP；</ul><li><strong>流水线</strong>：<ul><li>Presto是基于PipeLine进行设计<li>在大量数据计算过程中，终端用户（Driver）无需等到所有数据计算完成才能看到结果。<li>一旦开始计算就可立即产生一部分结果返回，后续的计算结果会以多个Page返回给终端用户（Driver）。<li>一旦开始计算，就可以立即产生一部分结果数据，并且结果数据会一部分接一部分地呈现在终端客户面前。</ul></ul><hr /><h2 id="架构">架构</h2><p>Trino</p><ul><li>是典型的 MPP 架构<li>由一个 Coordinator 和多个 Worker 组成 Trino集群<li>Coordinator 负责 SQL 的解析和调度<li>Worker 负责任务的具体执行。<li>可配置多个不同类型的 Catalog，实现对多个数据源的访问。</ul><p><img data-proofer-ignore data-src="https://i.imgur.com/Im4ZztF.png" alt="Screen Shot 2022-04-17 at 16.40.10" /></p><p><img data-proofer-ignore data-src="https://i.imgur.com/QNUwxmu.png" alt="modb_20211014_afe63b60-2cfe-11ec-9441-fa163eb4f6be" /></p><p>Presto 在整体业务中的架构图如下：</p><p><img data-proofer-ignore data-src="https://i.imgur.com/VOTGZH4.png" alt="Screen Shot 2022-04-18 at 00.07.58" /></p><p>原生容器类型（Native container type）</p><ul><li>presto架构的类型框架会自动将 SQL 中的数据类型与 “原生容器类型” （Native container type）进行绑定;<li>目前“原生容器类型”只包括：<ul><li>boolean<li>long<li>double<li>Slice<li>Block</ul></ul><hr /><h3 id="presto-服务进程">Presto 服务进程</h3><ol><li>Trino用户通过一个客户端 trino cli 连接到coordinator。<li>coordinator与访问数据源的worker进行协作。<li>一旦它接收到一条SQL语句，协调器就负责跨Trino工作节点解析、分析、计划和调度查询执行。<li>该语句被转换为运行在一组worker上的一系列连接的任务。<li>当worker处理数据时，coordinator将检索结果并在输出缓冲区上向客户机公开。</ol><p><img data-proofer-ignore data-src="https://i.imgur.com/9Ssm7h3.png" alt="trino" /></p><ul><li>Coordinator<ul><li>Coordinator 服务进程部署于集群中一个单独的节点上<li>是整个 Presto 集群的管理节点。<li>主要用于<strong>接收</strong>客户端提交的查询，<strong>查询</strong>语句解析，<strong>生成</strong>查询执行计划、Stage、Task，<strong>调度</strong>生成的Task<li>此外，Coordinator 还对集群中的所有 Worker 进行管理<li>是整个 Presto 集群的 Master 进程<ul><li>该进程既与 Worker 进行通信从而获得最新的 Worker 信息，又与 Client 进行通信，从而接收查询请求。</ul></ul><li>Worker<ul><li>在每个 Worker 节点上都存在一个 Worker 服务进程<li>主要进行数据的处理以及 Task 的执行。<li>Worker 进程 每隔一定的时间会向 Coordinator 上的 restful 服务 发送心跳。<li>当客户端提交一个查询时，Coordinator 则会从当前存活的 Worker 列表中选择出合适的 Worker 节点去运行 Task。<li>Worker 在执行每个 Task 时会进一步对当前 Task 读入的每个 Split 进行一系列的操作和处理。</ul></ul><hr /><h3 id="presto-模型">Presto 模型</h3><div class="table-wrapper"><table><tbody><tr><td>![https-_<td>__<td><em>mmbiz.qpic.cn</em><td><em>mmbiz_png</em><td><em>6ic9JdlNtEvr6ibm4K1Px0wVUWhK4rLhMpB49jicIfrsBpGNVRdNibF3ugqcwhhuWtJomqLGZnbeiaLjqzhGic2K0WnA</em><td>_640?wx_fmt=png](https://i.imgur.com/1pk4FYt.png)</table></div><ul><li>Connector<ul><li>使 Presto 适配一个数据源<li>每一个 Catalog 对应于一个特定的连接器。<li>在Trino中，存储和计算分离的核心是基于connector的体系结构。<li>connector为Trino提供了访问任意数据源的接口。<li>每个connector都提供了对底层数据源的基于表的抽象。<li>只要可以使用Trino可用的数据类型以表、列和行来表示数据，就可以创建connector，查询引擎就可以使用数据进行查询处理。<li>目前支持的connector包括：Hive, Iceberg, MySQL, PostgreSQL, Oracle, SQL Server, ClickHouse, MongoDB等。</ul><li>Catalog<ul><li>定义连接到一个数据源的细节<li>它包含了 Schema 并配置了一个连接器来使用。</ul><li>Schema<ul><li>组织表的一种方式。<li>Catalog 和 Schema 一起定义了一个集合的表，这些表可以查询。</ul><li>Table<ul><li>表是无序的行的集合。<li>这些行内容被组织成带有数据类型的有名称的列。</ul></ul><hr /><h3 id="presto-查询执行模型">Presto 查询执行模型</h3><p>在 Presto 中一次查询执行会被分解为多个 Stage</p><ul><li>Stage 与 Stage 之间是有前后依赖关系的。<li>每个 Stage 内部又会被分解为多个 Task，属于每个 Stage 的 Task 被均分在每个 Worker 上并行执行。<li>在每个 Task 内部又会被分解为多个 Driver ，每个 Driver 负责处理一个 Split<li><p>而且每个 Driver 由一系列前后相连的 Operator 组成，这里的每个 Operator 都代表针对于一个 Split 的操作。</p><li>Statement 语句<ul><li>终端用户输入的用文字表示的 SQL 语句，<li>由子句（Clause）、表达式（Expression）和断言（Predicate）组成。</ul><li>Query 查询执行。<ul><li>当 Presto 接收一个 SQL 语句并执行时，会解析该 SQL 语句，将其转变成一个查询执行和相关的查询执行计划。<li>一个查询执行代表可以在 Presto 集群中运行的查询，是由运行在各个 Worker 上且各自之间相互关联的阶段（Stage）组成的。<li>查询执行是为了完成 SQL 语句所表述的查询而实例化的配置信息、组件、查询执行计划和优化信息等。<li>一个查询执行由 Stage、Task、Driver、Split、Operator 和 DataSource 组成，</ul><li>Stage 查询执行阶段。<ul><li>当 Presto 运行 Query 时，Presto 会将一个 Query 拆分成具有层级关系的多个 Stage<li>一个 Stage 就代表查询计划的一部分。</ul><li>Exchange<ul><li>Presto 的 Stage 是通过 Exchange 来连接另一个 Stage 的<li>Exchange 用于完成有上下游关系的 Stage 之间的数据交换。</ul><li>Task<ul><li>Stage 并不会在 Presto 集群中实际运行，仅代表针对于一个 SQL 语句查询执行计划中的一部分查询的执行过程，只是用来对查询执行计划进行管理和建模。<li>Stage 在逻辑上又被分为一系列的 Task，这些 Task 则需要实际运行在 Presto 的各个 Worker 节点上。</ul><li>Driver<ul><li>一个 Task 包含一个或多个 Driver。<li>一个 Driver 其实就是作用于一个 Split 的一系列 Operator 的集合。<li>因此一个 Driver 用于处理一个 Split，并且生成相应的输出，这些输出由 Task 收集并传送给下游 Stage 中的一个 Task。<li>一个 Driver 拥有一个输入和一个输出。</ul><li>Operator<ul><li>一个 Operator 代表一个 Split 的一种操作，例如过滤、加权、转换等。<li>一个 Operator 依次读取一个 Split 中的数据，将 Operator 所代表的计算和操作作用于 Split 的数据上，并产生输出。<li>每个 Operator 均会以 Page 为最小处理单位分别读取输入数据和产生输出数据。<li>Operator 每次只会读取一个 Page 对象，相应地，每次也只会产生一个 Page 对象。</ul><li>Split 分片<ul><li>一个分片是一个大的数据集中的一个小的子集。<li>而 Driver 则是作用于一个分片上的一系列操作的集合，而每个节点上运行的 Task，又包含多个 Driver，从而一个 Task 可以处理多个 Split。</ul><li>Page<ul><li>Page 是 Presto 中处理的最小数据单元。一个 Page 对象包含多个 Block 对象，每个 Block 对象是一个字节数组，存储一个字段的若干行。<li>多个 Block 横切的一行是真实的一行数据。<li>一个 Page 最大为 1MB ，最多 16 * 1024 行数据。</ul></ul><hr /><h3 id="prestotrino数据可视化查询">Presto/trino数据可视化查询</h3><p><code class="language-plaintext highlighter-rouge">Airpal</code>是建立在Facebook的Prestodb上的一个可视化分布式SQL查询引擎。https://github.com/airbnb/airpal，目前已经归档，大部分功能转移到superset。</p><p>Apache Superset是Airbnb开源的数据挖掘平台。支持丰富的数据源连接，多种可视化方式，并能够对用户实现细粒度的权限控制。该工具主要特点是可自助分析、自定义仪表盘、分析结果可视化（导出）、用户/角色权限控制，还集成了一个SQL编辑器，可以进行SQL编辑查询等。支持的数据源：,Amazon Athena ,Amazon Redshift ,Apache Drill ,Apache Druid ,Apache Hive ,Apache Impala ,Apache Kylin ,Apache Pinot ,Apache Solr ,Apache Spark SQL ,Ascend.io ,Azure MS SQL ,Big Query ,ClickHouse ,CockroachDB ,Dremio ,Elasticsearch ,Exasol ,Google Sheets ,Firebolt ,Hologres ,IBM Db2 ,IBM Netezza Performance Server ,MySQL ,Oracle ,PostgreSQL ,Trino ,Presto ,SAP Hana ,Snowflake ,SQLite ,SQL Server ,Teradata ,Vertica</p><hr /><h2 id="应用场景">应用场景</h2><p>常见以下场景：</p><ul><li>实时计算：<ul><li>Trino（Presto）性能优越，实时查询工具上的重要选择。</ul><li>Ad-Hoc查询：<ul><li>数据分析应用、Trino（Presto）根据特定条件的查询返回结果和生成报表。</ul><li>ETL：<ul><li>因支持的数据源广泛、可用于不同数据库之间迁移，转换和完成ETL清洗的能力。</ul><li>实时数据流分析：<ul><li>Presto-Kafka Connector 使用 SQL对Kafka的数据流进行清洗、分析。</ul><li>MPP：<ul><li>Presto Connector有非常好的扩展性，可进行扩展开发，可支持其他异构非SQL查询引擎转为SQL，支持索引下推。</ul><li>单一的 SQL 分析访问点<ul><li>作为一个消费者和分析师，你可能会遇到数不清的问题：<ul><li>甚至不知道数据在哪儿，只有凭借公司某个部门的内部知识或者组织内多年的工作经验，你才能找到正确的数据。<li>为了查询多个数据库，需要使用不同的连接和运行多种 SQL 方言的不同查询。<li>这些查询看起来相似，行为上却不同。<li>若不使用数据仓库，就无法使用查询合并来自不同系统的数据。</ul><li>可以使用 Presto 对接这些数据库，使用一个 SQL 标准来查询所有的系统。<ul><li>所有的仪表盘和分析工具以及其他商业智能系统都可以指向一个系统 – Presto，并访问组织当中的所有数据。</ul></ul><li>数据仓库和数据源系统的访问点<ul><li>当一个组织需要更好的理解和分析存放在无数 RDBMS 中的数据时，就可以创建和维护<strong>数据仓库系统</strong>。<ul><li>从多个系统中抽取的数据通过一个复杂的 ETL 过程，最终进入一个严格受控的、巨大的数据仓库。</ul><li>尽管数据仓库在很多情况下非常有用，但作为一个数据分析师，你会面临很多新问题：<ul><li>除了原来的那些数据库，你的工具和查询现在又多了一个数据接入点。<li>你今天就要用的数据还没放入数据仓库。加载数据的过程痛苦、昂贵又困难重重重。</ul><li>Presto 允许添加任何数据仓库作为数据源，就像其他关系数据库一样。<ul><li>如果想深入研究数据仓库的查询，可以在 Presto 里直接完成，也可以在这里访问数据仓库及其源数据库系统，甚至可以编写将它们组合在一起查询。</ul></ul><li>提供对任何内容的 SQL 访问<ul><li>Presto 允许将所有支持的系统作为数据源进行连接。它使用标准的 ANSI SQL 和使用 SQL 的所有工具对外暴露要查询的数据。</ul><li>联邦查询<ul><li>将所有的数据孤岛都暴露给 Presto 是向理解数据迈出的一大步。<li>可以使用 SQL 和标准工具来联邦查询所有内容。<li>在一个语句中引用并使用不同数据库和模式的 SQL 查询，这些数据库和 Schema 来自于完全不同的系统。<li>在同一条 SQL 查询中，可以查询 Presto 中可用的所有数据源。</ul><li><p>虚拟数据仓库的语义层</p><ul><li><p>数据仓库系统为用户创造了巨大的价值，对组织来说确实一个负担。</p><ul><li>运行和维护数据仓库是一个巨大且昂贵的项目。<li>需要专门的团队运行与管理数据仓库和相关的 ETL 过程。<li>将数据导入数据仓库需要用户执行繁琐的操作，并且通常非常耗时。</ul><li><p>Presto 可用作虚拟仓库。</p><ul><li>使用这一工具和标准的 ANSI SQL ，就可以定义语义层。<li>一旦所有的数据库都设置成 Presto 的数据源，就可以直接查询它们。<li>Presto 提供了查询这些数据库所需的计算能力。<li>使用 SQL 和 Presto 支持的函数和运算符，可以直接从数据源获得想要的数据。<li>在使用数据进行分析之前，无需复制、移动或转换它们。</ul></ul><li>数据湖查询引擎<ul><li>在数据被存储到数据湖的存储系统时，并没有特别考虑接下来应该如何访问它们，Presto 可以使它们成为有用的数据仓库。<li>现代数据湖通常使用 HDFS 以外的其他对象存储系统，这些系统来自云供应商或其他开源项目。<li>Presto 能使用 Hive 连接器连接它们，无论数据在哪里、如何存储，都可以在数据湖上使用基于 SQL 的数据分析。</ul><li>Interactive Analytics（交互式分析）<ul><li>Facebook内运行着一个庞大的多租户数据仓库，一些业务部门或个别团队会共享其中一小部分托管的集群。<li>其数据存储在一个分布式文件系统之上，而元数据则存储在单独的服务中，这些系统分别具有HDFS和Hive Metastore服务类似的API。<li>我们称之为’Facebook data warehouse’，并且通过类似于Presto ‘Hive’ Connector的组件来进行文件的读写。<li>Facebook的工程师和数据科学家经常会检索少量的数据(50GB-3TB的压缩数据)，用来验证假设，并构建可视化的数据展板。<li>这些用户通常会使用查询工具、BI工具或Jupyter notebooks来进行查询操作。<li>各个群集需要支持50-100个具有各种查询模型的操作并发执行，并且需要在数秒或数分钟内返回结果。<li>这些用户通常并不关心查询所使用到的硬件资源，但是对查询时间却相当敏感。<li>而对于某些探索性的查询，用户可能并不需要获取所有的查询结果。<li>通常在返回初始结果后，查询就会被立即取消或者用户会通过LIMIT来限制系统返回的结果。</ul><li>SQL 转换和 ETL<ul><li>Presto 也可用于迁移数据，它所提供的丰富的 SQL 函数，可以查询数据，转换数据，并将数据写入同一个数据源或任何其他数据源。<li>因支持的数据源广泛、可用于不同数据库之间迁移，转换和完成ETL清洗的能力。</ul><li>Batch ETL （批量ETL）<ul><li>上面我们介绍到的数据仓库会使用ETL查询任务定期填充新的数据。<li>查询任务通常是通过一个工作流系统依次调度执行的。<li>Presto支持用户从历史遗留的批处理系统迁移ETL任务，目前ETL查询任务在Facebook的Presto工作负载中占了很大一部分。<li>这些查询通常是由数据工程师开发并优化的。<li>相对于Interactive Analytics中涉及的查询，它们通常会占用更多的硬件资源，并且会涉及大量的CPU转换和内存（通常是数TB的分布式内存）密集型的聚合操作以及与其他的大表连接操作。<li>因此相对于资源利用率以及集群吞吐量来说，查询延迟显得没那么重要。</ul><li>更快的响应带来更好的数据见解<ul><li>复杂的问题和海量数据集带来了诸多限制。<ul><li>将数据复制并加载到数据仓库并在其中分析它们的整个过程会过于昂贵。<li>计算可能消耗太多的计算资源而无法处理全部数据，或者要消耗数天才能得到答案。</ul><li>Presto 一开始就<strong>避免了数据复制</strong>。<li>Presto 的<code class="language-plaintext highlighter-rouge">并行计算</code>和<code class="language-plaintext highlighter-rouge">重度优化</code>通常能为数据分析带来性能提升。<li>如果原来需要 3 天的查询现在只需要 15 分钟就可以完成，那么执行这个查询便是有价值的。<li>从这些结果中获得的知识可以执行更多的查询。</ul><li>A/B Testing （A/B测试）<ul><li>Facebook使用A/B测试，通过统计假设性的测试来评估产品变更带来的影响。<li>在Facebook大量的A/B测试的基础架构是基于Presto构建的。<li>用户期望测试结果可以在数小时之内呈现（而不是数天），并且结果应该是准确无误的。<li>对于用户来说，能够在交互式延迟的时间内（5~30s），对结果数据进行任意切分来获得更深入的见解同样重要。<li>而通过预处理来聚合这些数据往往很难满足这一需求，因此必须得实时进行计算。<li>生成这样的结果需要关联多个大型数据集，包括用户、设备、测试以及事件属性等数据。<li>由于查询是通过编程方式实现的，所以查询需要被限制在较小的集合内。</ul><li>Developer/Advertiser Analytics（开发者/广告主分析）<ul><li>为外部开发者和广告客户提供的几种自定义报表工具也都是基于Presto构建的。<li>Facebook Analytics就是其中一个实际案例，它为使用Facebook平台构建应用程序的开发人员提供了高级的分析工具。<li>这些工具通常对外开放一个Web界面，该界面可以生成一组受限的查询模型。<li>查询需要聚合的数据量是非常大的，但是这些查询是有目的性的，因为用户只能访问他们的应用程序或广告的数据。<li>大部分的查询包括连接、聚合以及窗口函数。<li>由于这些工具是交互式的，因此有非常严格的时间限制（约50ms~5s）。<li>鉴于用户的数量，集群需要达到99.999%的可用性，并且支持数百个并发查询。</ul></ul><hr /><h2 id="安装和配置-presto">安装和配置 Presto</h2><h3 id="编译">编译</h3><p>mvn -T2C install -DskipTests</p><h3 id="服务端部署">服务端部署</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
</pre><td class="rouge-code"><pre><span class="c"># - 从编译后的源码中拷贝jar和配置文件</span>
<span class="nb">mkdir</span> /usr/local/presto

<span class="nb">cp</span> <span class="nt">-r</span> ～workspace/presto/presto-server/target/presto-server-0.255-SNAPSHOT /usr/local/presto

<span class="nb">cd</span> /usr/local/presto/presto-server-0.255-SNAPSHOT

<span class="nb">cp</span> ～workspace/presto/presto-server/target/presto-main/etc ./presto-server-0.255-SNAPSHOT/

<span class="nb">ln</span> <span class="nt">-s</span> presto-server-0.255-SNAPSHOT server


<span class="c"># - 设置环境变量</span>
vim /etc/profile

<span class="nb">export </span><span class="nv">PRESTO_SERVER_HOME</span><span class="o">=</span>/usr/local/presto/server
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$PRESTO_SERVER_HOME</span>/bin

<span class="nb">source</span> /etc/profile



<span class="c"># - 修改 config.properties</span>
<span class="nv">coordinator</span><span class="o">=</span><span class="nb">true
</span>node-scheduler.include-coordinator<span class="o">=</span><span class="nb">true
</span>http-server.http.port<span class="o">=</span>8086
discovery-server.enabled<span class="o">=</span><span class="nb">true
</span>discovery.uri<span class="o">=</span>http://localhost:8086


<span class="c"># - 修改 node.properties</span>
node.id<span class="o">=</span>562e42e2-e874-431f-8da5-cb779744cf7c
node.data-dir<span class="o">=</span>/usr/local/presto/data
catalog.config-dir<span class="o">=</span>/usr/local/presto/server/etc/catalog
plugin.dir<span class="o">=</span>/usr/local/presto/server/plugin
node.server-log-file<span class="o">=</span>/usr/local/presto/server/var/log/server.log
node.launcher-log-file<span class="o">=</span>/usr/local/presto/server/var/log/launcher.log

<span class="c"># - 修改 jvm.config</span>
<span class="se">\-</span>server
<span class="se">\-</span>Xmx4G
<span class="se">\-</span>XX:-UseBiasedLocking
<span class="se">\-</span>XX:+UseG1GC
<span class="se">\-</span>XX:+ExplicitGCInvokesConcurrent
<span class="se">\-</span>XX:+HeapDumpOnOutOfMemoryError
<span class="se">\-</span>XX:+UseGCOverheadLimit
<span class="se">\-</span>XX:+ExitOnOutOfMemoryError
<span class="se">\-</span>XX:ReservedCodeCacheSize<span class="o">=</span>512M

<span class="c"># - 修改 log.properties</span>
com.facebook.presto<span class="o">=</span>INFO

<span class="c"># - 后台启动</span>
<span class="nv">$PRESTO_SERVER_HOME</span>/bin/launcher start

<span class="c"># - 前台启动</span>
<span class="nv">$PRESTO_SERVER_HOME</span>/bin/launcher run

<span class="c"># [Presto Web UI] http://localhost:8086/ui/</span>
</pre></table></code></div></div><h3 id="presto-cli">Presto CLI</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
</pre><td class="rouge-code"><pre><span class="c"># - 从编译后的源码中拷贝jar</span>
<span class="nb">cd</span> /usr/local/presto

<span class="nb">mkdir</span> <span class="nt">-p</span> cli/lib

<span class="nb">cp</span> ～workspace/presto/presto-cli/target/presto-cli-0.255-SNAPSHOT-executable.jar /usr/local/presto/cli/lib

<span class="nb">cd</span> /usr/local/presto/cli/lib

<span class="nb">mv </span>presto-cli-0.255-SNAPSHOT-executable.jar presto

<span class="nb">chmod</span> +x presto

<span class="c"># - 设置环境变量</span>
vim /etc/profile

<span class="nb">export </span><span class="nv">PRESTO_CLI_HOME</span><span class="o">=</span>/usr/local/presto/cli
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$PRESTO_CLI_HOME</span>/lib

<span class="nb">source</span> /etc/profile

<span class="c"># - 运行 cli 并查看其版本</span>
presto <span class="nt">--version</span>
Presto CLI 0.255-SNAPSHOT-9095346

<span class="c"># - 启动 cli</span>
presto <span class="nt">--server</span> localhost:8086

<span class="c"># - 额外诊断，打印调试信息</span>
presto <span class="nt">--debug</span>

<span class="c"># - 执行查询</span>
presto <span class="nt">--server</span> localhost:8086 <span class="se">\</span>

<span class="nt">--catalog</span> tpch <span class="se">\</span>

<span class="nt">--schema</span> sf1 <span class="se">\</span>

<span class="nt">--execute</span> <span class="s1">'select nationkey,name,regionkey from nation limit 5'</span>
<span class="c"># "0","ALGERIA","0"</span>
<span class="c"># "1","ARGENTINA","1"</span>
<span class="c"># "2","BRAZIL","1"</span>
<span class="c"># "3","CANADA","1"</span>
<span class="c"># "4","EGYPT","4"</span>
</pre></table></code></div></div><h3 id="简单-sql-语法">简单 SQL 语法</h3><ul><li>查看 catalogs</ul><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
</pre><td class="rouge-code"><pre>presto&gt; show catalogs<span class="p">;</span>
<span class="c">##   Catalog</span>

 blackhole
 druid

 example
 hive

 jmx

 localfile
 memory

 mysql

 pinot

 postgresql
 raptor

 sqlserver
 system

 tpcds

 tpch

<span class="o">(</span>15 rows<span class="o">)</span>

Query 20210606_141818_00009_4qtix, FINISHED, 1 node
Splits: 19 total, 19 <span class="k">done</span> <span class="o">(</span>100.00%<span class="o">)</span>
0:00 <span class="o">[</span>0 rows, 0B] <span class="o">[</span>0 rows/s, 0B/s]

<span class="c"># - 查看 tpch Connector 的 schemas</span>
presto&gt; show schemas from tpch<span class="p">;</span>
<span class="c">##</span>
 Schema

 information_schema
 sf1

 sf100

 sf1000

 sf10000

 sf100000

 sf300

 sf3000

 sf30000

 tiny

<span class="o">(</span>10 rows<span class="o">)</span>

Query 20210606_142008_00010_4qtix, FINISHED, 1 node
Splits: 19 total, 19 <span class="k">done</span> <span class="o">(</span>100.00%<span class="o">)</span>
0:00 <span class="o">[</span>10 rows, 119B] <span class="o">[</span>141 rows/s, 1.65KB/s]

<span class="c"># - 查看 tpch.sf1 的 tables</span>
presto&gt; show tables from tpch.sf1<span class="p">;</span>
<span class="c">##   Table</span>
 customer
 lineitem
 nation
 orders
 part

 partsupp
 region
 supplier
<span class="o">(</span>8 rows<span class="o">)</span>

Query 20210606_142111_00011_4qtix, FINISHED, 1 node
Splits: 19 total, 19 <span class="k">done</span> <span class="o">(</span>100.00%<span class="o">)</span>
0:00 <span class="o">[</span>8 rows, 158B] <span class="o">[</span>85 rows/s, 1.66KB/s]

<span class="c"># - 查看 tpch.sf1.nation 表中的实际数据</span>
presto&gt; <span class="k">select </span>count<span class="o">(</span>name<span class="o">)</span> from tpch.sf1.nation<span class="p">;</span>
<span class="c">##  _col0</span>

    25
<span class="o">(</span>1 row<span class="o">)</span>

Query 20210606_142214_00012_4qtix, FINISHED, 1 node
Splits: 21 total, 21 <span class="k">done</span> <span class="o">(</span>100.00%<span class="o">)</span>
0:00 <span class="o">[</span>25 rows, 0B] <span class="o">[</span>358 rows/s, 0B/s]

<span class="c"># - 选择使用特定 schema</span>
presto&gt; use tpch.sf1<span class="p">;</span>
USE
</pre></table></code></div></div><hr /><h1 id="安装trino">安装trino</h1><h2 id="下载trino">下载trino</h2><p>下载地址：https://repo1.maven.org/maven2/io/trino/trino-server/359/trino-server-359.tar.gz</p><p>操作系统要求</p><ul><li>64位Linux系统<li>为运行trino的用户提供足够的unlimit。包括trino能够打开的文件描述符，官方推荐以下配置：</ul><div class="language-plaintext highlighter-rouge"><div class="code-header" text-data="plaintext"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>vim /etc/security/limits.conf

trino soft nofile 131072

trino hard nofile 131072
</pre></table></code></div></div><p>修改完后，退出当前会话，重新登录即可生效。查看配置是否生效：</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>su trino

<span class="nb">ulimit</span>  -a
</pre></table></code></div></div><hr /><h4 id="java运行时要求">Java运行时要求</h4><p>Trino要求使用Java 11 64位版本，最低要求为：11.0.11，</p><ul><li>注意：不支持Java 8，也不支持 Java 12或者Java 13。<li>Trino官方推荐我们使用Azul Zulu的JDK版本。<li>此处，我们选择较新的11.0.12+7版本。</ul><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_fdcb0156-0fa5-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>下载链接：https://cdn.azul.com/zulu/bin/zulu11.50.19-ca-jdk11.0.12-linux_x64.tar.gz</p><h4 id="python版本要求">Python版本要求</h4><ul><li>版本：2.6.x、2.7.x、或者3.x</ul><hr /><h2 id="开始安装">开始安装</h2><h3 id="创建trino用户">创建trino用户</h3><p>在每个节点中创建trino用户。</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>ssh ha-node1 <span class="s2">"useradd trino;usermod trino -G hadoop"</span><span class="p">;</span> 
ssh ha-node2 <span class="s2">"useradd trino;usermod trino -G hadoop"</span><span class="p">;</span> 
ssh ha-node3 <span class="s2">"useradd trino;usermod trino -G hadoop"</span>
</pre></table></code></div></div><h3 id="配置trino用户打开的文件">配置trino用户打开的文件</h3><p>切换到trino用户，并用按照前面说的操作系统要求配置trino用户能打开的文件描述符。</p><h3 id="上传并解压zulu-jdk">上传并解压Zulu JDK</h3><p>在第一个节点中配置以下：</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre><td class="rouge-code"><pre><span class="o">[</span>trino@ha-node1 ~]<span class="nv">$ </span>ll -hst
总用量 194M
194M -rw-r--r-- 1 root root 194M 7月  25 23:42 zulu11.50.19-ca-jdk11.0.12-linux_x64.tar.gz


<span class="c"># 解压</span>
<span class="o">[</span>trino@ha-node1 ~]<span class="nv">$ </span><span class="nb">tar</span> -xvzf zulu11.50.19-ca-jdk11.0.12-linux_x64.tar.gz -C /opt/

<span class="c"># 创建超链接</span>
<span class="o">[</span>trino@ha-node1 ~]<span class="nv">$ </span><span class="nb">ln</span> -s /opt/zulu11.50.19-ca-jdk11.0.12-linux_x64/ /opt/jdk11_zulu
<span class="o">[</span>trino@ha-node1 ~]<span class="nv">$ </span>ll /opt/ | grep jdk11_zulu
... jdk11_zulu -&gt; /opt/zulu11.50.19-ca-jdk11.0.12-linux_x64/



<span class="c"># 配置环境变量</span>
vim ~/.bashrc
<span class="nb">export</span> JAVA_HOME<span class="o">=</span>/opt/jdk11_zulu
<span class="nb">export</span> PATH<span class="o">=</span><span class="nv">$JAVA_HOME</span>/bin:<span class="nv">$PATH</span>
<span class="c"># 加载环境变量</span>
<span class="nb">source</span> ~/.bashrc

<span class="c"># 查看JAVA版本</span>
<span class="o">[</span>trino@ha-node1 jdk11_zulu]<span class="nv">$ </span>java -version
openjdk version <span class="s2">"11.0.12"</span> 2021-07-20 LTS
OpenJDK Runtime Environment Zulu11.50+19-CA <span class="o">(</span>build 11.0.12+7-LTS<span class="o">)</span>
OpenJDK 64-Bit Server VM Zulu11.50+19-CA <span class="o">(</span>build 11.0.12+7-LTS, mixed mode<span class="o">)</span>
</pre></table></code></div></div><p>分发到其他节点：</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="c"># 切换到root用户（只是为了免密发送文件）</span>
<span class="o">[</span>root@ha-node1 ~]# whoami
root

<span class="c"># 分发文件和环境变量</span>
<span class="k">for</span> node in <span class="s2">"ha-node2"</span> <span class="s2">"ha-node3"</span><span class="p">;</span>
<span class="k">do</span>
 scp -r /opt/zulu11.50.19-ca-jdk11.0.12-linux_x64 <span class="nv">$node</span>:/opt
 ssh <span class="nv">$node</span> <span class="s2">"ln -s /opt/zulu11.50.19-ca-jdk11.0.12-linux_x64/ /opt/jdk11_zulu"</span>
 ssh <span class="nv">$node</span> <span class="s2">"chown -R trino:trino /opt/jdk11_zulu"</span>
 scp /home/trino/.bashrc <span class="nv">$node</span>:/home/trino/
<span class="k">done</span>


<span class="c"># 测试其他节点JDK11是否配置成功。</span>
<span class="k">for</span> node in <span class="s2">"ha-node2"</span> <span class="s2">"ha-node3"</span><span class="p">;</span>
<span class="k">do</span>
 ssh <span class="nv">$node</span> <span class="s2">"java -version"</span>
<span class="k">done</span>
</pre></table></code></div></div><h3 id="上传并解压trino安装包">上传并解压trino安装包</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre><span class="o">[</span>trino@ha-node1 ~]<span class="nv">$ </span>ll -hst
总用量 593M
593M -rw-r--r-- 1 root root 593M 7月  25 23:59 trino-server-359.tar.gz

<span class="c"># 解压trino</span>
<span class="o">[</span>trino@ha-node1 ~]<span class="nv">$ </span><span class="nb">tar</span> -xvzf trino-server-359.tar.gz -C /opt/

<span class="c"># 创建超链接</span>
<span class="o">[</span>trino@ha-node1 ~]<span class="nv">$ </span><span class="nb">ln</span> -s /opt/trino-server-359/ /opt/trino

<span class="c"># 查看链接</span>
<span class="o">[</span>trino@ha-node1 ~]<span class="nv">$ </span>ll /opt | awk <span class="s1">'$0 ~ /^l/ { if($9 ~ /trino/) print $0 }'</span>
lrwxrwxrwx   1 trino             trino              22 7月  26 00:01 trino -&gt; /opt/trino-server-359/

<span class="c"># 创建数据目录</span>
<span class="o">[</span>trino@ha-node1 trino]<span class="nv">$ </span><span class="nb">mkdir</span> /opt/trino/data
</pre></table></code></div></div><h3 id="配置trino">配置trino</h3><p>在安装目录中创建一个etc目录，我们会在该目录中配置以下：</p><ul><li>trino节点配置：配置每个trino节点的环境。<li>JVM配置：配置JVM的相关参数。<li>Config属性：配置trino服务器。<li>Catalog属性：配置trino的connector（数据源）</ul><h4 id="创建配置目录">创建配置目录</h4><p><code class="language-plaintext highlighter-rouge">[trino@ha-node1 trino]$ mkdir /opt/trino/etc</code></p><h4 id="配置节点属性">配置节点属性</h4><p>以下是一个最简单的配置。</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>vim opt/trino/etc/node.properties

node.environment<span class="o">=</span>trino_dev
node.id<span class="o">=</span>ffffffff-ffff-ffff-ffff-ffffffffffff
node.data-dir<span class="o">=</span>/opt/trino/data
</pre></table></code></div></div><p>说明：</p><ul><li>node.environment：集群中的所有trino节点都必须由相同的环境名称。必须以小写字母开头，只能包含小写字母、数字和下划线。<li>node.id：安装的trino节点的唯一标识符。每个节点都必须由唯一的标识符。标识符必须以字母数字字符开头，并且只能包含字母数字、或 _ 字符。<li>node.data-dir：trino的数据目录，trino会在该目录中存放日志、以及其他数据。</ul><h4 id="配置jvm">配置JVM</h4><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre>vim /opt/trino/etc/jvm.config

<span class="nt">-server</span>
<span class="nt">-Xmx3G</span>
<span class="nt">-XX</span>:-UseBiasedLocking
<span class="nt">-XX</span>:+UseG1GC
<span class="nt">-XX</span>:G1HeapRegionSize<span class="o">=</span>32M
<span class="nt">-XX</span>:+ExplicitGCInvokesConcurrent
<span class="nt">-XX</span>:+ExitOnOutOfMemoryError
<span class="nt">-XX</span>:+HeapDumpOnOutOfMemoryError
<span class="nt">-XX</span>:-OmitStackTraceInFastThrow
<span class="nt">-XX</span>:ReservedCodeCacheSize<span class="o">=</span>512M
<span class="nt">-XX</span>:PerMethodRecompilationCutoff<span class="o">=</span>10000
<span class="nt">-XX</span>:PerBytecodeRecompilationCutoff<span class="o">=</span>10000
<span class="nt">-Djdk</span>.attach.allowAttachSelf<span class="o">=</span><span class="nb">true</span>
<span class="nt">-Djdk</span>.nio.maxCachedBufferSize<span class="o">=</span>2000000
</pre></table></code></div></div><p>大家可以看到，都是JVM相关配置。每个节点可以配置不同的容量，大家根据自己的机器内存大小调整。</p><hr /><h4 id="配置trino服务器">配置trino服务器</h4><p>在trino中，每个节点都可以充当coordinator（协调器）和worker。</p><ul><li>官方推荐配置一台机器专门执行协调工作，保证集群的最佳性能。<li>此处，我让ha-node1充当coordinator，其他的两台机器为worker。</ul><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre><td class="rouge-code"><pre><span class="c"># 以下是coordinator的最小配置：</span>
vim /opt/trino/etc/config.properties

<span class="nv">coordinator</span><span class="o">=</span><span class="nb">true
</span>node-scheduler.include-coordinator<span class="o">=</span><span class="nb">false
</span>http-server.http.port<span class="o">=</span>10080
query.max-memory<span class="o">=</span>8GB
query.max-memory-per-node<span class="o">=</span>1GB
query.max-total-memory-per-node<span class="o">=</span>2GB
discovery.uri<span class="o">=</span>http://ha-node1:10080



<span class="c"># 以下是worker的最小配置：</span>
vim /opt/trino/etc/config.properties

<span class="nv">coordinator</span><span class="o">=</span><span class="nb">false
</span>http-server.http.port<span class="o">=</span>8080
query.max-memory<span class="o">=</span>8GB
query.max-memory-per-node<span class="o">=</span>1GB
query.max-total-memory-per-node<span class="o">=</span>2GB
discovery.uri<span class="o">=</span>http://ha-node1:10080
</pre></table></code></div></div><ul><li>discovery.uri：<ul><li>Trino coordinator有一个发现服务，<li>所有节点通过它来发现其他节点，<li>每个trino启动时，向服务器发现注册，并不断发送心跳保持活动状态。</ul></ul><h3 id="配置日志级别">配置日志级别</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>vim /opt/trino/etc/log.properties

io.trino<span class="o">=</span>INFO
</pre></table></code></div></div><h4 id="配置trino-catalog">配置trino catalog</h4><p>catalog 数据目录。</p><ul><li>一个catalog数据目录可以对应数据schema。<li>后续我们还会继续配置catalog目录。<li>此处，我们仅配置一个jmx的connector。</ul><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="c"># 创建catalog目录</span>
<span class="nb">mkdir</span> /opt/trino/etc/catalog

vim /opt/trino/etc/catalog/jmx.properties

connector.name<span class="o">=</span>jmx
</pre></table></code></div></div><hr /><h3 id="分发配置">分发配置</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="k">for</span> node in <span class="s2">"ha-node2"</span> <span class="s2">"ha-node3"</span><span class="p">;</span>
<span class="k">do</span>
 scp -r /opt/trino-server-359 <span class="nv">$node</span>:/opt
 ssh <span class="nv">$node</span> <span class="s2">"ln -s /opt/trino-server-359/ /opt/trino"</span>
<span class="k">done

for</span> node in <span class="s2">"ha-node2"</span> <span class="s2">"ha-node3"</span><span class="p">;</span>
<span class="k">do</span>
 ssh <span class="nv">$node</span> <span class="s2">"chown -R trino:trino /opt/trino-server-359"</span>
<span class="k">done</span>
</pre></table></code></div></div><h3 id="修改node2node3配置">修改node2、node3配置</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre><td class="rouge-code"><pre><span class="c"># ha-node2节点：</span>
ssh ha-node2
vim /opt/trino/etc/node.properties
node.environment<span class="o">=</span>trino_dev
node.id<span class="o">=</span>ffffffff-ffff-ffff-ffff-fffffffffffe
node.data-dir<span class="o">=</span>/opt/trino/data
<span class="c"># -- end of node.properties</span>

vim /opt/trino/etc/config.properties
<span class="nv">coordinator</span><span class="o">=</span><span class="nb">false
</span>http-server.http.port<span class="o">=</span>10080
query.max-memory<span class="o">=</span>8GB
query.max-memory-per-node<span class="o">=</span>1GB
query.max-total-memory-per-node<span class="o">=</span>2GB
discovery.uri<span class="o">=</span>http://ha-node1:10080
<span class="c"># -- end of config.properties</span>



<span class="c"># ha-node3节点：</span>
ssh ha-node3
vim /opt/trino/etc/node.properties
node.environment<span class="o">=</span>trino_dev
node.id<span class="o">=</span>ffffffff-ffff-ffff-ffff-fffffffffffd
node.data-dir<span class="o">=</span>/opt/trino/data
<span class="c"># -- end of node.properties</span>

vim /opt/trino/etc/jvm.config
<span class="nt">-server</span>
<span class="nt">-Xmx12G</span>
<span class="c"># -- end of jvm.config</span>

vim /opt/trino/etc/config.properties
<span class="nv">coordinator</span><span class="o">=</span><span class="nb">false
</span>http-server.http.port<span class="o">=</span>10080
query.max-memory<span class="o">=</span>10GB
query.max-memory-per-node<span class="o">=</span>4GB
query.max-total-memory-per-node<span class="o">=</span>6GB
discovery.uri<span class="o">=</span>http://ha-node1:10080
<span class="c"># -- end of config.properties</span>
</pre></table></code></div></div><h3 id="启动关闭trino">启动、关闭trino</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c"># 在每个节点启动以下命令</span>
su trino
bin/launcher start

<span class="o">[</span>trino@ha-node1 trino]<span class="nv">$ </span>jps
5696 TrinoServer
5735 Jps


<span class="c"># 关闭</span>
bin/launcher stop
</pre></table></code></div></div><p>一键启动脚本。</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>vim /opt/trino/bin/one_key.sh
<span class="c"># ! /bin/bash</span>

<span class="nv">EXE_MODE</span><span class="o">=</span><span class="nv">$1</span>

<span class="k">for</span> node in <span class="s2">"ha-node1"</span> <span class="s2">"ha-node2"</span> <span class="s2">"ha-node3"</span><span class="p">;</span>
<span class="k">do</span>
 ssh <span class="nv">$node</span> <span class="s2">"su - trino -c </span><span class="se">\"</span><span class="s2">/opt/trino/bin/launcher </span><span class="k">${</span><span class="nv">EXE_MODE</span><span class="k">}</span><span class="se">\"</span><span class="s2">"</span>
<span class="k">done

</span><span class="nb">chmod</span> a+x /opt/trino/bin/one_key.sh
</pre></table></code></div></div><p>执行启动：</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>./one_key.sh start
./one_key.sh stop

<span class="c"># 查看节点是否运行</span>
./one_key.sh status
<span class="c"># [root@ha-node1 bin] # ./one_key.sh status</span>
<span class="c"># Running as 7200</span>
<span class="c"># Running as 2552</span>
<span class="c"># Running as 2971</span>
</pre></table></code></div></div><hr /><h2 id="安装trino-cli客户端">安装trino cli客户端</h2><h3 id="下载trino-cli">下载trino cli</h3><p>下载地址：https://repo1.maven.org/maven2/io/trino/trino-cli/359/trino-cli-359-executable.jar</p><h3 id="设置执行权限">设置执行权限</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="nb">mv</span> ~/trino-cli-359-executable.jar /opt/trino/bin/trino
<span class="nb">chmod</span> a+x /opt/trino/bin/trino
</pre></table></code></div></div><hr /><h3 id="启动客户端">启动客户端</h3><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="o">[</span>trino@ha-node1 bin]<span class="nv">$ </span>./trino --server ha-node1:10080 --catalog jmx --schema default
trino:default&gt; show catalogs<span class="p">;</span>
 Catalog 
<span class="nt">---------</span>
 jmx     
 system  
<span class="o">(</span>2 rows<span class="o">)</span>
</pre></table></code></div></div><p>到此处，trino已经安装完成。</p><hr /><h3 id="webui">webui</h3><p>我们可以通过：http://ha-node1:10080/ui/访问trino的web ui。</p><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_fdf88252-0fa5-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>image-20210726015158495</p><hr /><h2 id="使用trino">使用Trino</h2><p>–</p><h3 id="连接mysql">连接MySQL</h3><p>接下来，我们使用trino来实现MySQL中数据查询。要去连接外部数据源，我们需要准备一个Connector。</p><hr /><h4 id="创建mysql对应的catalog">创建MySQL对应的catalog</h4><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>vim /opt/trino/etc/catalog/mysql_metadb.properties
connector.name<span class="o">=</span>mysql
connection-url<span class="o">=</span>jdbc:mysql://ha-node1:3306?enabledTLSProtocols<span class="o">=</span>TLSv1.2&amp;useSSL<span class="o">=</span><span class="nb">false
</span>connection-user<span class="o">=</span>root
connection-password<span class="o">=</span>123456
</pre></table></code></div></div><p>分发到所有节点：</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="k">for</span> node in <span class="s2">"ha-node2"</span> <span class="s2">"ha-node3"</span><span class="p">;</span>
<span class="k">do</span>
 scp /opt/trino/etc/catalog/mysql_metadb.properties <span class="nv">$node</span>:/opt/trino/etc/catalog/
<span class="k">done</span>
</pre></table></code></div></div><blockquote><p>注意一定要分发哦！</p></blockquote><h4 id="重启trino">重启trino</h4><p><code class="language-plaintext highlighter-rouge">./one_key.sh restart</code></p><h4 id="启动客户端-1">启动客户端</h4><p><code class="language-plaintext highlighter-rouge">bin/trino --server ha-node1:10080</code></p><h4 id="执行查询">执行查询</h4><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre><td class="rouge-code"><pre>trino&gt; show catalogs<span class="p">;</span>
<span class="c">#    Catalog    </span>
<span class="c"># --------------</span>
<span class="c">#  jmx          </span>
<span class="c">#  mysql_metadb </span>
<span class="c">#  system     </span>
 


<span class="c"># 查询mysql的数据库</span>
trino&gt;  show schemas from mysql_metadb<span class="p">;</span>
       Schema       
<span class="nt">--------------------</span>
 hive               
 hue                
 information_schema 
 performance_schema 
 c       
 
<span class="c"># 选择数据库</span>
use mysql_metadb.ranger<span class="p">;</span>
 
<span class="c"># 执行查询</span>
<span class="k">select</span> <span class="k">*</span> from mysql_metadb.ranger.x_group_users limit 5<span class="p">;</span>
</pre></table></code></div></div><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_fe2d2a7a-0fa5-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>再执行一个聚合计算：</p><div class="language-sql highlighter-rouge"><div class="code-header" text-data="sql"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>
<span class="k">select</span> <span class="k">count</span> <span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="err"> </span>
<span class="k">from</span> <span class="n">mysql_metadb</span><span class="p">.</span><span class="n">ranger</span><span class="p">.</span><span class="n">x_group_users</span><span class="p">;</span>
</pre></table></code></div></div><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_fe6672d0-0fa5-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>在TrinoDB中显示如下：</p><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_fea765ba-0fa5-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>进入到查询中，我们可以看到更具体的执行信息。</p><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_fee9d904-0fa5-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>再看一下查询计划。</p><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_ff180ffe-0fa5-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>一共分为两个Stage。</p><ul><li>第一个执行的Stage是TableScan。<li>Table Scan并只拉取了一条数据，直接执行了sql语句，然后输出。</ul><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_ff5e8498-0fa5-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>那是不是Trino把所有查询都会下推到Mysql呢？我们有理由相信不会的。因为Trino是一个分布式计算引擎。</p><p>我们再来一个带有JOIN和COUNT的SQL：</p><div class="language-sql highlighter-rouge"><div class="code-header" text-data="sql"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="k">select</span> <span class="n">group_name</span><span class="p">,</span> <span class="k">count</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="err"> </span><span class="k">as</span> <span class="n">cnt</span><span class="err"> </span>
<span class="k">from</span> <span class="n">x_user</span><span class="err"> </span><span class="n">t1</span><span class="p">,</span><span class="err"> </span><span class="n">x_group_users</span><span class="err"> </span><span class="n">t2</span><span class="err"> </span>
<span class="k">where</span> <span class="n">t1</span><span class="p">.</span><span class="n">id</span><span class="err"> </span><span class="o">=</span><span class="err"> </span><span class="n">t2</span><span class="p">.</span><span class="n">user_id</span><span class="err"> </span>
<span class="k">group</span> <span class="k">by</span> <span class="n">group_name</span><span class="p">;</span>
</pre></table></code></div></div><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_ff9290ee-0fa5-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>一共分为5个Stage执行</p><ul><li>对应查询Mysql就是5个任务。<li>任务的执行情况：</ul><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_ffd416a4-0fa5-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>看下Trino的执行计划。在控制台来看下执行计划。</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
</pre><td class="rouge-code"><pre>trino:ranger&gt; explain select group_name, count<span class="o">(</span>1<span class="o">)</span> as cnt from x_user t1, x_group_users t2 where t1.id <span class="o">=</span> t2.user_id group by group_name<span class="p">;</span>
         Query Plan    
<span class="nt">--------------------------------------------------------------------------------------------------------------------------------------</span>
 Fragment 0 [SINGLE]   
     Output layout: [group_name, count]                     
     Output partitioning: SINGLE []                         
     Stage Execution Strategy: UNGROUPED_EXECUTION          
     Output[group_name, cnt]                                
     │   Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, count:bigint]    
     │   Estimates: <span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: ?, network: ?<span class="o">}</span>                                 
     │   cnt :<span class="o">=</span> count  
     └─ RemoteSource[1]
            Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, count:bigint] 
                       
 Fragment 1 [HASH]     
     Output layout: [group_name, count]                     
     Output partitioning: SINGLE []                         
     Stage Execution Strategy: UNGROUPED_EXECUTION          
     Project[]         
     │   Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, count:bigint]    
     │   Estimates: <span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: ?, network: ?<span class="o">}</span>                                 
     └─ Aggregate<span class="o">(</span>FINAL<span class="o">)[</span>group_name][<span class="nv">$hashvalue</span><span class="o">]</span>            
        │   Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, <span class="nv">$hashvalue</span>:bigint, count:bigint]                   
        │   Estimates: <span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: ?, network: ?<span class="o">}</span>                              
        │   count :<span class="o">=</span> count<span class="o">(</span><span class="s2">"count_5"</span><span class="o">)</span>                       
        └─ LocalExchange[HASH][<span class="nv">$hashvalue</span><span class="o">]</span> <span class="o">(</span><span class="s2">"group_name"</span><span class="o">)</span>   
           │   Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, count_5:bigint, <span class="nv">$hashvalue</span>:bigint]              
           │   Estimates: <span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: ?, network: ?<span class="o">}</span>                           
           └─ RemoteSource[2]                               
                  Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, count_5:bigint, <span class="nv">$hashvalue_6</span>:bigint]         
                  
                  
 Fragment 2 [HASH]     
     Output layout: [group_name, count_5, <span class="nv">$hashvalue_12</span><span class="o">]</span>    
     Output partitioning: HASH [group_name][<span class="nv">$hashvalue_12</span><span class="o">]</span>  
     Stage Execution Strategy: UNGROUPED_EXECUTION          
     Aggregate<span class="o">(</span>PARTIAL<span class="o">)[</span>group_name][<span class="nv">$hashvalue_12</span><span class="o">]</span>          
     │   Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, <span class="nv">$hashvalue_12</span>:bigint, count_5:bigint]                 
     │   count_5 :<span class="o">=</span> count<span class="o">(</span><span class="k">*</span><span class="o">)</span>                                
     └─ Project[]      
        │   Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, <span class="nv">$hashvalue_12</span>:bigint]                              
        │   Estimates: <span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: ?, network: ?<span class="o">}</span>                              
        │   <span class="nv">$hashvalue_12</span> :<span class="o">=</span> combine_hash<span class="o">(</span>bigint <span class="s1">'0'</span>, COALESCE<span class="o">(</span><span class="s2">"</span><span class="nv">$operator$hash_code</span><span class="s2">"</span><span class="o">(</span><span class="s2">"group_name"</span><span class="o">)</span>, 0<span class="o">))</span>                               
        └─ InnerJoin[<span class="o">(</span><span class="s2">"id"</span> <span class="o">=</span> <span class="s2">"user_id"</span><span class="o">)][</span><span class="nv">$hashvalue_7</span>, <span class="nv">$hashvalue_9</span><span class="o">]</span>                             
           │   Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)]</span>            
           │   Estimates: <span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: ?, network: ?<span class="o">}</span>                           
           │   Distribution: PARTITIONED                    
           │   dynamicFilterAssignments <span class="o">=</span> <span class="o">{</span>user_id -&gt; #df_340<span class="o">}</span>                                   
           ├─ RemoteSource[3]                               
           │      Layout: [id:bigint, <span class="nv">$hashvalue_7</span>:bigint]  
           └─ LocalExchange[HASH][<span class="nv">$hashvalue_9</span><span class="o">]</span> <span class="o">(</span><span class="s2">"user_id"</span><span class="o">)</span> 
              │   Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, user_id:bigint, <span class="nv">$hashvalue_9</span>:bigint]         
              │   Estimates: <span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: 0B, network: ?<span class="o">}</span>                       
              └─ RemoteSource[4]                            
                     Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, user_id:bigint, <span class="nv">$hashvalue_10</span>:bigint] 
                     
 Fragment 3 [SOURCE]   
     Output layout: [id, <span class="nv">$hashvalue_8</span><span class="o">]</span>                      
     Output partitioning: HASH [id][<span class="nv">$hashvalue_8</span><span class="o">]</span>           
     Stage Execution Strategy: UNGROUPED_EXECUTION          
     ScanFilterProject[table <span class="o">=</span> mysql_metadb:ranger.x_user ranger.x_user columns<span class="o">=[</span><span class="nb">id</span>:bigint:BIGINT], grouped <span class="o">=</span> false, filterPredicate <span class="o">=</span>
         Layout: [id:bigint, <span class="nv">$hashvalue_8</span>:bigint]           
         Estimates: <span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: 0B, network: 0B<span class="o">}</span>/<span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: 0B, network: 0B<span class="o">}</span>/<span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?
         <span class="nv">$hashvalue_8</span> :<span class="o">=</span> combine_hash<span class="o">(</span>bigint <span class="s1">'0'</span>, COALESCE<span class="o">(</span><span class="s2">"</span><span class="nv">$operator$hash_code</span><span class="s2">"</span><span class="o">(</span><span class="s2">"id"</span><span class="o">)</span>, 0<span class="o">))</span>      
         id :<span class="o">=</span> id:bigint:BIGINT                             
                       
 Fragment 4 [SOURCE]   
     Output layout: [group_name, user_id, <span class="nv">$hashvalue_11</span><span class="o">]</span>    
     Output partitioning: HASH [user_id][<span class="nv">$hashvalue_11</span><span class="o">]</span>     
     Stage Execution Strategy: UNGROUPED_EXECUTION          
     ScanProject[table <span class="o">=</span> mysql_metadb:ranger.x_group_users ranger.x_group_users columns<span class="o">=[</span>group_name:varchar<span class="o">(</span>740<span class="o">)</span>:VARCHAR, user_id:bigi
         Layout: [group_name:varchar<span class="o">(</span>740<span class="o">)</span>, user_id:bigint, <span class="nv">$hashvalue_11</span>:bigint]                 
         Estimates: <span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: 0B, network: 0B<span class="o">}</span>/<span class="o">{</span>rows: ? <span class="o">(</span>?<span class="o">)</span>, cpu: ?, memory: 0B, network: 0B<span class="o">}</span>                     
         <span class="nv">$hashvalue_11</span> :<span class="o">=</span> combine_hash<span class="o">(</span>bigint <span class="s1">'0'</span>, COALESCE<span class="o">(</span><span class="s2">"</span><span class="nv">$operator$hash_code</span><span class="s2">"</span><span class="o">(</span><span class="s2">"user_id"</span><span class="o">)</span>, 0<span class="o">))</span>
         group_name :<span class="o">=</span> group_name:varchar<span class="o">(</span>740<span class="o">)</span>:VARCHAR      
         user_id :<span class="o">=</span> user_id:bigint:BIGINT
<span class="sb">```</span>  


1. 扫描 x_group_users 表，Trino自动选择 user_id 进行hash分区。并且只拉取三个字段：group_name、user_id、<span class="sb">`</span><span class="nv">$hashvalue_11</span><span class="sb">`</span>。可以看到group by、以及聚合计算都下推到mysql中执行拉取。
2. 扫描 x_user 表，按照id hash分区，只拉取了id，以及<span class="sb">`</span><span class="nv">$hashvalue_8</span><span class="sb">`</span>。
3. 拉取完数据后，在本地按照hash值执行shuffle分区。然后执行INNER JOIN操作。注意：这一步是按分区执行的。
4. 然后对分区的执行结果再聚合计算。计算得到最终结果。
5. 输出最终结果。



<span class="nt">---</span>



<span class="c">### 连接Hive</span>

Trino只需要使用Hive的两个组件：

<span class="k">*</span> 存储在HDFS中的数据
<span class="k">*</span> Hive Metastore

Trino支持Hive 2、以及Hive3，以及衍生的发行版本，CDH以及HDP。支持的文件类型也比较全：

<span class="k">*</span> ORC
<span class="k">*</span> Parquet
<span class="k">*</span> Avro
<span class="k">*</span> RCText <span class="o">(</span>RCFile using <span class="sb">`</span>ColumnarSerDe<span class="sb">`</span>    <span class="o">)</span>

<span class="k">*</span> RCBinary <span class="o">(</span>RCFile using <span class="sb">`</span>LazyBinaryColumnarSerDe<span class="sb">`</span>    <span class="o">)</span>

<span class="k">*</span> SequenceFile
<span class="k">*</span> JSON <span class="o">(</span>using <span class="sb">`</span>org.apache.hive.hcatalog.data.JsonSerDe<span class="sb">`</span>    <span class="o">)</span>

<span class="k">*</span> CSV <span class="o">(</span>using <span class="sb">`</span>org.apache.hadoop.hive.serde2.OpenCSVSerde<span class="sb">`</span>    <span class="o">)</span>

<span class="k">*</span> TextFile


<span class="nt">---</span>


<span class="c">#### 配置Hive MetaStore</span>

为了能够在使用Hive 3时，对Avro表的支持，需要配置以下属性：


<span class="sb">```</span>xml
&lt;property&gt;
     &lt;name&gt;metastore.storage.schema.reader.impl&lt;/name&gt;
     &lt;value&gt;org.apache.hadoop.hive.metastore.SerDeStorageSchemaReader&lt;/value&gt;
 &lt;/property&gt;
</pre></table></code></div></div><h4 id="配置hive-connector">配置Hive connector</h4><p>分别配置hive metastore的地址和HDFS（因为我们配置了HA）。</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>vim etc/catalog/hive.properties

connector.name<span class="o">=</span>hive
hive.metastore.uri<span class="o">=</span>thrift://ha-node1:9083
hive.config.resources<span class="o">=</span>/opt/hadoop/etc/hadoop/core-site.xml,/opt/hadoop/etc/hadoop/hdfs-site.xml
</pre></table></code></div></div><p>分发到所有节点：</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="k">for</span> node in <span class="s2">"ha-node2"</span> <span class="s2">"ha-node3"</span><span class="p">;</span>
<span class="k">do</span>
 scp /opt/trino/etc/catalog/hive.properties <span class="nv">$node</span>:/opt/trino/etc/catalog/
<span class="k">done</span>
</pre></table></code></div></div><h4 id="启动">启动</h4><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="c"># 启动HDFS</span>
<span class="c"># 启动Hive MetaStore</span>
<span class="c"># 重启Trino</span>
</pre></table></code></div></div><h4 id="测试">测试</h4><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
</pre><td class="rouge-code"><pre><span class="c"># 连接客户端</span>
bin/trino --server ha-node1:10080

<span class="c"># 查看catalog</span>
trino&gt; show catalogs<span class="p">;</span>
<span class="c">#    Catalog    </span>
<span class="c"># --------------</span>
<span class="c">#  hive         </span>
<span class="c">#  jmx          </span>
<span class="c">#  mysql_metadb </span>
<span class="c">#  system       </span>


<span class="c"># 查看hive schemas</span>
trino&gt; show schemas in hive<span class="p">;</span>
<span class="c">#        Schema       </span>
<span class="c"># --------------------</span>
<span class="c">#  default            </span>
<span class="c">#  hudi_datalake      </span>
<span class="c">#  information_schema </span>
<span class="c">#  kylin_test         </span>
<span class="c">#  ods_hudi           </span>
<span class="c">#  test               </span>
<span class="c"># (6 rows)</span>


<span class="c"># 查询表数据</span>
trino&gt; show tables <span class="k">in </span>hive.test<span class="p">;</span>
<span class="c">#         Table        </span>
<span class="c"># ---------------------</span>
<span class="c">#  dim_date_orc        </span>
<span class="c">#  dim_date_orc_snappy </span>
<span class="c">#  x_axis_orc          </span>
<span class="c">#  x_axis_orc_snappy   </span>
<span class="c">#  y_axis_orc          </span>
<span class="c">#  y_axis_orc_snappy   </span>
<span class="c"># (6 rows)</span>



<span class="c"># 执行查询</span>
trino&gt; use hive.test<span class="p">;</span>
<span class="c"># USE</span>
<span class="c"># trino:test&gt; </span>
<span class="c"># trino:test&gt; select * from dim_date_orc_snappy limit 10;</span>
<span class="c">#  year | month </span>
<span class="c"># ------+-------</span>
<span class="c">#  2022 |     1 </span>
<span class="c">#  2022 |     2 </span>
<span class="c">#  2022 |     3 </span>
<span class="c">#  2022 |     4 </span>
<span class="c">#  2022 |     5 </span>
<span class="c">#  2022 |     6 </span>
<span class="c">#  2022 |     7 </span>
<span class="c">#  2022 |     8 </span>
<span class="c">#  2022 |     9 </span>
<span class="c">#  2022 |    10 </span>
<span class="c"># (10 rows)</span>



<span class="c"># 执行聚合计算</span>
trino:test&gt; select count<span class="o">(</span><span class="k">*</span><span class="o">)</span> from dim_date_orc_snappy<span class="p">;</span>
<span class="c">#  _col0 </span>
<span class="c"># -------</span>
<span class="c">#     36 </span>
<span class="c"># (1 row)</span>
</pre></table></code></div></div><hr /><h3 id="将mysql数据导入到hive">将MySQL数据导入到Hive</h3><h4 id="执行导入">执行导入</h4><p>因为我们使用Trino能够方便得连接到Mysql与Hive</p><ul><li>所以我们在一个引擎中可以很容易地将MySQL的数据查询出来，然后导入到Hive中。</ul><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre><td class="rouge-code"><pre><span class="c"># 在Hive中创建一个schema</span>
create schema hive.ranger<span class="p">;</span>

<span class="c"># hive创建表</span>
create table <span class="k">if </span>not exists hive.ranger.x_user<span class="o">(</span>
        id                bigint    
    , create_time       date
    , update_time       date
    , added_by_id       bigint        
    , upd_by_id         bigint        
    , user_name         varchar
    , descr             varchar
    , status            integer       
    , cred_store_id     bigint        
    , is_visible        integer       
    , other_attributes  varchar
    , dt                varchar
<span class="o">)</span>
with <span class="o">(</span>  
      format<span class="o">=</span><span class="s1">'ORC'</span>, 
    partitioned_by<span class="o">=</span>ARRAY[<span class="s1">'dt'</span><span class="o">]</span>
<span class="o">)</span>
<span class="p">;</span>

<span class="c"># 添加分区</span>
CALL system.create_empty_partition<span class="o">(</span>
        schema_name <span class="o">=&gt;</span> <span class="s1">'ranger'</span>
    , table_name <span class="o">=&gt;</span> <span class="s1">'x_user'</span>
    , partition_columns <span class="o">=&gt;</span> ARRAY[<span class="s1">'dt'</span><span class="o">]</span>
    , partition_values <span class="o">=&gt;</span> ARRAY[<span class="s1">'2021-08-08'</span><span class="o">]</span>
<span class="o">)</span><span class="p">;</span>

<span class="c"># 导入数据</span>
insert into hive.ranger.x_user
<span class="k">select</span>
 t.<span class="k">*</span>    , <span class="s1">'2021-08-08'</span> as dt
from mysql_madb.ranger.x_user t<span class="p">;</span>
 
<span class="c"># 收集表和列的列统计信息</span>
ANALYZE hive.ranger.x_user<span class="p">;</span>
</pre></table></code></div></div><p>同样，我们把另外两张表也导入到Hive里面来。</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
</pre><td class="rouge-code"><pre>
create table <span class="k">if </span>not exists hive.ranger.x_group_users <span class="o">(</span>
     id          bigint      
 , create_time date
 , update_time date
 , added_by_id bigint      
 , upd_by_id   bigint      
 , group_name  varchar
 , p_group_id  bigint      
 , user_id     bigint     
    , dt          varchar
<span class="o">)</span>
with <span class="o">(</span>  
      format<span class="o">=</span><span class="s1">'ORC'</span>, 
    partitioned_by<span class="o">=</span>ARRAY[<span class="s1">'dt'</span><span class="o">]</span>
<span class="o">)</span>
<span class="p">;</span>

<span class="c"># 添加分区</span>
CALL system.create_empty_partition<span class="o">(</span>
        schema_name <span class="o">=&gt;</span> <span class="s1">'ranger'</span>
    , table_name <span class="o">=&gt;</span> <span class="s1">'x_group_users'</span>
    , partition_columns <span class="o">=&gt;</span> ARRAY[<span class="s1">'dt'</span><span class="o">]</span>
    , partition_values <span class="o">=&gt;</span> ARRAY[<span class="s1">'2021-08-08'</span><span class="o">]</span>
<span class="o">)</span><span class="p">;</span>

<span class="c"># 导入数据</span>
insert into hive.ranger.x_group_users
<span class="k">select</span>
 t.<span class="k">*</span>    , <span class="s1">'2021-08-08'</span> as dt
from mysql_metadb.rger.x_group_users t<span class="p">;</span>
 
<span class="c"># 收集表和列的列统计信息</span>
ANALYZE hive.ranger.x_group_users<span class="p">;</span>

create table <span class="k">if </span>not exists hive.ranger.x_group<span class="o">(</span>
   id               bigint        
 , create_time      date  
 , update_time      date  
 , added_by_id      bigint        
 , upd_by_id        bigint        
 , group_name       varchar
 , descr            varchar
 , status           integer       
 , group_type       integer       
 , cred_store_id    bigint        
 , group_src        integer       
 , is_visible       integer       
 , other_attributes varchar
    , dt      varchar
<span class="o">)</span>
with <span class="o">(</span>  
      format<span class="o">=</span><span class="s1">'ORC'</span>, 
    partitioned_by<span class="o">=</span>ARRAY[<span class="s1">'dt'</span><span class="o">]</span>
<span class="o">)</span>
<span class="p">;</span>

<span class="c"># 添加分区</span>
CALL system.create_empty_partition<span class="o">(</span>
        schema_name <span class="o">=&gt;</span> <span class="s1">'ranger'</span>
    , table_name <span class="o">=&gt;</span> <span class="s1">'x_group'</span>
    , partition_columns <span class="o">=&gt;</span> ARRAY[<span class="s1">'dt'</span><span class="o">]</span>
    , partition_values <span class="o">=&gt;</span> ARRAY[<span class="s1">'2021-08-08'</span><span class="o">]</span>
<span class="o">)</span><span class="p">;</span>

  <span class="c"># 导入数据</span>
insert into hive.ranger.x_group
<span class="k">select</span>
 t.<span class="k">*</span>    , <span class="s1">'2021-08-08'</span> as dt
from
 mysql_medb.ranger.x_group t<span class="p">;</span>
 
<span class="c"># 收集表和列的列统计信息</span>
ANALYZE hive.ranger.x_group<span class="p">;</span>
</pre></table></code></div></div><h4 id="执行关联查询">执行关联查询</h4><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="k">select </span>group_name, count<span class="o">(</span>1<span class="o">)</span> as cnt 
from hive.ranger.x_user t1, hive.ranger.x_group_users t2 
where t1.id <span class="o">=</span> t2.user_id group by group_name<span class="p">;</span>
</pre></table></code></div></div><p>非常地痛快，是不是？一个引擎把所有数据源全部连接到一起了。</p><blockquote><ul><li><p>大家可以在https://trino.io/docs/current/language/types.html找到Trino所有的类型信息。</p><li><p>大家可以在https://trino.io/docs/current/connector/hive.html#table-properties找到Trino与Hive相关的所有语</p></ul></blockquote><hr /><h3 id="连接kafka">连接Kafka</h3><p>连接Kafka，是不是有点头嗡嗡的？想想我们之前查询Kafka的数据可是费劲了，特别是要做一些数据验证，或者探索。需要一个很长的Pipeline。而有了Trino，将改变着一切。</p><h4 id="启动kafka">启动Kafka</h4><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="o">[</span>kafka@ha-node1 kafka]<span class="nv">$ </span>bin/kafka-topics.sh --list --zookeeper ha-node1:2181
__consumer_offsets
chk_demo
ogg_test_ogg
oracle_test_ogg
</pre></table></code></div></div><h4 id="kafka-connector">Kafka Connector</h4><p>Kafka Connector将topic映射为Trino中的表，而每条消息就是一行。配置起来相当地简单：</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>vim etc/catalog/kafka.properties

connector.name<span class="o">=</span>kafka
kafka.table-names<span class="o">=</span>chk_demo,ogg_test_ogg
kafka.nodes<span class="o">=</span>ha-node1:9092,ha-node2:9092,ha-node3:9092
kafka.hide-internal-columns<span class="o">=</span><span class="nb">false</span>
</pre></table></code></div></div><p>分发到所有节点：</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="k">for</span> node in <span class="s2">"ha-node2"</span> <span class="s2">"ha-node3"</span><span class="p">;</span>
<span class="k">do</span>
 scp /opt/trino/etc/catalog/kafka.properties <span class="nv">$node</span>:/opt/trino/etc/catalog/
<span class="k">done</span>
</pre></table></code></div></div><p>重新启动Trino。</p><hr /><h4 id="测试-1">测试</h4><p>我们先往Kafka中发送一些测试数据。</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>bin/kafka-console-producer.sh --topic chk_demo --broker-list ha-node1:9092
<span class="o">&gt;</span>test1
<span class="o">&gt;</span>test2
<span class="o">&gt;</span>test3
<span class="o">&gt;</span>测试
</pre></table></code></div></div><p>使用Trino查询：</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre><td class="rouge-code"><pre>
<span class="c"># 连接客户端</span>
bin/trino --server ha-node1:10080
trino&gt; use kafka.default<span class="p">;</span>
<span class="c"># USE</span>

<span class="c"># 查看表(topic)</span>
trino:default&gt; show tables<span class="p">;</span>
<span class="c">#     Table     </span>
<span class="c"># --------------</span>
<span class="c">#  chk_demo     </span>
<span class="c">#  ogg_test_ogg </span>
<span class="c"># (2 rows)</span>


<span class="c"># 查看表信息</span>
trino:default&gt; desc chk_demo<span class="p">;</span>

<span class="c"># Trino还专门给我们准备了注释。</span>
<span class="c">#       Column       |              Type              | Extra |                   Comment                   </span>
<span class="c"># -------------------+--------------------------------+-------+---------------------------------------------</span>
<span class="c">#  _partition_id     | bigint                         |       | Partition Id                                </span>
<span class="c">#  _partition_offset | bigint                         |       | Offset </span>
  forthe message within the partition 
<span class="c">#  _message_corrupt  | boolean                        |       | Message data is corrupt                     </span>
<span class="c">#  _message          | varchar                        |       | Message text                                </span>
<span class="c">#  _headers          | map(varchar, array(varbinary)) |       | Headers of the message as map               </span>
<span class="c">#  _message_length   | bigint                         |       | Total number of message bytes               </span>
<span class="c">#  _key_corrupt      | boolean                        |       | Key data is corrupt                         </span>
<span class="c">#  _key              | varchar                        |       | Key text                                    </span>
<span class="c">#  _key_length       | bigint                         |       | Total number of key bytes                   </span>
<span class="c">#  _timestamp        | timestamp(3)                   |       | Message timestamp                           </span>
<span class="c"># (10 rows)</span>


<span class="c"># 查询数据</span>
trino:default&gt; select <span class="k">*</span> from chk_demo limit 10<span class="p">;</span>
</pre></table></code></div></div><p><img data-proofer-ignore data-src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20210907_00105e16-0fa6-11ec-abfc-00163e068ecd.png" alt="img" /></p><p>再演示几个查询：</p><div class="language-bash highlighter-rouge"><div class="code-header" text-data="bash"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre>
<span class="c"># 根据分区、offset查询指定位置数据</span>
<span class="k">select</span> _partition_id, _partition_offset, _message, _key 
from chk_demo 
where _partition_id <span class="o">=</span> 0 and _partition_offset <span class="o">=</span> 0<span class="p">;</span>
<span class="c">#  _partition_id | _partition_offset | _message | _key </span>
<span class="c"># ---------------+-------------------+----------+------</span>
<span class="c">#              0 |                 0 | test1    | NULL </span>
<span class="c"># (1 row)</span>



<span class="c"># 查询指定时间戳范围的消息</span>
<span class="k">select</span> 
 _partition_id
 , _partition_offset
 , _message
 , _key 
from chk_demo 
where 
 format_datetime<span class="o">(</span>_timestamp, <span class="s1">'yyyy-MM-dd HH:mm:ss'</span><span class="o">)</span> &gt;<span class="o">=</span> <span class="s1">'2021-08-08 02:57'</span> 
 and format_datetime<span class="o">(</span>_timestamp, <span class="s1">'yyyy-MM-dd HH:mm:ss'</span><span class="o">)</span> &lt;<span class="o">=</span> <span class="s1">'2021-08-08 02:58'</span>
<span class="p">;</span>
<span class="c">#  _partition_id | _partition_offset | _message | _key </span>
<span class="c"># ---------------+-------------------+----------+------</span>
<span class="c">#              0 |                 0 | test1    | NULL </span>
<span class="c">#              1 |                 0 | test2    | NULL </span>
<span class="c"># (2 rows)</span>
</pre></table></code></div></div><p>.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/00basic/'>00Basic</a>, <a href='/categories/50bigdata/'>50BigData</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/bigdata/" class="post-tag no-text-decoration" >BigData</a> <a href="/tags/trino/" class="post-tag no-text-decoration" >Trino</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=FB Trino - Grace&url=https://ocholuo.github.io//posts/Trino/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=FB Trino - Grace&u=https://ocholuo.github.io//posts/Trino/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=FB Trino - Grace&url=https://ocholuo.github.io//posts/Trino/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Amazon-CloudFront/">AWS Lab - AWS CloudFront</a><li><a href="/posts/Alexa-1stSkill/">AWS Alex First Skill - RedVelvet Time</a><li><a href="/posts/NetworkProtocol-SSL-TLS-Handshake/">NetworkProtocol SSL/TLS Handshake</a><li><a href="/posts/pythonCrash/">Python Crash</a><li><a href="/posts/%E4%B8%80%E5%8F%A5%E8%AF%9D%E8%A7%A3%E9%87%8AAWS/">AWS - 一句话解释AWS</a><li><a href="/posts/GKE/">GCP - Google Cloud Computing - Kubernetes and Kubernetes Engine</a><li><a href="/posts/Go-Note/">Go Note</a><li><a href="/posts/SCPs/">AWS - IdenAccessManage - SCPs (Service Control Policies)</a><li><a href="/posts/CompanyBenefit/">Company Benefit</a><li><a href="/posts/Encryption-SSL&TLS/">Cryptography - SSL/TLS Encryption</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/aws/">AWS</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/cyberattack/">CyberAttack</a> <a class="post-tag" href="/tags/lab/">Lab</a> <a class="post-tag" href="/tags/cyberattacktools/">CyberAttackTools</a> <a class="post-tag" href="/tags/gcp/">GCP</a> <a class="post-tag" href="/tags/sysadmin/">Sysadmin</a> <a class="post-tag" href="/tags/java/">Java</a> <a class="post-tag" href="/tags/network/">Network</a> <a class="post-tag" href="/tags/soc/">SOC</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Batch/"><div class="card-body"> <span class="timeago small" >Nov 11, 2020<i class="unloaded">2020-11-11T10:11:11-05:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Batch</h3><div class="text-muted small"><p> Batch basic Batch Processing vs Stream Processing user case ref [Batch Pr...</p></div></div></a></div><div class="card"> <a href="/posts/Hadoop/"><div class="card-body"> <span class="timeago small" >Nov 11, 2020<i class="unloaded">2020-11-11T10:11:11-05:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Apache Hadoop</h3><div class="text-muted small"><p> Apache Hadoop history basic Hadoop 核心 HDFS - Storage unit MapReduce YARN usages Apache Hadoop histo...</p></div></div></a></div><div class="card"> <a href="/posts/Spark/"><div class="card-body"> <span class="timeago small" >Nov 11, 2020<i class="unloaded">2020-11-11T10:11:11-05:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Apache Spark</h3><div class="text-muted small"><p> Apache Spark basic 基本概念 Spark产生的背景：大数据问题 相关概念 计算模型 Hadoop与Spark的区别 RDD - Resilient Distributed Datasets basic ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Spark/" class="btn btn-outline-primary" prompt="Older"><p>Apache Spark</p></a> <a href="/posts/Github-model/" class="btn btn-outline-primary" prompt="Newer"><p>GitHub - A successful Git branching model</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/ocholuo">Grace JyL</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/aws/">AWS</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/cyberattack/">CyberAttack</a> <a class="post-tag" href="/tags/lab/">Lab</a> <a class="post-tag" href="/tags/cyberattacktools/">CyberAttackTools</a> <a class="post-tag" href="/tags/gcp/">GCP</a> <a class="post-tag" href="/tags/sysadmin/">Sysadmin</a> <a class="post-tag" href="/tags/java/">Java</a> <a class="post-tag" href="/tags/network/">Network</a> <a class="post-tag" href="/tags/soc/">SOC</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://ocholuo.github.io/{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-179830187-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-179830187-1'); }); </script>
