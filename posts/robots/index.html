<!DOCTYPE html><html lang="en" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://myochosite-291718.appspot.com/query?id=ahNwfm15b2Nob3NpdGUtMjkxNzE4chULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="The Web Robots Pages" /><meta property="og:locale" content="en" /><meta name="description" content="[toc]" /><meta property="og:description" content="[toc]" /><link rel="canonical" href="https://ocholuo.github.io//posts/robots/" /><meta property="og:url" content="https://ocholuo.github.io//posts/robots/" /><meta property="og:site_name" content="Grace" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-09-20T11:11:11-04:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="The Web Robots Pages" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-09-20T11:11:11-04:00","datePublished":"2020-09-20T11:11:11-04:00","description":"[toc]","headline":"The Web Robots Pages","mainEntityOfPage":{"@type":"WebPage","@id":"https://ocholuo.github.io//posts/robots/"},"url":"https://ocholuo.github.io//posts/robots/"}</script><title>The Web Robots Pages | Grace</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Grace"><meta name="application-name" content="Grace"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://myochosite-291718.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://myochosite-291718.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/huoye.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Grace</a></div><div class="site-subtitle font-italic">2023 Mar 14 updated</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/ocholuo" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['',''].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>The Web Robots Pages</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>The Web Robots Pages</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Grace JyL </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Sep 20, 2020, 11:11 AM -0400" >Sep 20, 2020<i class="unloaded">2020-09-20T11:11:11-04:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2695 words">14 min read</span> <span id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </span> views</div></div><div class="post-content"><p>[toc]</p><hr /><h1 id="the-web-robots-pages">The Web Robots Pages</h1><hr /><h2 id="web-robots">Web Robots</h2><p>ref https://ahrefs.com/blog/zh/robots-txt/</p><ul><li>Web Robots (Web Wanderers, Crawlers, or Spiders)<li>programs that traverse the Web automatically.<li>Search engines such as Google use them to index the web content,<li>spammers use them to scan for email addresses, and they have many other uses.</ul><p>搜索引擎通过程序robot（spider），自动访问互联网上的网页并获取网页信息。</p><p>可以在网站中创建一个纯文本文件robots.txt，在这个文件中声明该网站中不想被robot访问的部分，这样，该网站的部分或全部内容就可以不被搜索引擎收录了，或者指定搜索引擎只收录指定的内容。</p><p>User-agents（用户代理）</p><ul><li>每个搜索引擎都有一个特定的用户代理。<li>可以在robots.txt文件中针对不同的用户代理分配抓取规则。<li><p>总共大约有上百种用户代理，以下是一些对SEO有用的用户代理：</p><div class="language-plaintext highlighter-rouge"><div class="code-header" text-data="plaintext"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>Google: Googlebot
Google Images: Googlebot-Image
Bing: Bingbot
Yahoo: Slurp
Baidu: Baiduspider
DuckDuckGo: DuckDuckBot
</pre></table></code></div></div></ul><p>robots.txt中的所有用户代理均严格区分大小写。 也可以使用通配符<code class="language-plaintext highlighter-rouge">（*）</code>来一次性为所有的用户代理制定规则。</p><div class="language-plaintext highlighter-rouge"><div class="code-header" text-data="plaintext"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>举例，想屏蔽除了谷歌以外的搜索引擎蜘蛛：
User-agent: *
Disallow: /

User-agent: Googlebot
Allow: /
</pre></table></code></div></div><p>在 robots.txt文件中，可以指定无数个用户代理。</p><ul><li>虽然这么说，每当你指定一个新的用户代理时，它都是独立的。<li>如果你陆续为多一个用户代理制定了规则，那么第一个用户代理的规则并不适用于第二个，或者时第三个。<li>有一个例外就是，如果你针对同一个用户代理制定了多次规则，那么这些规则则会被放在一起执行。</ul><p>重要提示</p><ul><li>蜘蛛只会遵循准确表明详细用户代理的指令。所以上方的 robots.txt文件只会排除除谷歌蜘蛛（以及其它类型的谷歌蜘蛛）以外的搜索引擎爬虫。谷歌蜘蛛会忽略一些不太具体的用户代理声明。</ul><h2 id="about-robotstxt">About /robots.txt</h2><p>Web site owners use the <code class="language-plaintext highlighter-rouge">/robots.txt</code> file to give instructions about their site to web robots; this is called The <code class="language-plaintext highlighter-rouge">Robots Exclusion Protocol</code>.</p><p>It works likes this:</p><ul><li>a robot wants to vists a Web site URL, say http://www.example.com/welcome.html.<li><p>Before it does so, it firsts checks for http://www.example.com/robots.txt, and finds:</p><div class="language-plaintext highlighter-rouge"><div class="code-header" text-data="plaintext"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>User-agent: *
Disallow: /
</pre></table></code></div></div><li><code class="language-plaintext highlighter-rouge">User-agent: \*</code> : this section applies to all robots.<ul><li>该项的值用于描述搜索引擎robot的名字<li>在”robots.txt”文件中，如果有多条User-agent记录说明有多个robot会受到该协议的限制，对该文件来说，至少要有一条User-agent记录。<li>如果该项的值设为*，则该协议对任何机器人均有效，在”robots.txt”文件中，<code class="language-plaintext highlighter-rouge">"User-agent：*"</code>只能有一条。</ul><li><code class="language-plaintext highlighter-rouge">Disallow: /</code> : tells the robot that it should not visit any pages on the site.<ul><li>该项的值用于描述不希望被访问到的一个URL，这个URL可以是一条完整的路径，也可以是部分的，任何以Disallow 开头的URL均不会被robot访问到。<li>例如<li><code class="language-plaintext highlighter-rouge">"Disallow: /help"</code> : <code class="language-plaintext highlighter-rouge">/help.html</code> 和 <code class="language-plaintext highlighter-rouge">/help/index.html</code> 都不允许搜索引擎访问<li><code class="language-plaintext highlighter-rouge">"Disallow: /help/"</code> : 则允许robot访问<code class="language-plaintext highlighter-rouge">/help.html</code>，而不能访问<code class="language-plaintext highlighter-rouge">/help/index.html</code>。<li>Disallow记录为空，说明该网站的所有部分都允许被访问<li>在”/robots.txt”文件中，至少要有一条Disallow记录。</ul><li><p><code class="language-plaintext highlighter-rouge">Allow</code>: 定义允许搜索引擎收录的地址</p><li><p><code class="language-plaintext highlighter-rouge">Crawl-delay</code>:支持Crawl-delay参数，设置为多少秒，以等待同服务器之间连续请求(网络爬虫的礼貌策略)</p><li>如果”/robots.txt”是一个空文件，则对于所有的搜索引擎robot，该网站都是开放的。</ul><p>There are two important considerations when using <code class="language-plaintext highlighter-rouge">/robots.txt</code>:</p><ul><li>robots can ignore your <code class="language-plaintext highlighter-rouge">/robots.txt</code>. Especially malware robots that scan the web for security vulnerabilities, and email address harvesters used by spammers will pay no attention.<li>the <code class="language-plaintext highlighter-rouge">/robots.txt</code> file is a publicly available file. Anyone can see what sections of your server you don’t want robots to use.<li>So don’t use <code class="language-plaintext highlighter-rouge">/robots.txt</code> to hide information.</ul><p>Can I block just bad robots?</p><blockquote><p>In theory yes, in practice, no. If the bad robot obeys /robots.txt, and you know the name it scans for in the User-Agent field. then you can create a section in your /robotst.txt to exclude it specifically. But almost all bad robots ignore /robots.txt, making that pointless. If the bad robot operates from a single IP address - block its access to your web server through <code class="language-plaintext highlighter-rouge">server configuration</code> or with a <code class="language-plaintext highlighter-rouge">network firewall</code>. If robots operate at lots of different IP addresses, such as hijacked PCs that are part of a large Botnet - becomes more difficult. The best option, use <code class="language-plaintext highlighter-rouge">advanced firewall rules configuration</code> that automatically block access to IP addresses that make many connections; - but that can hit good robots as well your bad robots.</p></blockquote><p>Why did this robot ignore my /robots.txt?</p><blockquote><p>these days it’s more likely that the robot is explicitly written to scan your site for information to abuse: it might be collecting email addresses to send email spam, look for forms to post links (“spamdexing”), or security holes to exploit.</p></blockquote><p>What are the security implications of /robots.txt?</p><blockquote><p>There is no law stating that /robots.txt must be obeyed, nor does it constitute a binding contract between site owner and user, but having a /robots.txt can be relevant in legal cases.</p></blockquote><p>Surely listing sensitive files is asking for trouble?</p><blockquote><p>listing pages or directories in the /robots.txt file may invite unintended access. There are two answers to this. The first answer is a workaround: You could put all the files you don’t want robots to visit in a separate sub directory, make that directory un-listable on the web (by configuring your server), then place your files in there, and list only the directory name in the /robots.txt. Now an ill-willed robot won’t traverse that directory unless you or someone else puts a direct link on the web to one of your files, and then it’s not /robots.txt fault. For example, rather than: <code class="language-plaintext highlighter-rouge">User-Agent: *</code> <code class="language-plaintext highlighter-rouge">Disallow: /foo.html</code> <code class="language-plaintext highlighter-rouge">Disallow: /bar.html</code> do: <code class="language-plaintext highlighter-rouge">User-Agent: *</code> <code class="language-plaintext highlighter-rouge">Disallow: /norobots/</code> make a “norobots” directory, put foo.html and bar.html into it, and configure your server to not generate a directory listing for that directory. attacker won’t be able to list the files in there However, in practice this is a bad idea – it’s too fragile. Someone may publish a link to your files on their site. Or it may turn up in a publicly accessible log file, say of you user’s proxy server, or maybe it will show up in someone’s web server log as a Referer. Or someone may misconfigure your server at some future date, “fixing” it to show a directory listing. Which leads me to the real answer: The real answer is that /robots.txt is not intended for access control, so don’t try to use it as such. Think of it as a “No Entry” sign, not a locked door. If you have files on your web site that you don’t want unauthorized people to access, then configure your server to do authentication, and configure appropriate authorization. Basic Authentication has been around since the early days of the web (and in e.g. Apache on UNIX is trivial to configure). Modern content management systems support access controls on individual pages and collections of resources.</p></blockquote><h2 id="how-to-create-a-robotstxt-file">How to create a /robots.txt file</h2><ul><li>The /robots.txt is a de-facto standard, and is not owned by any standards body.<li>The /robots.txt standard is not actively developed.</ul><h3 id="where-to-put-it">Where to put it</h3><p>in the top-level directory of your web server.</p><ul><li>When a robot looks for the “/robots.txt” file for URL, it strips the path component from the URL (everything from the first single slash), and puts “/robots.txt” in its place.<ul><li>For example<li>for http://www.example.com/shop/index.html<li>http://www.example.com/robots.txt</ul><li><p>Usually the same place where put your web site’s main “index.html” welcome page.</p><li>how to put the file there, depends on your web server software.<li>Remember to use all lower case for the filename: “robots.txt”, not “Robots.TXT.</ul><p>See also:</p><p>What program should I use to create /robots.txt</p><blockquote><p>You can use anything that produces a text file.</p><ul><li>On Microsoft Windows, use notepad.exe, wordpad.exe (Save as Text Document), or Microsoft Word (Save as Plain Text)<li>On the Macintosh, use TextEdit (Format-&gt;Make Plain Text, then Save as Western)<li>On Linux, vi or emacs</ul></blockquote><p>How do I use /robots.txt on a virtual host?</p><blockquote><p>The term “virtual host” is sometimes use to mean various different things: A “virtual host” web server uses the HTTP Host Header to distinguish requests to different domain names on the same IP address. In this case the fact that the domain is on a shared host makes no difference to a visitng robot, and you can put a /robots.txt file in the directory dedicated to your domain. A “virtual server” runs a separate operating system on a virtual machine, like VMWare or Xen. Again, to a robot that’s a separate computer.</p></blockquote><p>How do I use /robots.txt on a shared host?</p><blockquote><p>If you share a host with other people, and you have a URL like http://www.example.com/~username/ or http://www.example.com/username, then you can’t have your own /robots.txt file. If you want to use /robots.txt you’ll have to ask the host administrator to help you. If you want more control, switch to a provider with a virtual host.</p></blockquote><h3 id="what-to-put-in-it">What to put in it</h3><p>The “/robots.txt” file is a <code class="language-plaintext highlighter-rouge">text</code> file, with one or more records. Usually contains a single record looking like this:</p><div class="language-plaintext highlighter-rouge"><div class="code-header" text-data="plaintext"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>User-agent: *
Disallow: /cgi-bin/
Disallow: /tmp/
Disallow: /~joe/
</pre></table></code></div></div><ul><li>need a separate “Disallow” line for every URL prefix to exclude – cannot say “Disallow: /cgi-bin/ /tmp/” on a single line.<li>Also, you may not have blank lines in a record, as they are used to delimit multiple records.<li>globbing and regular expression are not supported in either the User-agent or Disallow lines.<li>The <code class="language-plaintext highlighter-rouge">'*'</code> in the User-agent field is a special value meaning “any robot”.<li>Specifically, you cannot have lines like <code class="language-plaintext highlighter-rouge">"User-agent: *bot*"</code>, <code class="language-plaintext highlighter-rouge">"Disallow: /tmp/*" or "Disallow: *.gif"</code>.</ul><h3 id="examples">examples:</h3><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
</pre><td class="rouge-code"><pre><span class="c1"># To exclude all robots from the entire server
</span><span class="n">User</span><span class="o">-</span><span class="n">agent</span><span class="p">:</span> <span class="o">*</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/</span>

<span class="c1"># To allow all robots complete access
</span><span class="n">User</span><span class="o">-</span><span class="n">agent</span><span class="p">:</span> <span class="o">*</span>
<span class="n">Disallow</span><span class="p">:</span>
<span class="p">(</span><span class="ow">or</span> <span class="n">just</span> <span class="n">create</span> <span class="n">an</span> <span class="n">empty</span> <span class="s">"/robots.txt"</span> <span class="nb">file</span><span class="p">,</span>
<span class="ow">or</span> <span class="n">dont</span> <span class="n">use</span> <span class="n">one</span> <span class="n">at</span> <span class="nb">all</span><span class="p">)</span>

<span class="c1"># To exclude all robots from part of the server
</span><span class="n">User</span><span class="o">-</span><span class="n">agent</span><span class="p">:</span> <span class="o">*</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/</span><span class="n">cgi</span><span class="o">-</span><span class="nb">bin</span><span class="o">/</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/</span><span class="n">junk</span><span class="o">/</span>

<span class="c1"># To exclude a single robot
</span><span class="n">User</span><span class="o">-</span><span class="n">agent</span><span class="p">:</span> <span class="n">BadBot</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/</span>

<span class="c1"># To allow a single robot
</span><span class="n">User</span><span class="o">-</span><span class="n">agent</span><span class="p">:</span> <span class="n">Google</span>
<span class="n">Disallow</span><span class="p">:</span>

<span class="n">User</span><span class="o">-</span><span class="n">agent</span><span class="p">:</span> <span class="o">*</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/</span>

<span class="c1"># To exclude all files except one
</span><span class="k">as</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">no</span> <span class="s">"Allow"</span> <span class="n">field</span><span class="p">.</span>
<span class="n">The</span> <span class="n">easy</span> <span class="n">way</span> <span class="ow">is</span> <span class="n">to</span> <span class="n">put</span> <span class="nb">all</span> <span class="n">files</span> <span class="n">to</span> <span class="n">be</span> <span class="n">disallowed</span> <span class="n">into</span> <span class="n">a</span> <span class="n">separate</span> <span class="n">directory</span><span class="p">,</span> <span class="n">say</span> <span class="s">"stuff"</span><span class="p">,</span> <span class="ow">and</span> <span class="n">leave</span> <span class="n">the</span> <span class="n">one</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">level</span> <span class="n">above</span> <span class="n">this</span> <span class="n">directory</span><span class="p">:</span>

<span class="n">User</span><span class="o">-</span><span class="n">agent</span><span class="p">:</span> <span class="o">*</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/~</span><span class="n">joe</span><span class="o">/</span><span class="n">stuff</span><span class="o">/</span>

<span class="n">Alternatively</span> <span class="n">you</span> <span class="n">can</span> <span class="n">explicitly</span> <span class="n">disallow</span> <span class="nb">all</span> <span class="n">disallowed</span> <span class="n">pages</span><span class="p">:</span>
<span class="n">User</span><span class="o">-</span><span class="n">agent</span><span class="p">:</span> <span class="o">*</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/~</span><span class="n">joe</span><span class="o">/</span><span class="n">junk</span><span class="p">.</span><span class="n">html</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/~</span><span class="n">joe</span><span class="o">/</span><span class="n">foo</span><span class="p">.</span><span class="n">html</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/~</span><span class="n">joe</span><span class="o">/</span><span class="n">bar</span><span class="p">.</span><span class="n">html</span>


<span class="n">User</span><span class="o">-</span><span class="n">agent</span><span class="p">:</span> <span class="o">*</span>
<span class="c1"># 这里的*代表的所有的搜索引擎种类，*是一个通配符
</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/</span><span class="n">admin</span><span class="o">/</span>
<span class="c1"># 这里定义是禁止爬寻admin目录下面的目录
</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/</span><span class="n">cgi</span><span class="o">-</span><span class="nb">bin</span><span class="o">/*</span><span class="p">.</span><span class="n">htm</span>
<span class="c1"># 禁止访问/cgi-bin/目录下的所有以".htm"为后缀的URL(包含子目录)。
</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/*</span><span class="err">?</span><span class="o">*</span>
<span class="c1"># 禁止访问网站中所有的动态页面
</span>
<span class="n">Disallow</span><span class="p">:</span> <span class="o">/</span><span class="n">jpg</span><span class="err">$</span>
<span class="c1"># 禁止抓取网页所有的.jpg格式的图片
</span>
<span class="n">Disallow</span><span class="p">:</span><span class="o">/</span><span class="n">ab</span><span class="o">/</span><span class="n">adc</span><span class="p">.</span><span class="n">html</span>
<span class="c1"># 禁止爬去ab文件夹下面的adc.html文件。
</span>
<span class="n">Allow</span><span class="p">:</span> <span class="o">/</span><span class="n">cgi</span><span class="o">-</span><span class="nb">bin</span><span class="o">/</span><span class="err">　</span>
<span class="c1"># 这里定义是允许爬寻cgi-bin目录下面的目录
</span>
<span class="n">Allow</span><span class="p">:</span> <span class="o">/</span><span class="n">tmp</span>
<span class="c1"># 这里定义是允许爬寻tmp的整个目录
</span>
<span class="n">Allow</span><span class="p">:</span> <span class="p">.</span><span class="n">htm</span><span class="err">$</span>
<span class="c1"># 仅允许访问以".htm"为后缀的URL。
</span>
<span class="n">Allow</span><span class="p">:</span> <span class="p">.</span><span class="n">gif</span><span class="err">$</span>
<span class="c1"># 允许抓取网页和gif格式图片
</span>
<span class="n">Crawl</span><span class="o">-</span><span class="n">delay</span><span class="p">:</span> <span class="mi">10</span>


</pre></table></code></div></div><h2 id="about-the-robots-meta-tag">About the Robots <code class="language-plaintext highlighter-rouge">&lt;META&gt;</code> tag</h2><p>use a special HTML<meta /> tag to tell robots not to index the content of a page, and/or not scan it for links to follow.</p><div class="language-plaintext highlighter-rouge"><div class="code-header" text-data="plaintext"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>&lt;html&gt;
&lt;head&gt;
&lt;title&gt;...&lt;/title&gt;
`&lt;META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW"&gt;`
&lt;/head&gt;
</pre></table></code></div></div><p>There are two important considerations when using the robots <code class="language-plaintext highlighter-rouge">&lt;META&gt;</code> tag:</p><ul><li>robots can ignore your<meta /> tag. Especially malware robots that scan the web for security vulnerabilities, and email address harvesters used by spammers will pay no attention.<li>the <code class="language-plaintext highlighter-rouge">NOFOLLOW</code> directive only applies to links on this page. It’s entirely likely that a robot might find the same links on some other page without a <code class="language-plaintext highlighter-rouge">NOFOLLOW</code> (perhaps on some other site), and so still arrives at your undesired page.<li>Don’t confuse this NOFOLLOW with the rel=”nofollow” link attribute.</ul><p>Like the /robots.txt, the robots META tag is a de-facto standard. It originated from a “birds of a feather” meeting at a 1996 distributed indexing workshop, and was described in meeting notes.</p><p>The META tag is also described in the HTML 4.01 specification, Appendix B.4.1.</p><h3 id="where-to-put-it-1">Where to put it</h3><p>Like any <code class="language-plaintext highlighter-rouge">&lt;META&gt;</code> tag it should be placed in the HEAD section of an HTML page</p><p>You should put it in every page on your site, because a robot can encounter a deep link to any page on your site.</p><h3 id="what-to-put-into-it">What to put into it</h3><p>The “NAME” attribute must be “ROBOTS”.</p><ul><li>Valid values for the “CONTENT” attribute are: “INDEX”, “NOINDEX”, “FOLLOW”, “NOFOLLOW”.<li>Multiple comma-separated values are allowed, but obviously only some combinations make sense. If there is no robots<meta /> tag, the default is “INDEX,FOLLOW”, so there’s no need to spell that out. That leaves:</ul><div class="language-plaintext highlighter-rouge"><div class="code-header" text-data="plaintext"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>&lt;META NAME="ROBOTS" CONTENT="NOINDEX, FOLLOW"&gt;
&lt;META NAME="ROBOTS" CONTENT="INDEX, NOFOLLOW"&gt;
&lt;META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW"&gt;
</pre></table></code></div></div><p>.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/web/'>Web</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/web/" class="post-tag no-text-decoration" >Web</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=The Web Robots Pages - Grace&url=https://ocholuo.github.io//posts/robots/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=The Web Robots Pages - Grace&u=https://ocholuo.github.io//posts/robots/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=The Web Robots Pages - Grace&url=https://ocholuo.github.io//posts/robots/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Amazon-CloudFront/">AWS Lab - AWS CloudFront</a><li><a href="/posts/Alexa-1stSkill/">AWS Alex First Skill - RedVelvet Time</a><li><a href="/posts/NetworkProtocol-SSL-TLS-Handshake/">NetworkProtocol SSL/TLS Handshake</a><li><a href="/posts/pythonCrash/">Python Crash</a><li><a href="/posts/%E4%B8%80%E5%8F%A5%E8%AF%9D%E8%A7%A3%E9%87%8AAWS/">AWS - 一句话解释AWS</a><li><a href="/posts/GKE/">GCP - Google Cloud Computing - Kubernetes and Kubernetes Engine</a><li><a href="/posts/Go-Note/">Go Note</a><li><a href="/posts/SCPs/">AWS - IdenAccessManage - SCPs (Service Control Policies)</a><li><a href="/posts/CompanyBenefit/">Company Benefit</a><li><a href="/posts/Encryption-SSL&TLS/">Cryptography - SSL/TLS Encryption</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/aws/">AWS</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/cyberattack/">CyberAttack</a> <a class="post-tag" href="/tags/lab/">Lab</a> <a class="post-tag" href="/tags/cyberattacktools/">CyberAttackTools</a> <a class="post-tag" href="/tags/gcp/">GCP</a> <a class="post-tag" href="/tags/sysadmin/">Sysadmin</a> <a class="post-tag" href="/tags/java/">Java</a> <a class="post-tag" href="/tags/network/">Network</a> <a class="post-tag" href="/tags/soc/">SOC</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/HTTP-Header/"><div class="card-body"> <span class="timeago small" >Apr 25, 2020<i class="unloaded">2020-04-25T11:11:11-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>HTTP Header</h3><div class="text-muted small"><p> HTTP Header Pragma WWW-Authenticate response header HTTP Header Pragma The Pragma HTTP/1.0 general header is an implementation-specific header that may have vari...</p></div></div></a></div><div class="card"> <a href="/posts/HTTP-Referrer/"><div class="card-body"> <span class="timeago small" >Apr 25, 2020<i class="unloaded">2020-04-25T11:11:11-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>HTTP Referer</h3><div class="text-muted small"><p> HTTP Referer Referer 的含义 Referer 的发生场景 Referer 的作用 rel属性 Referrer Policy 的值 Referrer Policy 的用法 退出页面重定向 ref http://www.ruanyif...</p></div></div></a></div><div class="card"> <a href="/posts/HTTP-Status-Code/"><div class="card-body"> <span class="timeago small" >Apr 25, 2020<i class="unloaded">2020-04-25T11:11:11-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>HTTP status code</h3><div class="text-muted small"><p> HTTP Status Code 1xx: Information 2xx: Successful 3xx: Redirection 4xx: Client Error 5xx: Server Error HTTP Status Code 1xx: Information ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/JPMorganChase-SDE-Virtual-Experience/" class="btn btn-outline-primary" prompt="Older"><p>JPMorganChase SDE Virtual Experience</p></a> <a href="/posts/Authentication/" class="btn btn-outline-primary" prompt="Newer"><p>Basic - Authentication</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/ocholuo">Grace JyL</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/aws/">AWS</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/cyberattack/">CyberAttack</a> <a class="post-tag" href="/tags/lab/">Lab</a> <a class="post-tag" href="/tags/cyberattacktools/">CyberAttackTools</a> <a class="post-tag" href="/tags/gcp/">GCP</a> <a class="post-tag" href="/tags/sysadmin/">Sysadmin</a> <a class="post-tag" href="/tags/java/">Java</a> <a class="post-tag" href="/tags/network/">Network</a> <a class="post-tag" href="/tags/soc/">SOC</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://ocholuo.github.io/{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-179830187-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-179830187-1'); }); </script>
