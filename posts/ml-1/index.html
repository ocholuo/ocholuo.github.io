<!DOCTYPE html><html lang="en" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="pv-proxy-endpoint" content="https://myochosite-291718.appspot.com/query?id=ahNwfm15b2Nob3NpdGUtMjkxNzE4chULEghBcGlRdWVyeRiAgIDo14eBCgw"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="ML - 1st - Intro to Machine Learning" /><meta property="og:locale" content="en" /><meta name="description" content="Intro to Machine Learning How Models Work over all Your First Machine Learning Model - DecisionTreeRegressor Model Validation Mean Absolute Error (MAE) Underfitting and Overfitting Random Forests -RandomForestRegressor example" /><meta property="og:description" content="Intro to Machine Learning How Models Work over all Your First Machine Learning Model - DecisionTreeRegressor Model Validation Mean Absolute Error (MAE) Underfitting and Overfitting Random Forests -RandomForestRegressor example" /><link rel="canonical" href="https://ocholuo.github.io//posts/ml-1/" /><meta property="og:url" content="https://ocholuo.github.io//posts/ml-1/" /><meta property="og:site_name" content="Grace" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-08-11T11:11:11-04:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="ML - 1st - Intro to Machine Learning" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-01-02T18:26:10-05:00","datePublished":"2021-08-11T11:11:11-04:00","description":"Intro to Machine Learning How Models Work over all Your First Machine Learning Model - DecisionTreeRegressor Model Validation Mean Absolute Error (MAE) Underfitting and Overfitting Random Forests -RandomForestRegressor example","headline":"ML - 1st - Intro to Machine Learning","mainEntityOfPage":{"@type":"WebPage","@id":"https://ocholuo.github.io//posts/ml-1/"},"url":"https://ocholuo.github.io//posts/ml-1/"}</script><title>ML - 1st - Intro to Machine Learning | Grace</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Grace"><meta name="application-name" content="Grace"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://myochosite-291718.appspot.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://myochosite-291718.appspot.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/huoye.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Grace</a></div><div class="site-subtitle font-italic">2023 Mar 14 updated</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/ocholuo" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['',''].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>ML - 1st - Intro to Machine Learning</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>ML - 1st - Intro to Machine Learning</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Grace JyL </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Aug 11, 2021, 11:11 AM -0400" >Aug 11, 2021<i class="unloaded">2021-08-11T11:11:11-04:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Mon, Jan 2, 2023, 3:26 PM -0800" >Jan 2<i class="unloaded">2023-01-02T18:26:10-05:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2656 words">14 min read</span> <span id="pv" class="pageviews"> <i class="fas fa-spinner fa-spin fa-fw"></i> </span> views</div></div><div class="post-content"><ul><li><a href="#intro-to-machine-learning">Intro to Machine Learning</a><ul><li><a href="#how-models-work">How Models Work</a><li><a href="#over-all">over all</a><li><a href="#your-first-machine-learning-model---decisiontreeregressor">Your First Machine Learning Model - <code class="language-plaintext highlighter-rouge">DecisionTreeRegressor</code></a><li><a href="#model-validation">Model Validation</a><ul><li><a href="#mean-absolute-error-mae">Mean Absolute Error (MAE)</a></ul><li><a href="#underfitting-and-overfitting">Underfitting and Overfitting</a><li><a href="#random-forests--randomforestregressor">Random Forests -<code class="language-plaintext highlighter-rouge">RandomForestRegressor</code></a><li><a href="#example">example</a></ul><li>ref:<ul><li>https://www.kaggle.com/lgraceye/exercise-explore-your-data/edit</ul></ul><hr /><h1 id="intro-to-machine-learning">Intro to Machine Learning</h1><hr /><h2 id="how-models-work">How Models Work</h2><p>First Decision Trees</p><ul><li>fitting or training the model.<ul><li>capturing patterns from data is called<li>We use data to decide how to break the houses into two groups, and then again to determine the predicted price in each group.</ul><li>The data used to fit the model is called the training data.<li>After the model has been fit, apply it to new data to predict<li>The point at the bottom where we make a prediction is called a leaf.</ul><p>The steps to building and using a model are:</p><ul><li>Define: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.<li>Fit: Capture patterns from provided data. This is the heart of modeling.<li>Predict: Just what it sounds like<li>Evaluate: Determine how accurate the model’s predictions are.</ul><hr /><h2 id="over-all">over all</h2><ol><li>notebook</ol><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="c1"># Set up code checking
</span><span class="kn">from</span> <span class="n">learntools.core</span> <span class="kn">import</span> <span class="n">binder</span>
<span class="n">binder</span><span class="p">.</span><span class="nf">bind</span><span class="p">(</span><span class="nf">globals</span><span class="p">())</span>
<span class="kn">from</span> <span class="n">learntools.machine_learning.ex7</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Set up filepaths
</span><span class="kn">import</span> <span class="n">os</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="s">"../input/train.csv"</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="nf">symlink</span><span class="p">(</span><span class="s">"../input/home-data-for-ml-course/train.csv"</span><span class="p">,</span> <span class="s">"../input/train.csv"</span><span class="p">)</span>
    <span class="n">os</span><span class="p">.</span><span class="nf">symlink</span><span class="p">(</span><span class="s">"../input/home-data-for-ml-course/test.csv"</span><span class="p">,</span> <span class="s">"../input/test.csv"</span><span class="p">)</span>
</pre></table></code></div></div><ol><li>get the select data</ol><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># save filepath to variable
</span><span class="n">test_file_path</span> <span class="o">=</span> <span class="s">'../input/melbourne-housing-snapshot/melb_data.csv'</span>

<span class="c1"># pd.read_csv(path)
# read the data and store data in DataFrame titled test_data
</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">test_file_path</span><span class="p">)</span>

<span class="c1"># .describe()
# print a summary of the data in Melbourne data
</span><span class="n">test_data</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>

<span class="c1"># Selecting Data for Modeling
</span><span class="n">test_data</span><span class="p">.</span><span class="n">columns</span>

<span class="c1"># Selecting The Prediction Target
</span><span class="n">y</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">.</span><span class="n">Price</span>

<span class="c1"># Choosing "Features"
</span><span class="n">test_features</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Rooms'</span><span class="p">,</span> <span class="s">'Bathroom'</span><span class="p">,</span> <span class="s">'Landsize'</span><span class="p">,</span> <span class="s">'Latitude'</span><span class="p">,</span> <span class="s">'Longtitude'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">test_features</span><span class="p">]</span>
<span class="n">X</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>

<span class="c1"># shows the top few rows.
</span><span class="n">X</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</pre></table></code></div></div><ol><li>setup ML</ol><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
</pre><td class="rouge-code"><pre><span class="c1"># defining a decision tree model with scikit-learn
# fitting it with the features and target variable.
</span><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="c1"># ====================== Define model
# Specify a number for random_state to ensure same results each run
</span><span class="n">test_model</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Fit model
</span><span class="n">test_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># Predict
</span><span class="n">predicted_prices</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="nf">print</span><span class="p">(</span><span class="s">"Making predictions for the following 5 houses:"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="nf">head</span><span class="p">())</span>
<span class="c1">#    Rooms  Bathroom  Landsize  Latitude  Longtitude
# 1      2       1.0     156.0   -37.8079    144.9934
# 2      3       2.0     134.0   -37.8093    144.9944
# 4      4       1.0     120.0   -37.8072    144.9941
# 6      3       2.0     245.0   -37.8024    144.9993
# 7      2       1.0     256.0   -37.8060    144.9954
</span>

<span class="c1"># .predict()
</span><span class="nf">print</span><span class="p">(</span><span class="s">"The predictions are"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">test_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="nf">head</span><span class="p">()))</span>
<span class="c1"># The predictions are
# [1035000. 1465000. 1600000. 1876000. 1636000.]
</span></pre></table></code></div></div><ol><li>calculate MAE<ol><li>use train_data to get the model<li>use val_X to predict preds_val_y<li>mae = mean_absolute_error(val_y, preds_val_y)</ol></ol><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">preds_val</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
    <span class="nf">return</span><span class="p">(</span><span class="n">mae</span><span class="p">)</span>


<span class="c1"># ====================== calculate the mean absolute error 1
</span><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predicted_prices</span><span class="p">)</span>


<span class="c1"># ====================== calculate the mean absolute error 2
</span><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Define model
</span><span class="n">test_model</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">()</span>

<span class="c1"># Fit model
</span><span class="n">test_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>

<span class="c1"># Predict
</span><span class="n">val_predictions</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>

<span class="c1"># get predicted prices on validation data
</span><span class="nf">print</span><span class="p">(</span><span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">val_predictions</span><span class="p">))</span>

</pre></table></code></div></div><ol><li>setup the leaf</ol><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">candidate_max_leaf_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">{</span><span class="n">leaf_size</span><span class="p">:</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">leaf_size</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span><span class="p">)</span> <span class="k">for</span> <span class="n">leaf_size</span> <span class="ow">in</span> <span class="n">candidate_max_leaf_nodes</span><span class="p">}</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">scores</span><span class="p">.</span><span class="n">get</span><span class="p">)</span>

<span class="c1"># Fill in argument to make optimal size and uncomment
</span><span class="n">final_model</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">best_tree_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># fit the final model and uncomment the next two lines
</span><span class="n">final_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Check your answer
</span><span class="n">step_2</span><span class="p">.</span><span class="nf">check</span><span class="p">()</span>
</pre></table></code></div></div><ol><li>Random Forests</ol><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="c1"># build a random forest model
</span><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="n">forest_model</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">forest_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
<span class="n">melb_preds</span> <span class="o">=</span> <span class="n">forest_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">melb_preds</span><span class="p">))</span>
</pre></table></code></div></div><hr /><h2 id="your-first-machine-learning-model---decisiontreeregressor">Your First Machine Learning Model - <code class="language-plaintext highlighter-rouge">DecisionTreeRegressor</code></h2><p>Building Model</p><ul><li>Many machine learning models allow some randomness in model training. Specifying a number for random_state ensures you get the same results in each run. This is considered a good practice. You use any number, and model quality won’t depend meaningfully on exactly what value you choose.</ul><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">test_file_path</span> <span class="o">=</span> <span class="s">'../input/melbourne-housing-snapshot/melb_data.csv'</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">test_file_path</span><span class="p">)</span>

<span class="c1"># Selecting Data for Modeling
</span><span class="n">test_data</span><span class="p">.</span><span class="n">columns</span>

<span class="c1"># dropna drops missing values (think of na as "not available")
</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Selecting The Prediction Target
</span><span class="n">y</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">.</span><span class="n">Price</span>

<span class="c1"># Choosing "Features"
</span><span class="n">test_features</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Rooms'</span><span class="p">,</span> <span class="s">'Bathroom'</span><span class="p">,</span> <span class="s">'Landsize'</span><span class="p">,</span> <span class="s">'Latitude'</span><span class="p">,</span> <span class="s">'Longtitude'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">test_features</span><span class="p">]</span>
<span class="n">X</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>

<span class="c1"># shows the top few rows.
</span><span class="n">X</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>

<span class="c1"># defining a decision tree model with scikit-learn
# fitting it with the features and target variable.
</span><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="c1"># Define model.
# Specify a number for random_state to ensure same results each run
</span><span class="n">test_model</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Fit model
</span><span class="n">test_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="s">"Making predictions for the following 5 houses:"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="nf">head</span><span class="p">())</span>
<span class="c1">#    Rooms  Bathroom  Landsize  Latitude  Longtitude
# 1      2       1.0     156.0   -37.8079    144.9934
# 2      3       2.0     134.0   -37.8093    144.9944
# 4      4       1.0     120.0   -37.8072    144.9941
# 6      3       2.0     245.0   -37.8024    144.9993
# 7      2       1.0     256.0   -37.8060    144.9954
</span><span class="nf">print</span><span class="p">(</span><span class="s">"The predictions are"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">test_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="nf">head</span><span class="p">()))</span>
<span class="c1"># The predictions are
# [1035000. 1465000. 1600000. 1876000. 1636000.]
</span>
</pre></table></code></div></div><hr /><h2 id="model-validation">Model Validation</h2><blockquote><p>The prediction error is:</p><p>error=actual−predicted</p></blockquote><h3 id="mean-absolute-error-mae">Mean Absolute Error (MAE)</h3><p>summarizing model quality</p><p>To calculate MAE:</p><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre><td class="rouge-code"><pre>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># ====================== Load data
</span><span class="n">test_file_path</span> <span class="o">=</span> <span class="s">'../input/melbourne-housing-snapshot/melb_data.csv'</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">test_file_path</span><span class="p">)</span>

<span class="c1"># Filter rows with missing price values
</span><span class="n">filtered_test_data</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Choose target and features
</span><span class="n">y</span> <span class="o">=</span> <span class="n">filtered_test_data</span><span class="p">.</span><span class="n">Price</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Rooms'</span><span class="p">,</span> <span class="s">'Bathroom'</span><span class="p">,</span> <span class="s">'Landsize'</span><span class="p">,</span> <span class="s">'BuildingArea'</span><span class="p">,</span>  <span class="s">'YearBuilt'</span><span class="p">,</span> <span class="s">'Latitude'</span><span class="p">,</span> <span class="s">'Longtitude'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">filtered_test_data</span><span class="p">[</span><span class="n">test_features</span><span class="p">]</span>


<span class="c1"># ====================== Define model
</span><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="n">test_model</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">()</span>

<span class="c1"># Fit model
</span><span class="n">test_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Predict
</span><span class="n">predicted_prices</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="c1"># ====================== calculate the mean absolute error:
</span><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predicted_prices</span><span class="p">)</span>
</pre></table></code></div></div><p>The most straightforward way to do this is to exclude some data from the model-building process, and then use those to test the model’s accuracy on data it hasn’t seen before. This data is called validation data.</p><p>The scikit-learn library has a function <code class="language-plaintext highlighter-rouge">train_test_split</code> to break up the data into two pieces.</p><ul><li>use some data as training data to fit the model<li>and use the other data as validation data to calculate <code class="language-plaintext highlighter-rouge">mean_absolute_error</code>.</ul><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># split data into training and validation data, for both features and target
# The split is based on a random number generator. Supplying a numeric value to
# the random_state argument guarantees we get the same split every time we
# run this script.
</span><span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Define model
</span><span class="n">test_model</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">()</span>

<span class="c1"># Fit model
</span><span class="n">test_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>

<span class="c1"># Predict
</span><span class="n">val_predictions</span> <span class="o">=</span> <span class="n">test_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>

<span class="c1"># get predicted prices on validation data
</span><span class="nf">print</span><span class="p">(</span><span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">val_predictions</span><span class="p">))</span>
</pre></table></code></div></div><hr /><h2 id="underfitting-and-overfitting">Underfitting and Overfitting</h2><p><strong>Experimenting With Different Models</strong> Now that you have a reliable way to measure model accuracy, you can experiment with alternative models and see which gives the best predictions. But what alternatives do you have for models?</p><p>In scikit-learn’s documentation that the <strong>decision tree model</strong> has many options. The most important options determine the tree’s <strong>depth</strong>, a measure of how many splits it makes before coming to a prediction. This is a relatively shallow tree</p><p><strong>overfitting</strong></p><ul><li>When we divide the houses amongst many leaves, we also have fewer houses in each leaf.<li>Leaves with very few houses will make predictions that are quite close to those homes’ actual values, but they may make very unreliable predictions for new data (because each prediction is based on only a few houses).<li>This is a phenomenon called overfitting, where a model matches the training data almost perfectly, but does poorly in validation and other new data.</ul><p><strong>underfitting</strong></p><ul><li>if we make our tree very shallow, it doesn’t divide up the houses into very distinct groups.<li>if a tree divides houses into only 2 or 4, each group still has a wide variety of houses.<li>Resulting predictions may be far off for most houses, even in the training data (and it will be bad in validation too for the same reason).<li>When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called underfitting.</ul><p>Since we care about accuracy on new data, which we estimate from our validation data, we want to find the sweet spot between underfitting and overfitting. Visually, we want the low point of the (red) validation curve in the figure below.</p><p><img data-proofer-ignore data-src="https://i.imgur.com/WUSECIc.png" alt="2q85n9s" /></p><p>There are a few alternatives for controlling the tree depth, and many allow for some routes through the tree to have greater depth than other routes. But the max_leaf_nodes argument provides a very sensible way to control overfitting vs underfitting. The more leaves we allow the model to make, the more we move from the underfitting area in the above graph to the overfitting area.</p><p>We can use a utility function to help compare MAE scores from different values for max_leaf_nodes:</p><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
</pre><td class="rouge-code"><pre>
<span class="c1"># Code you have previously used to load data
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>


<span class="c1"># Data Loading Code Runs At This Point
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="c1"># Load data
</span><span class="n">test_file_path</span> <span class="o">=</span> <span class="s">'../input/melbourne-housing-snapshot/melb_data.csv'</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">test_file_path</span><span class="p">)</span>
<span class="c1"># Filter rows with missing values
</span><span class="n">filtered_test_data</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Choose target and features
</span><span class="n">y</span> <span class="o">=</span> <span class="n">filtered_test_data</span><span class="p">.</span><span class="n">Price</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Rooms'</span><span class="p">,</span> <span class="s">'Bathroom'</span><span class="p">,</span> <span class="s">'Landsize'</span><span class="p">,</span> <span class="s">'BuildingArea'</span><span class="p">,</span> <span class="s">'YearBuilt'</span><span class="p">,</span> <span class="s">'Latitude'</span><span class="p">,</span> <span class="s">'Longtitude'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">filtered_test_data</span><span class="p">[</span><span class="n">test_features</span><span class="p">]</span>



<span class="c1"># split data into training and validation data, for both features and target
</span><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>



<span class="c1"># The data is loaded into train_X, val_X, train_y and val_y using the code you've already seen (and which you've already written).
</span><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="k">def</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">preds_val</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
    <span class="nf">return</span><span class="p">(</span><span class="n">mae</span><span class="p">)</span>

<span class="c1"># use a for-loop to compare the accuracy of models built with different values for max_leaf_nodes.
# compare MAE with differing values of max_leaf_nodes
</span><span class="k">for</span> <span class="n">max_leaf_nodes</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">5000</span><span class="p">]:</span>
    <span class="n">my_mae</span> <span class="o">=</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"Max leaf nodes: %d  </span><span class="se">\t\t</span><span class="s"> Mean Absolute Error:  %d"</span> <span class="o">%</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">my_mae</span><span class="p">))</span>
<span class="c1"># Max leaf nodes: 5  		 Mean Absolute Error:  347380
# Max leaf nodes: 50  		 Mean Absolute Error:  258171
# Max leaf nodes: 500  		 Mean Absolute Error:  243495
# Max leaf nodes: 5000  		 Mean Absolute Error:  254983
# Of the options listed, 500 is the optimal number of leaves.
</span></pre></table></code></div></div><p>Step 2: Fit Model Using All Data</p><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">candidate_max_leaf_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">{</span><span class="n">leaf_size</span><span class="p">:</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">leaf_size</span><span class="p">,</span> <span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span><span class="p">)</span> <span class="k">for</span> <span class="n">leaf_size</span> <span class="ow">in</span> <span class="n">candidate_max_leaf_nodes</span><span class="p">}</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">scores</span><span class="p">.</span><span class="n">get</span><span class="p">)</span>

<span class="c1"># Fill in argument to make optimal size and uncomment
</span><span class="n">final_model</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">best_tree_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># fit the final model and uncomment the next two lines
</span><span class="n">final_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Check your answer
</span><span class="n">step_2</span><span class="p">.</span><span class="nf">check</span><span class="p">()</span>
</pre></table></code></div></div><hr /><h2 id="random-forests--randomforestregressor">Random Forests -<code class="language-plaintext highlighter-rouge">RandomForestRegressor</code></h2><ul><li>Decision trees leave you with a difficult decision.<li>A deep tree with lots of leaves will overfit because each prediction is coming from historical data from only the few houses at its leaf.<li><p>But a shallow tree with few leaves will perform poorly because it fails to capture as many distinctions in the raw data.</p><li>many models have clever ideas that can lead to better performance. We’ll look at the <strong>random forest</strong> as an example.<li>The random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree.<li>It generally has much better predictive accuracy than a single decision tree and it works well with default parameters.</ul><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="c1"># Load data
</span><span class="n">test_file_path</span> <span class="o">=</span> <span class="s">'../input/melbourne-housing-snapshot/melb_data.csv'</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">test_file_path</span><span class="p">)</span>
<span class="c1"># Filter rows with missing values
</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Choose target and features
</span><span class="n">y</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">.</span><span class="n">Price</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Rooms'</span><span class="p">,</span> <span class="s">'Bathroom'</span><span class="p">,</span> <span class="s">'Landsize'</span><span class="p">,</span> <span class="s">'BuildingArea'</span><span class="p">,</span> <span class="s">'YearBuilt'</span><span class="p">,</span> <span class="s">'Latitude'</span><span class="p">,</span> <span class="s">'Longtitude'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">test_features</span><span class="p">]</span>


<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="c1"># split data into training and validation data, for both features and target
# The split is based on a random number generator. Supplying a numeric value to
# the random_state argument guarantees we get the same split every time we
# run this script.
</span><span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>


<span class="c1"># build a random forest model similarly to how we built a decision tree in scikit-learn - this time using the RandomForestRegressor class instead of DecisionTreeRegressor.
</span><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="n">forest_model</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">forest_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
<span class="n">melb_preds</span> <span class="o">=</span> <span class="n">forest_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">melb_preds</span><span class="p">))</span>
</pre></table></code></div></div><hr /><h2 id="example">example</h2><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre><td class="rouge-code"><pre><span class="c1"># Set up code checking
</span><span class="kn">from</span> <span class="n">learntools.core</span> <span class="kn">import</span> <span class="n">binder</span>
<span class="n">binder</span><span class="p">.</span><span class="nf">bind</span><span class="p">(</span><span class="nf">globals</span><span class="p">())</span>
<span class="kn">from</span> <span class="n">learntools.machine_learning.ex7</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Set up filepaths
</span><span class="kn">import</span> <span class="n">os</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">exists</span><span class="p">(</span><span class="s">"../input/train.csv"</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="nf">symlink</span><span class="p">(</span><span class="s">"../input/home-data-for-ml-course/train.csv"</span><span class="p">,</span> <span class="s">"../input/train.csv"</span><span class="p">)</span>
    <span class="n">os</span><span class="p">.</span><span class="nf">symlink</span><span class="p">(</span><span class="s">"../input/home-data-for-ml-course/test.csv"</span><span class="p">,</span> <span class="s">"../input/test.csv"</span><span class="p">)</span>


<span class="c1"># Import helpful libraries
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Load the data, and separate the target
</span><span class="n">iowa_file_path</span> <span class="o">=</span> <span class="s">'../input/train.csv'</span>
<span class="n">home_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">iowa_file_path</span><span class="p">)</span>

<span class="c1"># Create X (After completing the exercise, you can return to modify this line!)
</span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s">'LotArea'</span><span class="p">,</span> <span class="s">'YearBuilt'</span><span class="p">,</span> <span class="s">'1stFlrSF'</span><span class="p">,</span> <span class="s">'2ndFlrSF'</span><span class="p">,</span> <span class="s">'FullBath'</span><span class="p">,</span> <span class="s">'BedroomAbvGr'</span><span class="p">,</span> <span class="s">'TotRmsAbvGrd'</span><span class="p">]</span>

<span class="c1"># Select columns corresponding to features, and preview the data
</span><span class="n">y</span> <span class="o">=</span> <span class="n">home_data</span><span class="p">.</span><span class="n">SalePrice</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">home_data</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">X</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>

<span class="c1"># Split into validation and training data
</span><span class="n">train_X</span><span class="p">,</span> <span class="n">val_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">val_y</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Define a random forest model
</span><span class="n">rf_model</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rf_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
<span class="n">rf_val_predictions</span> <span class="o">=</span> <span class="n">rf_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
<span class="n">rf_val_mae</span> <span class="o">=</span> <span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">rf_val_predictions</span><span class="p">,</span> <span class="n">val_y</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="s">"Validation MAE for Random Forest Model: {:,.0f}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">rf_val_mae</span><span class="p">))</span>
</pre></table></code></div></div><p>The code cell above trains a Random Forest model on train_X and train_y.</p><p>Use the code cell below to build a Random Forest model and train it on all of X and y.</p><div class="language-py highlighter-rouge"><div class="code-header" text-data="py"><button data-original-title="Copied!"><i class="far fa-clone"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre><td class="rouge-code"><pre>

<span class="c1"># To improve accuracy, create a new Random Forest model which you will train on all training data
</span><span class="n">rf_model_on_full_data</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">()</span>

<span class="c1"># fit rf_model_on_full_data on all data from the training data
</span><span class="n">rf_model_on_full_data</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># path to file you will use for predictions
</span><span class="n">test_data_path</span> <span class="o">=</span> <span class="s">'../input/test.csv'</span>

<span class="c1"># read test data file using pandas
</span><span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">test_data_path</span><span class="p">)</span>

<span class="c1"># create test_X which comes from test_data but includes only the columns you used for prediction.
# The list of columns is stored in a variable called features
</span><span class="n">test_X</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>

<span class="c1"># make predictions which we will submit.
</span><span class="n">test_preds</span> <span class="o">=</span> <span class="n">rf_model_on_full_data</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>

<span class="c1"># Run the code to save predictions in the format used for competition scoring
</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="s">'Id'</span><span class="p">:</span> <span class="n">test_data</span><span class="p">.</span><span class="n">Id</span><span class="p">,</span>
                       <span class="s">'SalePrice'</span><span class="p">:</span> <span class="n">test_preds</span><span class="p">})</span>
<span class="n">output</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="s">'submission.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></table></code></div></div><p>.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/00codenote/'>00CodeNote</a>, <a href='/categories/mlnote/'>MLNote</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/ml/" class="post-tag no-text-decoration" >ML</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=ML - 1st - Intro to Machine Learning - Grace&url=https://ocholuo.github.io//posts/ml-1/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=ML - 1st - Intro to Machine Learning - Grace&u=https://ocholuo.github.io//posts/ml-1/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=ML - 1st - Intro to Machine Learning - Grace&url=https://ocholuo.github.io//posts/ml-1/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Amazon-CloudFront/">AWS Lab - AWS CloudFront</a><li><a href="/posts/Alexa-1stSkill/">AWS Alex First Skill - RedVelvet Time</a><li><a href="/posts/NetworkProtocol-SSL-TLS-Handshake/">NetworkProtocol SSL/TLS Handshake</a><li><a href="/posts/pythonCrash/">Python Crash</a><li><a href="/posts/%E4%B8%80%E5%8F%A5%E8%AF%9D%E8%A7%A3%E9%87%8AAWS/">AWS - 一句话解释AWS</a><li><a href="/posts/GKE/">GCP - Google Cloud Computing - Kubernetes and Kubernetes Engine</a><li><a href="/posts/Go-Note/">Go Note</a><li><a href="/posts/SCPs/">AWS - IdenAccessManage - SCPs (Service Control Policies)</a><li><a href="/posts/CompanyBenefit/">Company Benefit</a><li><a href="/posts/Encryption-SSL&TLS/">Cryptography - SSL/TLS Encryption</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/aws/">AWS</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/cyberattack/">CyberAttack</a> <a class="post-tag" href="/tags/lab/">Lab</a> <a class="post-tag" href="/tags/cyberattacktools/">CyberAttackTools</a> <a class="post-tag" href="/tags/gcp/">GCP</a> <a class="post-tag" href="/tags/sysadmin/">Sysadmin</a> <a class="post-tag" href="/tags/java/">Java</a> <a class="post-tag" href="/tags/network/">Network</a> <a class="post-tag" href="/tags/soc/">SOC</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/ml-2/"><div class="card-body"> <span class="timeago small" >Aug 11, 2021<i class="unloaded">2021-08-11T11:11:11-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML - 2nd - Intermediate Machine Learning</h3><div class="text-muted small"><p> ML - Intermediate Machine Learning Missing Values Three Approaches Approach 1 (Drop Columns with Missing Values) 删除无数值列 Approach 2 (Imputation) ...</p></div></div></a></div><div class="card"> <a href="/posts/ml-lab-01-Titanic-ML-from-Disaster/"><div class="card-body"> <span class="timeago small" >Aug 11, 2021<i class="unloaded">2021-08-11T11:11:11-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML lab 01 - Titanic-ML-from-Disaster</h3><div class="text-muted small"><p> ML Lab - Titanic - Machine Learning from Disaster ML Lab - Titanic - Machine Learning from Disaster the file 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # This Python 3 environment comes wi...</p></div></div></a></div><div class="card"> <a href="/posts/ml-lab-02-Homedata/"><div class="card-body"> <span class="timeago small" >Aug 11, 2021<i class="unloaded">2021-08-11T11:11:11-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML lab 02 - Predict home prices in Iowa</h3><div class="text-muted small"><p> ML lab - Home data Basic Step 1: Evaluate several models Step 2: Generate test predictions Missing value Step 1: ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/HTTP-Retry/" class="btn btn-outline-primary" prompt="Older"><p>HTTP - Retry</p></a> <a href="/posts/ml-2/" class="btn btn-outline-primary" prompt="Newer"><p>ML - 2nd - Intermediate Machine Learning</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/ocholuo">Grace JyL</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/aws/">AWS</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/cyberattack/">CyberAttack</a> <a class="post-tag" href="/tags/lab/">Lab</a> <a class="post-tag" href="/tags/cyberattacktools/">CyberAttackTools</a> <a class="post-tag" href="/tags/gcp/">GCP</a> <a class="post-tag" href="/tags/sysadmin/">Sysadmin</a> <a class="post-tag" href="/tags/java/">Java</a> <a class="post-tag" href="/tags/network/">Network</a> <a class="post-tag" href="/tags/soc/">SOC</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://ocholuo.github.io/{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/npm/countup.js@1.9.3/dist/countUp.min.js"></script> <script defer src="/assets/js/dist/pvreport.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-179830187-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-179830187-1'); }); </script>
